{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d539ed0b-a1e5-4d3b-bcf4-41c550f7c2e6",
      "metadata": {
        "id": "d539ed0b-a1e5-4d3b-bcf4-41c550f7c2e6"
      },
      "source": [
        "# Homework 2: Simple Linear Regression\n",
        "***\n",
        "\n",
        "**Name**: HARISH NANDHAN SHANMUGAM\n",
        "\n",
        "***\n",
        "\n",
        "This assignment is due on Gradescope by **Friday February 7 at 5:00PM**. Your solutions to theoretical questions should be done in Markdown directly below the associated question.  Your solutions to computational questions should include any specified R code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
        "\n",
        "**NOTES**:\n",
        "\n",
        "- There are 2 total questions on this assignment.\n",
        "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Remember that there is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked here. **All** of your written commentary, justifications and mathematical work should be in Markdown.\n",
        "- Because you can technically evaluate notebook cells in a non-linear order, it's a good idea to do Kernel $\\rightarrow$ Restart & Run All as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected.\n",
        "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code.\n",
        "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit.\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7541fc1b-4780-4356-add7-b4ccc1aa98ef",
      "metadata": {
        "id": "7541fc1b-4780-4356-add7-b4ccc1aa98ef"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "### Problem 1 - Analysis of Regression Coefficients (50 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "535c5cc4-28ef-4917-bae8-f5665c65bff6",
      "metadata": {
        "id": "535c5cc4-28ef-4917-bae8-f5665c65bff6"
      },
      "source": [
        "**Part A:**  In class, we analyzed regression with an intercept, $\\beta_0$. In some circumstances, we may have theoretical reasons to suggest that the intercept term is zero. As such, some have proposed to not estimate $\\beta_0$, and instead, use the one-predictor linear model: $Y_i = \\beta_1 x_i + \\epsilon_i$.\n",
        "\n",
        "Find the least squares estimator of $\\beta_1$ in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "408ceac5-98cd-404a-9613-3573627bbccb",
      "metadata": {
        "id": "408ceac5-98cd-404a-9613-3573627bbccb"
      },
      "source": [
        "$$\n",
        "\\text{The model is } Y_i = \\beta_1 x_i + \\varepsilon_i\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{The Sum of Squared Errors:}\n",
        "$$\n",
        "\n",
        "$$\n",
        "SSE = \\sum_{i=1}^{n} (Y_i - \\beta_1 x_i)^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{To minimize, differentiate with respect to } \\beta_1 \\text{ to find } \\hat{\\beta_1}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{d}{d\\beta_1} \\sum_{i=1}^{n} (Y_i - \\beta_1 x_i)^2 = 0\n",
        "$$\n",
        "\n",
        "$$\n",
        "2 \\sum_{i=1}^{n} (Y_i - \\beta_1 x_i)(-x_i) = 0\n",
        "$$\n",
        "\n",
        "$$\n",
        "-2 \\sum_{i=1}^{n} x_i (Y_i - \\beta_1 x_i) = 0\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^{n} x_i Y_i - \\beta_1 \\sum_{i=1}^{n} x_i^2 = 0\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^{n} x_i Y_i = \\beta_1 \\sum_{i=1}^{n} x_i^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\bar{Y} \\bar{x}*n = \\beta_1 \\bar{x}^2*n\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{\\beta_1} = \\frac{\\bar{Y} \\bar{x}}{\\bar{x}^2}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a372dc67-cf61-4123-b960-b382cfa029b4",
      "metadata": {
        "id": "a372dc67-cf61-4123-b960-b382cfa029b4"
      },
      "source": [
        "**Part B:** Show that the residuals of this model fit do not sum necessarily sum to zero. You can use a simulation to show this, if you would like."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\textbf{Residual:}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\varepsilon_i = y_i - \\widehat{\\beta}_1 x_i\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\widehat{\\beta}_1 = \\frac{\\overline{xy}}{\\overline{x^2}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\varepsilon_i = y_i - \\frac{\\overline{xy}}{\\overline{x^2}} x_i\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\textbf{Sum of Residuals:}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^{n} \\varepsilon_i = \\sum_{i=1}^{n} \\left( y_i - \\frac{\\overline{xy}}{\\overline{x^2}} x_i \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "= n \\bar{y} - \\frac{\\overline{xy}}{\\overline{x^2}} \\sum_{i=1}^{n} x_i\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{if the mean of\n",
        "x is not zero, residuals will not sum to zero}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "K1AmKRDYp50l"
      },
      "id": "K1AmKRDYp50l"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "41335397-02fd-4f07-9e05-6d4cff00686d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "41335397-02fd-4f07-9e05-6d4cff00686d",
        "outputId": "048f64d3-0d4b-4ea7-d78e-647b178aa9af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.939245046888"
            ],
            "text/markdown": "1.939245046888",
            "text/latex": "1.939245046888",
            "text/plain": [
              "[1] 1.939245"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The residuals of the model fit is ~ -3.28 (approx) is not sum to zero"
          ]
        }
      ],
      "source": [
        "n = 100\n",
        "x = rnorm(n)\n",
        "beta_1 = 3\n",
        "e = rnorm(n)\n",
        "y = beta_1 * x + e\n",
        "\n",
        "model_no_intercept = lm(y ~ x - 1)\n",
        "y_cap = predict(model_no_intercept)\n",
        "residuals = sum(y-y_cap)\n",
        "residuals\n",
        "\n",
        "\n",
        "cat(\"The residuals of the model fit is ~ 1.93 (approx) is not sum to zero\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "779135af-f66c-46bb-babf-f7bbb5b91d28",
      "metadata": {
        "id": "779135af-f66c-46bb-babf-f7bbb5b91d28"
      },
      "source": [
        "**Part C:** Suppose that, for $i = 1,...,n$, the pairs $(x_i, y_i)$ are generated according to a simple linear regression model\n",
        "\n",
        "$$Y_i = \\beta_0 + \\beta_1x_i + \\varepsilon_i,$$\n",
        "\n",
        "where $x_i$ are fixed constants and $\\varepsilon_i \\overset{iid}{\\sim} N(0,\\sigma^2)$. Then, imagine reparameterizing the model as\n",
        "\n",
        "$$Y_i = \\beta^*_0 + \\beta^*_1\\left(\\frac{x_i- \\bar{x}}{sd(x)}\\right) + \\varepsilon_i,$$\n",
        "\n",
        "where $sd(x) = \\frac{1}{n-1}\\sum(x_i - \\bar{x})^2$.\n",
        "\n",
        "Let $\\widehat\\beta_j$ be the least squares estimator of $\\beta_j$, and $\\widehat\\beta^*_j$ be the least squares estimator of $\\beta^*_j$ for $j=0,1$.\n",
        "\n",
        "Show that $\\widehat\\beta^*_1 \\ne \\widehat\\beta_1$.\n",
        "\n",
        "HINT: For regression with one predictor, $\\displaystyle \\widehat\\beta_1 = \\frac{\\sum^n_{i=1}\\left( x_i - \\bar{x}\\right)\\left(y_i - \\bar{y} \\right)}{\\sum^n_{i=1}\\left(x_i - \\bar{x}\\right)^2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c25c3f7-c6ff-46d0-a0b2-4943981ccb45",
      "metadata": {
        "id": "5c25c3f7-c6ff-46d0-a0b2-4943981ccb45"
      },
      "source": [
        "$$y_i = \\beta^*_0 + \\beta^*_1\\left(\\frac{x_i- \\bar{x}}{sd(x)}\\right) + \\varepsilon_i$$\n",
        "\n",
        "$$\\text{Here,}$$\n",
        " $$z_i = (x_i - \\bar{x})/sd(x)$$\n",
        "$$\\text{Sum of Squared Errors,}$$\n",
        " $$SSE = \\sum^n_{i=1} e^2_{i} = \\sum^n_{i=1} (y_{i} -\\beta^*_{0}- \\beta^*_{1}*z_i)^2$$\n",
        "\n",
        "$$\n",
        "\\text{To minimize, differentiate with respect to } \\beta_1^* \\text{ to get } \\hat{\\beta_1^*}\n",
        "$$\n",
        "\n",
        " $$\\frac{d \\sum^n_{i=1} (y_{i} - \\beta^*_{0}- \\beta^*_{1}*z_i)^2}{d\\beta_{1}} = 0$$\n",
        "\n",
        " $$\\sum^n_{i=1} 2 * (y_{i} -\\beta^*_{0}- \\beta^*_{1}*z_i)* -1 * (z_i) = 0$$\n",
        "\n",
        "\n",
        " $$ (\\sum^n_{i=1} y_{i}*z_i -\\beta^*_{0}* \\sum^n_{i=1} z_i -\\beta^*_{1}* \\sum^n_{i=1} z_i^2)= 0$$\n",
        "\n",
        " $$\\text{As $z_{i}$ is standardized value (where mean = 0, variance = 1)}$$\n",
        "\n",
        " $$ \\sum^n_{i=1}z_i =0$$\n",
        "\n",
        " $$ (\\sum^n_{i=1} y_{i}*z_i -\\beta^*_{0}* 0 -\\beta^*_{1}* \\sum^n_{i=1} z_i^2)= 0$$\n",
        "\n",
        " $$ (\\sum^n_{i=1} y_{i}*z_i -\\beta^*_{1}* \\sum^n_{i=1} z_i^2)= 0$$\n",
        "\n",
        " $$\\beta^*_{1} = \\frac{\\sum^n_{i=1} y_{i}*z_i}{\\sum^n_{i=1} z_i^2}$$\n",
        "\n",
        " $$\\beta^*_{1} = \\frac{\\sum^n_{i=1} y_{i}*z_i}{\\sum^n_{i=1} z_i^2}$$\n",
        "\n",
        "$$\\quad \\text{[NUMERATOR]}$$\n",
        "\n",
        " $$\\sum^n_{i=1} y_{i}*z_i= \\sum^n_{i=1} y_{i}*(x_i - \\bar{x})/sd(x) $$\n",
        "\n",
        " $$\\sum^n_{i=1} y_{i}*z_i= \\frac{\\sum^n_{i=1} y_{i}*(x_i - \\bar{x})}{sd(x)}$$\n",
        "\n",
        "$$\\quad \\text{[DENOMINATOR]}$$\n",
        "\n",
        " $$\\sum^n_{i=1} z_i^2 =\\sum^n_{i=1} \\frac{(x_i - \\bar{x})^2}{sd(x)^2}$$\n",
        "\n",
        " $$\\sum^n_{i=1} z_i^2 = \\frac{1}{sd(x)^2} \\sum^n_{i=1} (x_i - \\bar{x})^2$$\n",
        "\n",
        " $$\\sum^n_{i=1} z_i^2 = \\frac{1}{sd(x)^2} * (n-1) * var(x)$$\n",
        "\n",
        " $$\\sum^n_{i=1} z_i^2 = \\frac{1}{sd(x)^2} * (n-1) * sd(x)^2$$\n",
        "\n",
        " $$\\sum^n_{i=1} z_i^2 = n-1$$\n",
        "\n",
        "$$\\text{Substituting the numerator and denominator}$$\n",
        " $$\\hat{\\beta^*_{1}} = \\frac{\\sum^n_{i=1} y_{i}*(x_i - \\bar{x})}{sd(x) *(n-1)}$$\n",
        "\n",
        " $$\\hat{\\beta^*_{1}} = \\frac{\\sum^n_{i=1} y_{i}*(x_i - \\bar{x})}{\\frac{\\sum^n_{i=1}(x_i - x)^2}{sd(x)}}$$\n",
        "\n",
        " $$\\hat{\\beta^*_{1}} = sd(x) * \\frac{\\sum^n_{i=1} y_{i}*(x_i - \\bar{x})}{\\sum^n_{i=1}(x_i - x)^2}$$\n",
        "\n",
        " $$\\hat{\\beta^*_{1}} = sd(x) * \\frac{\\sum^n_{i=1} x_i *y_i - \\sum^n_{i=1} \\bar{y}*x_i - \\sum^n_{i=1} y_i*\\bar{x} - \\sum^n_{i=1} \\bar{x}*\\bar{y}}{\\sum(x_i - x)^2}$$\n",
        "\n",
        " $$\\hat{\\beta^*_{1}} = sd(x) * \\frac{n*\\bar{xy} - n*\\bar{x}*\\bar{y} - n*\\bar{x}*\\bar{y} + n *\\bar{x}*\\bar{y}}{\\sum^n_{i=1}(x_i - x)^2}$$\n",
        "\n",
        " $$\\hat{\\beta^*_{1}} = sd(x) * \\frac{n\\bar{xy} - n\\bar{x}\\bar{y}}{\\sum^n_{i=1}(x_i - x)^2}$$\n",
        "\n",
        "$$\\text{In the question, $\\hat{\\beta_{1}}$ is given as,}$$\n",
        "\n",
        " $$\\displaystyle \\widehat\\beta_1 = \\frac{\\sum^n_{i=1}\\left( x_i - \\bar{x}\\right)\\left(y_i - \\bar{y} \\right)}{\\sum^n_{i=1}\\left(x_i - \\bar{x}\\right)^2}$$\n",
        "\n",
        " $$\\displaystyle \\widehat\\beta_1 = \\frac{\\sum^n_{i=1}\\left( x_i *y_i - \\bar{y}*x_i - y_i*\\bar{x} - \\bar{x}*\\bar{y} \\right)}{\\sum^n_{i=1}\\left(x_i - \\bar{x}\\right)^2}$$\n",
        "\n",
        " $$\\displaystyle \\widehat\\beta_1 = \\frac{\\sum^n_{i=1} x_i *y_i - \\sum\\bar{y}*x_i - \\sum^n_{i=1} y_i*\\bar{x} - \\sum^n_{i=1} \\bar{x}*\\bar{y}}{\\sum^n_{i=1}\\left(x_i - \\bar{x}\\right)^2}$$\n",
        "\n",
        " $$\\displaystyle \\widehat\\beta_1 = \\frac{n*\\bar{xy} - n*\\bar{x}*\\bar{y} - n*\\bar{x}*\\bar{y} + n *\\bar{x}*\\bar{y}}{\\sum^n_{i=1}\\left(x_i - \\bar{x}\\right)^2}$$\n",
        "\n",
        " $$\\displaystyle \\widehat\\beta_1 = \\frac{n\\bar{xy} - n\\bar{x}\\bar{y}}{\\sum^n_{i=1}\\left(x_i - \\bar{x}\\right)^2}$$\n",
        "\n",
        "$$\\text{After solving $\\hat{\\beta^*_{1}}$ and $\\hat{\\beta_{1}}$, the relationship established between them is}$$\n",
        " $$\\hat{\\beta^*_{1}} = \\hat{\\beta_{1}} *sd(x)$$\n",
        "\n",
        "$$\\text{So, it is clearly proved that}$$\n",
        " $$\\hat{\\beta^*_{1}} \\ne \\hat{\\beta_{1}}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf57718-804a-4e83-8f01-2af9c7313701",
      "metadata": {
        "id": "dbf57718-804a-4e83-8f01-2af9c7313701"
      },
      "source": [
        "**Part D:** Show that, in general, $\\widehat\\beta^*_0 \\ne \\widehat\\beta_0$, and find $\\widehat\\beta^*_0$ in terms of $Y_i$. In what particular case is $\\widehat\\beta^*_0 = \\widehat\\beta_0$?\n",
        "\n",
        "HINT: For SLR, $\\widehat\\beta_0 = \\bar{y} - \\widehat\\beta_1 \\bar{x}$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53427d7a-d0e1-48f8-88fd-991d5d0fdc7b",
      "metadata": {
        "id": "53427d7a-d0e1-48f8-88fd-991d5d0fdc7b"
      },
      "source": [
        "$$\n",
        "\\text{From Simple Linear Regression, we know}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1} \\bar{x}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Now, for the standardized intercept:}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{\\beta_0^*} = \\bar{y} - \\hat{\\beta_1^*} \\bar{x^*}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Here,}\n",
        "$$\n",
        "\n",
        "$$\n",
        "x^* = \\frac{x_i - \\bar{x}}{sd(x)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{So,}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{\\beta_0^*} = \\bar{y} - \\hat{\\beta_1^*} \\left(\\frac{x_i - \\bar{x}}{sd(x)}\\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{We know that the mean of a standardized value is 0:}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{\\beta_0^*} = \\bar{y}\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1} \\bar{x}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Here, } \\hat{\\beta_0^*} \\neq \\hat{\\beta_0}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{In the case where } \\bar{x} \\text{ is equal to 0,}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1} (0)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{\\beta_0} = \\bar{y}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\therefore \\hat{\\beta_0} = \\hat{\\beta_0^*}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8b59c95-7a08-4dda-849f-f388b214257c",
      "metadata": {
        "id": "e8b59c95-7a08-4dda-849f-f388b214257c"
      },
      "source": [
        "**Part E:** Why might the reparameterized model be beneficial?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a516d59-17bd-4b92-b757-f3c7ebe389bf",
      "metadata": {
        "id": "0a516d59-17bd-4b92-b757-f3c7ebe389bf"
      },
      "source": [
        "- Standardizing 'x' helps in making the coefficients comparable across different predictors, which makes sure no variable dominates due to different scales.\n",
        "- It prevents the issues related to collinearity and precision errors which are directly related to deciding the model performance.\n",
        "- The standardized slope represents the change in 'y' for 1 SD increase in 'x' which makes easier to compare the reparameterized and the normal models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bf3ae93-ce53-41ac-ab9d-55f15d2ab599",
      "metadata": {
        "id": "3bf3ae93-ce53-41ac-ab9d-55f15d2ab599"
      },
      "source": [
        "**Part F:** Run a simulation to confirm your result in parts 1(c) - 1(d). Let's do this in parts. In the cell directly below:**\n",
        "\n",
        "- Set `n = 50`, $\\boldsymbol\\beta = $ `beta = c(1, 3.5)`.\n",
        "- Simulate $n$ predictor values ($x$) randomly from $N(3,1)$. Store those values in a variable `x`.\n",
        "- Simulate $n$ random error terms from $N(0,2)$. Store them in the variable `e`.\n",
        "- Calculate the response ($y$) according to `y = b0 + b1 x + e`\n",
        "- Fit a simple linear regression model to the data using the `lm()` function. Store the `lm()` object in a variable `l` and the coefficients of that model in a variable `b1 = coef(l)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42f307ba-c8f2-4070-91a4-c01c271e7ca1",
      "metadata": {
        "id": "42f307ba-c8f2-4070-91a4-c01c271e7ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa4af0f7-bfa9-4255-b5af-3438d999416e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".dl-inline {width: auto; margin:0; padding: 0}\n",
              ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
              ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
              ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
              "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>1.36564100231492</dd><dt>x</dt><dd>3.43558468905318</dd></dl>\n"
            ],
            "text/markdown": "(Intercept)\n:   1.36564100231492x\n:   3.43558468905318\n\n",
            "text/latex": "\\begin{description*}\n\\item[(Intercept)] 1.36564100231492\n\\item[x] 3.43558468905318\n\\end{description*}\n",
            "text/plain": [
              "(Intercept)           x \n",
              "   1.365641    3.435585 "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "set.seed(1)\n",
        "n = 50\n",
        "beta = c(1,3.5)\n",
        "\n",
        "x = rnorm(n, mean = 3, sd =1)\n",
        "e = rnorm(n, mean = 0, sd =sqrt(2))\n",
        "\n",
        "y = beta[1] + beta[2]* x + e\n",
        "\n",
        "l = lm(y~x)\n",
        "b = coef(l)\n",
        "b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b8ca6b5-02d0-4cab-b302-88df00136c0c",
      "metadata": {
        "id": "1b8ca6b5-02d0-4cab-b302-88df00136c0c"
      },
      "source": [
        "**Part G:**\n",
        "\n",
        "- Center and scale the predictor values and store those values in a variable `z`.\n",
        "- Fit a simple linear regression model to the new data, $(z_i, y_i)$, using the `lm()` function. Store the `lm()` object in a variable `l2` and the coefficients of that model in a variable `b2 = coef(l2)` (`b2` should be a vector of length $2$).\n",
        "- Describe the differences between `b` and `b2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fbc564-5369-4aee-8f21-4ed0e257cb75",
      "metadata": {
        "id": "31fbc564-5369-4aee-8f21-4ed0e257cb75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc175266-9ee1-441a-d154-e2ef2b894878"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".dl-inline {width: auto; margin:0; padding: 0}\n",
              ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
              ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
              ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
              "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>12.0174936421477</dd><dt>z</dt><dd>3.16748720348743</dd></dl>\n"
            ],
            "text/markdown": "(Intercept)\n:   12.0174936421477z\n:   3.16748720348743\n\n",
            "text/latex": "\\begin{description*}\n\\item[(Intercept)] 12.0174936421477\n\\item[z] 3.16748720348743\n\\end{description*}\n",
            "text/plain": [
              "(Intercept)           z \n",
              "  12.017494    3.167487 "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "z = (y - mean(y))/sd(y)\n",
        "\n",
        "l2 = lm(y~z)\n",
        "b2 = coef(l2)\n",
        "b2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Change in Slope:  \n",
        "   - $ \\widehat{\\beta}_1^* = \\widehat{\\beta}_1 \\times sd(x) $\n",
        "   - The standardized slope can be rescaled by multiplying it with the standard deviation (x)\n",
        "\n",
        "2. Change in Intercept:  \n",
        "   - In the 'z',  $ \\widehat{\\beta}_0^* = \\bar{y} $  instead of $ \\bar{y} - \\widehat{\\beta}_1 \\bar{x} $  \n",
        "\n",
        "3. Interpretation:\n",
        "   - In the 'y', $\\widehat{\\beta}_1$ represents the change in \\( y \\) per unit increase in \\( x \\).  \n",
        "   - In the 'z', $\\widehat{\\beta}_1^*$  represents the change in \\( y \\) per one standard deviation increase in \\( x \\).  \n"
      ],
      "metadata": {
        "id": "uNSXxpkVb10-"
      },
      "id": "uNSXxpkVb10-"
    },
    {
      "cell_type": "markdown",
      "id": "f06739c1-13c4-4468-a7b6-535943ec3117",
      "metadata": {
        "id": "f06739c1-13c4-4468-a7b6-535943ec3117"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "### Problem 2 - Simple Linear Regression (50 points)\n",
        "\n",
        "For this problem, we will be performing simple linear regression using the following dataset:\n",
        "`Fish.csv`\n",
        "\n",
        "Information about this data from the original source (kaggle): \"This dataset is a record of 7 common different fish species in fish market sales. With this dataset, a predictive model can be performed using machine friendly data and estimate the weight of fish can be predicted.\"\n",
        "\n",
        "**Response**:\n",
        "- Weight (in grams)\n",
        "\n",
        "**Features**:\n",
        "- Length1 (vertical length in cm)\n",
        "- Length2 (diagonal length in cm)\n",
        "- Length3 (cross length in cm)\n",
        "- Height (in cm)\n",
        "- Width (diagonal width in cm)\n",
        "\n",
        "The species name of the fish is also given."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf69846-a777-4198-b230-0706e0bf40f6",
      "metadata": {
        "id": "7cf69846-a777-4198-b230-0706e0bf40f6"
      },
      "source": [
        "**Part A**: Read the data from the csv into a DataFrame.  If you are reading in `Fish.csv`, I would recommend dropping the species column as it is non-numerical.\n",
        "\n",
        "Also, make sure to re-order the columns so that the response variable is the last column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "601f2839-d5dc-471d-b880-4c6d6b0c3ea7",
      "metadata": {
        "id": "601f2839-d5dc-471d-b880-4c6d6b0c3ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "16c60469-9421-4365-cbe7-3376992fea1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 6</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Length1</th><th scope=col>Length2</th><th scope=col>Length3</th><th scope=col>Height</th><th scope=col>Width</th><th scope=col>Weight</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>23.2</td><td>25.4</td><td>30.0</td><td>11.5200</td><td>4.0200</td><td>242</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>24.0</td><td>26.3</td><td>31.2</td><td>12.4800</td><td>4.3056</td><td>290</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>23.9</td><td>26.5</td><td>31.1</td><td>12.3778</td><td>4.6961</td><td>340</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>26.3</td><td>29.0</td><td>33.5</td><td>12.7300</td><td>4.4555</td><td>363</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>26.5</td><td>29.0</td><td>34.0</td><td>12.4440</td><td>5.1340</td><td>430</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>26.8</td><td>29.7</td><td>34.7</td><td>13.6024</td><td>4.9274</td><td>450</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 6\n\n| <!--/--> | Length1 &lt;dbl&gt; | Length2 &lt;dbl&gt; | Length3 &lt;dbl&gt; | Height &lt;dbl&gt; | Width &lt;dbl&gt; | Weight &lt;dbl&gt; |\n|---|---|---|---|---|---|---|\n| 1 | 23.2 | 25.4 | 30.0 | 11.5200 | 4.0200 | 242 |\n| 2 | 24.0 | 26.3 | 31.2 | 12.4800 | 4.3056 | 290 |\n| 3 | 23.9 | 26.5 | 31.1 | 12.3778 | 4.6961 | 340 |\n| 4 | 26.3 | 29.0 | 33.5 | 12.7300 | 4.4555 | 363 |\n| 5 | 26.5 | 29.0 | 34.0 | 12.4440 | 5.1340 | 430 |\n| 6 | 26.8 | 29.7 | 34.7 | 13.6024 | 4.9274 | 450 |\n\n",
            "text/latex": "A data.frame: 6 × 6\n\\begin{tabular}{r|llllll}\n  & Length1 & Length2 & Length3 & Height & Width & Weight\\\\\n  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t1 & 23.2 & 25.4 & 30.0 & 11.5200 & 4.0200 & 242\\\\\n\t2 & 24.0 & 26.3 & 31.2 & 12.4800 & 4.3056 & 290\\\\\n\t3 & 23.9 & 26.5 & 31.1 & 12.3778 & 4.6961 & 340\\\\\n\t4 & 26.3 & 29.0 & 33.5 & 12.7300 & 4.4555 & 363\\\\\n\t5 & 26.5 & 29.0 & 34.0 & 12.4440 & 5.1340 & 430\\\\\n\t6 & 26.8 & 29.7 & 34.7 & 13.6024 & 4.9274 & 450\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  Length1 Length2 Length3 Height  Width  Weight\n",
              "1 23.2    25.4    30.0    11.5200 4.0200 242   \n",
              "2 24.0    26.3    31.2    12.4800 4.3056 290   \n",
              "3 23.9    26.5    31.1    12.3778 4.6961 340   \n",
              "4 26.3    29.0    33.5    12.7300 4.4555 363   \n",
              "5 26.5    29.0    34.0    12.4440 5.1340 430   \n",
              "6 26.8    29.7    34.7    13.6024 4.9274 450   "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "library(dplyr)\n",
        "\n",
        "df = read.csv(\"Fish.csv\") %>%\n",
        "        select(-Species) %>%\n",
        "        select(-Weight, everything(), Weight)\n",
        "head(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56575c4-98fe-408e-bc67-3678aa77f4bd",
      "metadata": {
        "id": "a56575c4-98fe-408e-bc67-3678aa77f4bd"
      },
      "source": [
        "**Part B:** Make separate scatter plots for each feature versus the response. From these plots, we will try and make inferences about which features appear to have a relationship with the response variable. Write a brief summary of what you notice in each plot. Do you notice any trends in the data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6da0aa14-da9f-4908-8544-10d551875081",
      "metadata": {
        "id": "6da0aa14-da9f-4908-8544-10d551875081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "578e4a58-cc66-495a-a98d-3004acb54b16"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Plot with title “Width vs Weight”"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAACXBIWXMAABJ0AAASdAHeZh94\nAAAgAElEQVR4nOzdedx0Z10f/s8kYQ3EJ4RdFgWVxKDwAsJShQK2LgEELai/AhJbi1IiooCo\nxRZbodafouJCSwsiCLgAIosgaI0F2RIq+xohIYmELQQIJJBl+sd1Js8888yZe7azzJn3+37d\nr7nnnJk51z33zOee77muc50EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYNqlScZJ\nfqTrhizpwpT2fu8St71dkjdVtz+vwTYt8vFq+z81s/y8avkFM8t/sVr+7hW2scpzso37wbKG\nmi83TPKsJJ9K8pUk7015jx/baOuOJl/YZ0PNl0NJfjPlffzVJOcmOTPJMU02bg75sgPaflHQ\nD9+Y8gb4yTXu+4iUN+l3brVFq3tzdXna1LKbJbl99fNtktx6at3dZu63jNcn+YuUD2tN2OTv\nAH21yev6j5L8TMoHmYuT3DnJs5M8ZWutW458gX5a93V9TJKXJ3likpun5Msdk/xO5Ms6Bp8v\nCqT99MMb3Pc5KcHyy1tqy7omQXGPqWX3qi6/MnM9WS9gfjzJw5L8w8qtW84mfwfoq3Vf19+c\n5AeSXJPyweEOSZ5Urfu3W2jXKuQL9NO6r+t7JXlgks+nZM3tk/zXat2PbaFdq5Av7LVlu6iP\nTek+fX/KG+PcJI+buc0l1WOdluQPk3yxWva0mdudlORPk1yWstfgl1IKmXGS51a3eVd1ffJ9\nVbV80q16esoelUtrtvH0JDdI8uAsN8TuLdXtnj6z/M+r5b9ZXf/6JH+Q5BNJrkjysSTPSHKd\nmsc9tbr/1UluVC37L9WyP64uf7VafiiHf9/bVsuWed5nu5qXeX6n77fouaz7O8Ayhpgv35Cy\nN/KRU8vuW93viprfT77IF7ZviPly+5TPLfeZWvaQ6n4X1vx+8kW+0IBlA+bZ1e3OTXmDfLC6\nfsbUbf4ph8ef/lmSF+XwC/MhU7d7WbXsCylDVT6a5B+rZb9X3eZnUsa3jpO8Mcl/q5ZP3hR/\nneT8qj3ztjGxbIH0xOp2Z08tu16SL1XL710te1t1/S+S/EaSd8y0e9Yoyeeq29yvWvZXOfzG\nHif522r5A6vr50/df5nnfTZglnl+p++36Lms+zvAMoaeLxO/U92mbi+ofJEvbN8+5MstUvJg\nnDIyZh75Il9owDIBc4uUynucw12o35QyxOTcqdtNXrB/PLXs1dWy/15dv/nUY/1AtezQVDt+\nd+q+Z1XLpseOTrbx90mum+S4JOfMbGPasgXSbarf55qqjUl5w07f98bV9cuq7SbJ8UmemSPf\n8LMmz8HPpgTOJSnD/46tHutLKcNIn1Ld7sXV/VZ93r83qz2/yz6XZ+XovwMsY+j5kiSPyeF/\nzA+uuY18kS9s39Dz5X05XCw8o7rPPPJlj/PFMUjdOi3lzfC1JJ9JeTNekdL9eceUN8K0V039\n/M7q8lbV5cnVY42TvKZadmnKXolVPK9qz1UpB/lNb2MdF6bsXRkl+b5q2WQvxJ9Ul19KclFK\nqLw3ya8neUDKnpEXLHjs6XG8d0xyYpK3p3RbvzOl6/rUHD1+d9XnPVnv+d32cwmr2OV8+cmU\nIStJOU7gNXNuk8gX+UJXdjlfPpFSkJyQMvFU3aRT8mWP80WB1K1D1eV1U96wF1Tft6yWz74Y\nL5n6eTImfzL97UnV5ZeSXFlzn2V8curny2a2sa4/rS5Pry4ne4On9yg9PMkHUt7IT0rZu/KJ\nlIMM60wHzORgx3fMXN41yT1nbr/q856s9/w28VzCsnY1X34qZcjLKGXs/y8e8JjyRb7Qvl3N\nl6RkxUkpx+18c8rQv+NrHlO+7Gm+HHfwTWjQpdXlVzJ/RpDZufCXeawbpfxdJwfNnTT/5rXG\nK95+GS9LObfJdye5e8p5lD6aI48reFvK3pI7JfnnSX4wyfckeUnK9JdfnvO4Z6cE7TdV90kO\nB8vbq8vvSJkN69KUAxqT9Z73dZ7fJp5LWNYu5suDk/xWynCRx+XIg4fryBdo367ly72q74tS\npvtOyqQRz0lyk5RC6V1z7idf9pQepG6dndKdesOUg+Vek3Jg3E2q9V9Y4bE+nPKh4pgkD6qW\n3STlTTpr8sK/0Zx1TZh0Ux9KGZebHLn35Y4pM6o8JuX3eG7KuNlPp8yYd0LN434tZWzsKMkP\n5ciDKScB84jq8i0pz0+y3vO+yvO7rLb/DuyXXcuX45P8j2obz8hyxVEiX+rIF5q0a/lyzyS/\nnTIhwW2qZadPra8r6OTLfIPPFwVS834r5cC52e9TUsaM/q/qdm9IeeP+n5S9Gj+R1aZO/Kck\nr61+flGSl6a8keZ1oV5UXT6p2v6NV9jOa6rv/1hdv/nUsu9acL9JN/V3V5d/MrXuy0meWrXl\n+Skh9Mrqsc/OkV29sybdzjdJ2asz2VNyQXW/m8zcLlnveV/l+V3WJn8HSIaVL4/O4ZMjPjbl\ng8n0950W3Fe+HE2+sKkh5csfpEyscIuUwuKilN6hpAyx+9yC+8qXo8kX1jaZHaTu+67V7Y5L\n8p9TplO8MmUWk1/PkeNhZ6drTJKfz5EH3CVlDOpfJrk85cU7edOOc3i+/iT59pRpIb+WEhQn\nrLCNRb/TGQuej8lsMOOUAxln3SPJ61LesF9NCbLfz+GZY+pMpsQcp7zxp/351Lr7zqxb53lf\n9vld9rmc93eAZQwxX558wO905wXPh3yRL2zPEPMlKcfn/FGSz6YMb/tQkl/Jwb0g8kW+sOO+\nPaXLdPpNOZmP/8xOWjQsnl/2mdd/szy/7DOv/2Z5ftlrr015sX8k5URir6+ufzy6P7fB88s+\n8/pvlueXfeb13yzPL3vthJQX/vkp3cfnpYxLvX2HbRoSzy/7zOu/WZ5f9pnXf7M8vwAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAwNCMum5ADzw6yUO6bgRs2TVJnp7kQx23Y9/JF4ZIvvSDfGGIepEv\nx3W58Z54WJJvSfKWrhsCW/TIJK+JDzBdky8MkXzpB/nCEPUiXxRIxf9O8tNdNwK26PSuG8C1\n5AtDI1/6Q74wNL3Il2O6bgAAAEBfKJAAAAAqCiQAAICKAgkAAKCiQAIAAKgokGBHjZPxOBl3\n3Q5ggMbVF8DWjauPMP2lQIIdM1sYKZKArZktjBRJwNbMFkb9LZIUSDAAiiSgMYokoDH9LJIU\nSAAAABUFEgAAQEWBBDtmlIyWWQawstGcLJm3DGBlozlZMm9Z947rugHA6hREQGMUREBj+lkQ\nzdKDBAAAUNGDBD0yOxudniJga2Zno9NTBGzF7Ex0u9FLtIgeJOiJeVN1m74b2ApTdQON6Oc0\n3ZtSIAHAPlI0AY3Y/aJJgQQA+8gQO6ARuz/Ers/HIN0vyaOSnJrk+CSXJXlPkucnOafDdkEj\nRsnIkLrWyBegKfIFdlxfe5Aen+QVSa5M8sIkz0rykmrdG5M8uqN2QaOmJ2UYlV0wO78Xpofk\nC/tntrdI71FT5At7Zra3aPd7j/rs3CR3rll3nyQf2OK2Xp7kt7f4eNAHF6TsweRo8gU2I1/q\nyRfYTC/ypa89SIdSHyJnJ7lli20BhkW+AE2RLzAAfS2QPprkzDnLR0melDKWFwZnXKZ+ufa7\n6/YMlHxh/4znfNEE+cKeGc9+dBlEtvR1koYzk7wyyc8l+WCSy5PcMMkp1c8P7a5p0Iy68yA5\nDmnr5AvQFPkCA9DXAumdSe6Q5AFJTs7hWWCemeTvklzdXdOAHSdfICm9SiZr2Db5AhmPd32y\nhr4WSEk5mPHhOXqazC/GNJnAZuQLKI6aIl/Yc7tdHCX9PQbJNJnsnXlD6Qyva4R8AZoiX4DG\nmCYTNtOLaTJ7Sr7AZuRLPfkCm+lFvvS1B8k0mUBT5AvQFPkCA9DXAsk0mUBT5AvQFPkCA9DX\nSRpMkwk0Rb4ATZEvMAB9LZC2OU3mqUkevGD9XdLf5wHYPvkCNEW+wAD09Y31gCR/m+QNKbO+\nPDbJ9yd5YJJbJXnxCo917ySPWLD+dunv8wBsn3wBmiJfgMZcMfXzU5NcmOTpSZ6R5OKUaTS3\n5aIk79ri40Ef9GIWmJ6SL7AZ+VJPvsBm5MsC0wHzoSTfNnX9LinjerdFwDBEAqaefIHNyJd6\n8gU204t86essdtNukOS9U9ffndJNDbAp+QI0Rb7AjuprgTRKGVt7QpK3Jrnv1LoHpuw1AViH\nfAGaIl9gAPp6cN/lSc5LCZrJ9TclOS3Jq5M8rptmAQMgX4CmyBcYgL4WSIdSere+LsmJSa6s\nlp+fMkPMOzpqF7D75AvQFPkCA9DXIXZJck2Szyf5WMoBW0ny6ZRweUVXjQIGQb4ATZEvsOP6\nXCAtcnrXDQAGS74ATZEvsAP6OsTuaQesP7aVVgBDJF+ApsgXGIC+FkhPTpnb/9Ka9bva8wV0\nT74ATZEvMAB9LZCemORBSR5Rs/6KmuUAB5EvQFPkCwxAX/dkvCDJJ1OmxQTYphdEvgDNeEHk\nC+y8vvYgJckTFqy7fmutAIZIvgBNkS+w4/ragwQAANA6BRIAAEBFgQQAAFBRIAEAAFQUSAAA\nABUFEgAAQEWBBAAAUFEgAQAAVBRIAAAAFQUSAABARYEEAABQUSABAABUFEgAAAAVBRIAAEBF\ngQQAAFBRIAEAAFQUSAAAABUFEgAAQEWBBAAAUFEgAQAAVBRIAAAAFQUSAABA5biuGwBDNU7G\n09dHyairtgADMz4yXzKSL8A2jI/Mloz2Mlv0IEEDZoujumUAWzFbMAFsxWzBtB8USACwSxRD\nQCP2sxiaR4EEALvEcDqgEfs5nG4eBRI0YN7xRo5BAgDoP5M0QENGyWhy3JHiCNiqSS/SOGM9\nSsD2THqRxuN97lFSIEGDFEZAoxRHQCP2tzhKDLEDAAC4lgIJAACgokACAACoKJAAAAAqCiQA\nAICKAgkAAKCiQAIAAKgokAAAACoKJAAAgIoCCQAAoKJAAgAAqCiQAAAAKgokAACAigIJAACg\nokACAACoKJAAAAAqx3XdAFjVOBnXrRslozbbAgzMuD5fMpIvwDrG9bmSkVzpIT1I7JRFxdEy\n6wFqLSqOABqxqHiiKwokAACAigIJAACg0udjkO6X5FFJTk1yfJLLkrwnyfOTnNNhu4DdJ1+A\npsgXVuAYpD7qaw/S45O8IsmVSV6Y5FlJXlKte2OSR3fULjo2OwnD9PVRSRlBw0HkC/MtmoTB\nBA0sR74wR10RpDhiNecmuXPNuvsk+cAWt3VRkndt8fGgDy5I2YPJ0eQLbEa+1JMvsJle5Etf\ne5AOpT5Ezk5yyxbbAgyLfAGaIl9gAPpaIH00yZlzlo+SPCllLC/AOuQL0BT5AgPQ10kazkzy\nyiQ/l+SDSS5PcsMkp1Q/P7S7pgE7Tr4ATZEvMAB9LZDemeQOSR6Q5OQcngXmmUn+LsnV3TUN\n2HHyBWiKfIEB6GuBlJSDGR+eo6fJ/GJMkwlsRr4ATZEvsOP6egySaTKBpsgXoCnyBWiMaTL3\n3DgZT3933Z4d1ItpMntKvpCMp75YlXypJ1/22njm4wtr6EW+9LUHyTSZe2xeQaRIYovky76b\nLYoUSWyPfGGKImlX9bVAMk3mADXRIzTb06TXiSXIl6Fb1Du0SjE0rvmCevJlb9UVQ7O9SXUf\nW+iTgyZpOCbJPZJ8R5JbpLzBL07y9ykHGl7TULtMkzkwswXLOBmPyutppceYvs9BRdA626BV\n8oXtm9c7NJrKgVFGSxU5i24z+5j0kXyhZw4qgibrR7KlBxYVSI9I8oyUYHlHSrAkyd2S/HJ1\n/T8k+bMG2rXNaTLvluRfLlh/oyRfWq+ZNGGUjJYpftpqD42QL2yf3h0K+UIHRiM9QcNRVyD9\njySnJXlKktcmuWrO/R6U5D8l+RdJfqKBtm1rmsxTU8Kyzg2SXH/NNrIBPTx7S77QnW0VUXqR\n+kq+AI35b0mOXeJ2xyb5tQa2//gkn03yeynh9aNJ/n2S30/y+Wx3mkyzwLRg1WOEljmuaNHx\nR45D6scsMDXkC81Z5pihumOLpm+76DZ6quRLPfmy1w78WLLE997rRb4ctPfrKZn/IXOc5JKU\nsbwf2XajUqbJfFiS981Zd58kz0vyrVva1kVJPpPkrlt6PGpMFyzL9BzNK3BWOQZpz3unLkjy\nC0n+qOuGLCBf2L7Z4qWul2dRkTO5T91t9BzJl3ryZe/VFTnLDMFz/FF2I1/ysiRXJPlwkr9O\nOeDwyynd1m9JOeDwkQ1s97Opn2HvuJRw2xZ7YHpKj9BGerEH5gDyhe7pHVqHfKknXziAnqMD\n9CJfDprm+9NJzkhyp5Sxuqck+bGUPSP/LMl9kzytgXaZJnNPKH72mnyhHYqffSRf6AlF0BB9\nqGb5dNfxeQ1s9+4pFeSFSd6Y5FUpe4AuSum+PnWL27IHpiPrHmPUl/Z21Y4l9WIPzAHkC807\nqIeoDz1IXW9/dfKlnnxhSl1PUVu9SDvZS9WLfDnoPEjHpoyZfevUsrunTC2ZlHG2X2ygXduc\nJpMdVTfddxez3/WlHQMjX+hG32eg63v7doN8oafG4/rjkSbrmt42m3pMkitTxu6+OWXPy1VJ\nnpAyPO/TSb6vg3a9YouPZQ9MR5bpHepLL1Jf2rGCXuyBOYB8oXnrzFbXp/b1k3xZn3zZK4t6\nipruRdrZY516kS91PUiHklya5A9Tuojvn+Skatmbk3y8ut3t0s0c/Kd3sE06sMxJY9k58oVu\n6Z0ZMvlCz+nB2QV1BdJbUg5ufEeSf0rykprb3SXJH2R7U1ZOHHTg5DLnOKDn5hU/s9f7MoRt\nXlv70rYdJF9ozyijuccd9cW89rEJ+UKPzBtKt6gXZ5vF0zLTilOnrkD6NylTZL4ryR+n7HW5\nuFp3yyTfmeRHUube/6EG2vXkatuX1qw/aPY9dsCyPUOzxUlXhcl0OxRHG5Ev9FcXvUvTRZLe\nrU3JF3ZUEz1Ls0WS3qttOD7Jzyd5b8qHwunv91brjm9o22ck+bMF66/Y4raM4e1I3XE9O3KM\nT9/1YgzvAvKFdtQd47M7x/v0kXypd0bkC9c68GOO/Dla3/PlCCck+ZYk31z93IZnJzmtZp2A\nGQAFUqN2KWDkC81RIDVBviwmX6gokNbQi3w5aJrviS+mmekwF3nCgnVdHFhJBwxp2wvyhW6Z\nVnvI5AsNU+QMkbGw7AS9ScBaFD5Ar0yOAxqNHBPUX8v2IMHWzfYKKYIAgN2xTO/RvCJIYdR3\nepDoDcPogEboRQIaodAZqoMKpB+rWf70LbcDFlI8DZJ8AZoiX4C11Q2xu3n1/UtJzp5Zd1KS\np0TI0IBJITROxoqiwZIvtE8v0r6QL7RsXi/SeKx3abfVFUj/PMl/TvKNKecMmHZl6s9MDVuh\nOBo0+QI0Rb7QA4qjoXtZ1w1ogfMINGzd8xo5F9JGenEegQPIF7Zn1XMaOQ/SJuRLP8iXXnF+\noy3pRb4cNIvdj6Y08rZJjp1Z9yuNtIhBmS1wlhk6t8592Enyhe2YLnImPy8aUjdbFDkP0hDJ\nF1o0ryAyzG6XHVQgvSTJ3ZK8J8lVzTeHIdlm748iaZDkC+vT88Ni8oUNzBY8iwqdRb1FiqRd\ndVCBdN+Ucbxtn4UaGD75wno2KY4UVvtCvrAmw+M4eJrvTyb5chsNYVi2feyQ3qNBki+0z1C6\nfSFf2CJF076pK5BuWn3/WpJfT/LNU8sm31CrrqBR6BD5QtPmFUGLJmVQNA2JfKFHDK/bVXVD\n7D4zc/2Jc27jj87W1fU8OQZpUOQLmxlldFShs0mRY5KGIZEvNKCu0DmoZ8kxSLuqrkC6Waut\nYJBGyWi64FHgUJEvbG66SDqouHHc0T6RL2xoUtBMih8Fzj6qK5A+W10+JfP36I+TXJLk75N8\npIF2MRCzRZGCicgXtmW2MJouhPQI7Sv5wpas22vEEBw0i929kjw4yfkpJ276+iS3S3JWkhOT\n/H6SH0/y4uaayFA4vxEz5Avbs+jcRvOG5DF08oUGKI72xUGz2H06yRlJ7pTkXyQ5JcmPJXlf\nkn+WMo3m0xpsHwOx7Kx2JnfYK/KF7Vim+FnUo6S3aYjkC1tWVxxN9zTN9joZnjdUH6pZ/r6p\nn89roR1NuijJu7puxNCNS7Ic9d11uwbsgpSzyPeZfGF7xnO+aIp86Qf50qq5H2PkzPb1Il8O\n6kE6Nsl9ZpbdPcmNqp8fFidhYwl6gJhDvgBNkS9smd6gfXLQMUi/kuT/JDk3yeeSHEpycpKf\nTSmunpvkMU02kOHo26x283qwum7TnpEvbM/scUZdD5vb5jTkrEO+0IDR6Mheoy6KptleK4Vb\nEw4qkP4wyRuT3D/JSUkuTfLmJB+v1t8uyRVNNY7hUYAwRb6wXX0pQuYN73OupbbJFxrSZUEy\nb0ifcy01oa5AulGSLyc5PqUL+lVz1l8W4cLAmFmvFfIFaIp8ATZWVyB9KcmtknxywX19iGRw\nFEetkC9AU+QLsLG6Aum2KVNk3rbFtgD7Qb4wbPPOu2R4XVvkCwM2ewzUZBnbVjeL3YVJrqku\nT07yH5P8ZnX9W1LCB3baqKTKaPZnGidfGL7RzBdtkS8M3Gh05DdNOGia73+f5IUpXdbfWS17\nWJJfb7JR0CaFUWfkC9AU+QI05uNJbl39fF51eb2UaTOHwonWtszJYHuhFydaO4B8YX1OCtsl\n+dIP8qVzThrbgF7ky0E9SF9N8k9zltnjzlzzCiKFEjXkC+upm0ZbocRh8oWG1U25zRAcVCB9\nNskjZ5b9qyyeHQbmUiQxQ76wfQolCvlCgxYVQoqkfXCvJJ9K2Qvz1SQfSTnA8bQuG7Vluqi3\nYFL8zA6vW+a767YPVC+6qA8gX1jObNEzO7yu7oumyJd+kC+tmR5Ct8xHGzbQi3ypm+b7Xyb5\nuyRvT3KnJN+b5MSUN+Pfphz0CEf0Cq1b7Dg5696RLyxvtjBaZUa4yX3NIrdP5AtbNFvsLFv8\njMdmmNttdQXSq5JcmeQNSV6T5LVJPtNWo9g/iqS9Il9YTt2xRlBPvtADiqNdV3cM0k2S/HDK\nHpdfSHJxkrcm+cUk395O04CBki9AU+QLsLG6HqTLk7yu+k6Sb0zppv6uJE+s1t++8dYxGJPe\nIcccEfkCNEe+0CE9R0Nx0Cx2E1dU31+tvq9prEUMluKIGvKF+Rw7xObkC7CyugLpOknun+RX\nU2ZI+VDKGajfkuSBKXtkIKOyu2Tk+CFWIF9Y3qj6guXIF7Zo8hGHfVM3xO5zSb6c5HlJzkzy\ntiRXtdUohmmUjOp6kRRYe0W+sLpRRmtN0KC42jfyBdhYXYH0a0m+L8kTUs4l8FfV93tbahcD\nMl38TB+LVFcUTRdRCqdBki+s7qDiaFIILZoKfPoxFE5DJV9owWg0f8pv03sPRd0Qu19J8h1J\nbpfkuUlOSfL6lFlhnp8yQwxca17P0KKhd8sUR3WPy86TL6xmXnE0mvmaXr7MY5gufKjkC1tW\nd+6juuF3ThS7b0ZJHpEypndIf3xnot6CeaeS7vJx6MeZqFcgX6g3nvO16f0VSJuQL/0gX1px\n1MeS8eEiaNE61tSLfKkbYjdxYspZqb8vZZrMQ0nOSvI/m20WsAfkC9AU+QKsra5AelpKoNw7\nyaeS/GWSn0zyxiRfaadpwEDJF9q17gQP7CL5QgsmQ+vqjkVi19UVSN+f5LVJfjrJ/82wuqRp\nwLwZ6hZNxLDs45ikYZDkC6uZV+CsOuHC7GOYpGGo5AtbNq8Imr4+u94kDUNQVyDds9VWMFjr\nFklNtYdekC90Q1G0D+QLHVAUDU3dLHawEpMpAI0xPA7ojCF0++igSRrgKIohoFEKIqAzCiL0\nINEww+WAlSiOAOiYHiRWskrvkeIIaJRjioCtWqX3yHFHQ6ZAohGKI6AxCiOgEctM260w2geG\n2LGSusJndvnkdNLttAoYjHnFz6j6mhhXXwCtGI0OF0bj8eFvhkoPEiubPlfRrvQUzRZru9Ju\n2EvT5yyaFEbzCqJxxp33Js22q+v2ABua7kWa7i2aVxCNx830KM1uS69V2xRIrGXXC4x1zs8E\ntGgXCg29WDBQXRYkbRZi1FEg0ag+9DQZ6gcD1odepGl9aw+wpHmFiaJkX/W5QLpfkkclOTXJ\n8UkuS/KeJM9Pck6H7WINXfbYTA8JhIp82TXTw+6g3+TLIM2bwEEBNVR9naTh8UlekeTKJC9M\n8qwkL6nWvTHJoztq116bOipx7oeU6gjG1sPioHbBDPnSR+OZr3nqemaaKpwOas88eo/2nXzp\nvXmTLCw74cJksobpSRs2bYOii+Wdm+TONevuk+QDW9zWRUnetcXHG6Tx0e/m2jCZd9umipd1\n29VEW3rmgpQ9mBxNvvTNbHG0qCBZ5bZtt2l/yJd68qXX5n08WWZdW22Yd7u904t86esQu0Op\nD5Gzk9yyxbbsvVULinlD2proWVqnXdtuAztJvuyCXTqWZ1faSRvkS2/1udiYNwmDnqQu9XWI\n3UeTnDln+SjJk1LG8tJjM33Q3uT0iXzZZaM5X9Af8mVnzQ6fU6Dss772IJ2Z5JVJfi7JB5Nc\nnuSGSU6pfn5od03bPwdNctDVOYZMvsCa5MsumHf+I8UQ/SdfemveJAt9oRjrm74WSO9Mcock\nD0hycg7PAvPMJH+X5OrumrafZouRSRHUtwJFbxVLkC99MztDXd3JYdsadjfveCLFGcuRL6xI\ncdRHfS2QknIw48Nz9DSZX4xpMhs1rxBadJt569ooVOa1YXrby/we7C350rVFPUNdTniwzLb1\narGYfOmlg3qP2phNbpmTwE7fRvHUlb4eg2SazI7MFh2T633rKTpI3e8BkS/dmxEPkAAAACAA\nSURBVNcztCt2ue20Qb7snLrZ4roYjje7zb4OCRy+vvYg/UyS+yd535x1L0ryvOpyGfdO8rAF\n609I2btDDbPFMTDyhe3apRn3aJp86a0+H4OU9Ltt+6evBdI2p8m8fZK7L1h/nSTXXeHxWKDN\n4qit6cQZHPmyq9ooQmaPh2pruwyFfOm1roukeds3jI7lvTXJE+YsHyV5apKztrgtJ1qbUnfi\n1bqTv/Z16NqutLNBvTjRWk/Jl67NOwlr3Vff7EIbmydf6smX3qv9ONPSiWJXbdfe6UW+9LUH\nyTSZHZnXK7OouOhrj03drHsQ+dK9eb00dbfrm7oZ96CQL70324tT16vUds+O3qU+6WuBZJrM\nDs0WE3UFUt+Ljr63j87Ilz6YLix2rRdGUUQ9+bIT+lp49LVd+6evs9g9IGUGmDck+Z0klyT5\n3iQ/leRHOmwXPbPnw+hYj3xhMUPoWJ984QB7P4RuJ/S1QHrd1M8/l+SXUg5u/ECS30iZRpOG\n7ErRUXcepC7awk6RL31wUAHSVS/NvPYokliefNkJXRUpfZlOnF11xdTPH0rybVPX75Iyrndb\nHOQ4ZZmjFrtu40Tf29exXhzk2FPypWt9npihj23qH/lST77shK4mZzARwxJ6kS99PQZp2g2S\nvHfq+ruT3Kqjtuw9x/UwMPKlbxzfw3DIl15aVJA4Boiir0PsRklul3IStLcmue/Uugem7DVh\nILbZA6SAYwnypUtt9sas0wukQGMz8mVvrNMLNK8AU5T1UV97kC5Pcl4Of9i9PMmbkpyW5NVJ\nHtdNs4atL8PTxsl4mUJncptJuxVHLEm+dOWgIqXp4mSc8VLbmJ7KW8HEauRLr21rONsmjzM9\nnbfiqK/6WiAdSund+rokJ6bMCJMk56fMEPOOjtq115ooQLZRlCmMWJF86aNtFyKb9lQpjFiP\nfOmtg4qaTYuV8Xj5x1AY9V1fC6QkuSbJ56vviU9X37RIAcIAyZc+UYwwLPJlpyhWOFpfj0Gi\nJ5oujhRfsOeaKo4UXcARmi6EFFpDokDiWrPFSlvFS1fbBVo2W7Q0XcS0vT2g52aLmHWLmm09\nDn3V5yF2dGC2OJk+Rmh6Xd3ybW0XGKjpImX6OKHJ8tljhzYtahRFwBGmi5np45JWLXIURUOm\nB4lasxMoTK7XLQdY2mwhVDcVt5O0Ao2YnbTBCVs5TIEEAMAeUQyxmAKJufQKAQCwjxyDxBGm\nT7qqSAK2zpA5oDPTJ2jVi0Q9PUhca7ogmlccTSZSMOscsJZFxdGo+pq3HGAj4/GRBdG8k7qa\ndIHD9CCRpH5IXV3xoygCtma6CFIQAa2YVyRBoUCiN7Y9dThAkvnTiQNsxSZThdNXCqQ9MttL\ntEkRss3Hmvd442SsSIIdtOp5jOat3+a5kOZNJ65IgoGaPa5o3YJl2ceZN1W4ImkIHIO0xw7q\nsakrUNqavMEkEbBjDjqP0TKFSRvnQjJRBAzQvEkXpidlmLVs0bPK9hgKPUh7YpliY9MeJT0+\nwIH03gCd2KRnR8/QvlEgsdCyQ+maKI4UXDBw2xxKtwpFGrAxU4UPmSF2e2KdYmNer1NTw95M\nHQ4DsMo03XXD3LY91ffsfRVHMFCbDplb57FNFT5UepD2yPTJX6cLkFVnj5s9iey2ihlFEQzA\nKKNri59JMbLscUiTCRTmPcambQJYyqTIWXT80rzbMyQKpD01OWZo3uxxy9x/UTGz6DHqCrOD\nHhPYAbOF0CYTLiwzu13d7bsauge0oO1hbQdtT4E0RIbY7ZF1i6FpBxUxBz3mZH2bw/eAFsyb\nTntVB/UuLbP9NmbBAwbOsUX7ToHE0vTwAI3RywMcaJ3CpekeHsXUEBlix1IUR0AjFEYA9Iwe\npD0wLrs3Nj62qGmKMNhB4+prHasUR8veVsEFbGyVXifHIA2RAmngVjmuZ1KgTBcqo/LOX/rN\nv2i67unHmn1cxRHsoFUKo21Mtz19n9mfl10H7Ki2h7ItU/gojobKELsBW3XSg+kpwDcpWFY5\np5HCCPbEZArvTdUVQotuB+y4ro7zUQDtKz1IALTDbHJAqxQ4rEeBNGDr9s6YbhtojCIJWNk6\nhY7iiPUpkAZOkQQ0xjA2oDUKHtqjQBq4ukLHsT9AYw4qnPQiAWtZtkhSTLEZBRIAq1tU5BxU\nAOl5AqDHzGI3QKuc80gPE7CS6eJnUSE0ykhPEbCa2dnq5vUEjUbdzWrHvlAgDcwyxdGk+Jm9\nraII2JpJcTTpLdrWNN/AQM0resbjw0VSXfG0TFEFqzHEbs/UFUd1ywCutU6P0GyhBLCyuuIp\nObIgUhyxHXqQBmRRgdNU79D0yWWbeHygJw4aTnfQbTbZpuIK9tgyw+nWKYymH1dhxZEUSANx\nUO9PE71D04+pUIIBO6jwaaowmr6uSIKBa/PYotntTA/lA0PsmLJKcWM4HrCUbRU2JnwAjqCg\noTl6kPaY3h7gQOsWJnp8gMY0URzpReIwPUgA1FPoAL3TxFA8xRGHKZB2yLgkwrXfXbZlXu+T\nHinYceOpry7NK8oUajAg0x9nppet+hjrUgyxmCF2O2ycjCdFyaKTvjZFQQQDsmhihFVP+rqN\nYkZBBAM1b4KELiiSqKdA2hF1xU/XPUnAACwqfrruTQKAlhlit6f0/gAHWqc40vMD1Npmb5Ee\nIJqjB2kHbKOXSEEEzLWNHiJFEXAgxRG7Qw9SzxlCBzTG8DmgFYojdosCCQCAHaA4oh0KpJ4z\nNA5ojKFxQCs2KWxGo8Pf0A7HIPXUNofWKbKAIxhaB7Siqym8YTMKpIFTHAFH2HZxpBcKmGvT\n4kiPEd1RIPXQpr1HiiKgMQoioDGKIvpBgdQT2xpSpzgC5jKdN9CY2d4ihQ67zSQNPaA4Ahrl\nmCOgMfOG0o3HqxdJiir6Q4HUYwoeAGA3maCB3aVA6rFVepYUU8Bc2+o9MrwOaIzeI/rFMUg7\nSkEENEYxBLRCYUQ/6UHq2DbPdwQA0B7D6BgmPUgt20ZBpPcImGt6ON0oI5MzANu3raJI7xH9\npUBqwTZ7iRRHwBHqiqB1iyPD64CjbLunSHFEvymQdoTCCDiKcxsBO0VhxG5QIDVsk94jRRFQ\nS3EEtGKV3qPRaP7tFUbsFgVSg1YtjhREwFJWLY4UQsBKVh1SN10AKYbYfWaxa4jZ6YBGmHgB\naNQmxREMgwKpAesUR3qPgEboPQIaozhimAyx2yJD6oBGGFIHNEqvEUxTINWYLnamCxlD54CN\nNX2+onHGiiTYV9PFznQhs82pusdjRRJD1ucC6X5JHpXk1CTHJ7ksyXuSPD/JOU1ueLYIGifj\nUTLqQ3FUV7gBK+ksX44qhvpyTNFs0Qasq7t8OaoImhQy2z6P0SbqCjjoj74eg/T4JK9IcmWS\nFyZ5VpKXVOvemOTRbTeob8XRvOvAUnqXL1u3aoHT16INdk8P86WJ4mjdwmZeAQf909cepJ9J\ncv8k75uz7kVJnlddLuN+SU5fsP6EJF9epXHbsGrvj2IItmbY+bKt3h/D9GAdw86XJHp92Ad9\nLZAOJflAzbqzk9xyhce6SZI7LFh/ZZJLDnqQTYbYGQoHvdK7fFmbAgb6pof5su4QO4UQ9M1b\nkzxhzvJRkqcmOWuL23p5kt+eXTguaTKeN6ztoO8ttq22TU1vi513QcoYeI7Web5kPPU1e33e\nV9O62Ca7TL7U6z5fjviYULd83ncbutouO6QX+dLXHqQzk7wyyc8l+WCSy5PcMMkp1c8PbboB\ndb0+XfYGzfZi6ZmCtXSeL0f1/HTdEzQ7k17X7YHd1X2+1Pb89KFHaLY3qw9tgqP1tUB6Z0q3\n8gOSnJzDs8A8M8nfJbm6u6Z1S1EEG5Mv8yiKYBvky4EURfRfXwukpIytfUP1DbBN8gVoinyB\nHdfXab4BAABap0ACAACoKJAAAAAqCiQAAIBKnydpaNOdkzx2jfvdL8kNknxlu81Z2ijJbVPm\njO/qXALXT/J1ST7V0faT5KQkX02ZKagrt0nyyXQ3Q9F1U97Pf1VdP76jdnC0VfLlXyX5bJJr\nmmvOXDdIcuMkn255u0lyiyRfSHJFy9s9NsmtklzY8naTcjLRccrv3bZbp0xD/dUNHkO+9Mcy\n+fLNSU5N8rnmm5Okm88mJ6b8//1iS9vrIj9unuRLKdPFt+G6KScrvril7SXlOb1xi9urpUBK\nzkny4ykncFvV7VOCoKsPxaOUv+FV6a5AOqb6vqqj7SflORjH3+GYJHetrn8myUc6aguHrZIv\nxyT5hnTzOuryfXxcSkHYdlF4TMqHnCtb3m6q7SbtZ9Ykq741m+3Yky/9sGy+3DJlJ0hb7+8u\n/ie2/Tmgi/xoOyu7+L9wnZQddfJlx70lyS90uP1bpgTCyR224SdTTobXpdennGOiKzdM+Tvc\ns8M2PDLd7Alne26c8jq6ewfb/tmU87d04QNJHtfBdu+b8nwfe9ANG/CHSZ7XwXavl/I736eD\nbdOdX03yly1u79Ypr7NvaXGbf5rkd1vc3nem/I5tdjSck+RJLW7vR5Oc3+L2kuSSJD/Q8jbn\ncgwSAABARYEEAABQUSABAABUFEgAAAAVBRIAAEBFgQQAAFDpYnrTIbl1krcn+VhH278qyZ2S\nvCSbnfRvE8elFNp/3dH2k3Kiyfck+XBH2786Zar1P07y5Y7acEzKeS5e19H22dzkdfTStH/y\n6eum5MnftrzdJLldtd22p6m/OuVUCS9rebtJOfnieUne3fJ2r0n5n/En6fbE2rTrRinTJ7+t\npe1dlTLFd5ufTW6acu6c97W0vatTTmraZn58fcrpZc5raXvHpJwa4PUtbS9J7pDk1SknTAcA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhXj0lyaZKnzSy/W5K3JPlsknOT\nPK6h7d8zyZuTXJLkwiRPb7kN35XknCSfT/LxJD/f8vanXT/JB5O8rIM2fCHJV5NcMfX9gBbb\ncOMkL0x5HXw2ye8kObbF7bM9XWRKlznSdYZ0kRtd5oWs2E9t50rbmdJVjrSZH23nRttZ8QM5\n8ne7IsmVSf6swW3SkGen/OHOypGhc50kn0jyxCTHJPm2lD/ofbe8/ROSfC7JTyQZJTm52s4P\nttSGWyT5cpKHVtdPSXkjPbil7c/6rSQfy+GgaqsNxyS5Jsnt5qxrqw0vSvLSJMen/F3+JuUf\nRhd/B9bXRaZ0mSN9yJC2c6PrvJAV+6ftXGk7U7rMkbbyo4vc6DorjkkpiB7a4jbZktOqy1fm\nyND57pQ9JtN+M8lzt7z9myb5NzPLXpXkP7TUhlsl+aGZZX+Tsuemredg4gFJ3pvkSTkcVG21\n4cQk45R/CrPaaMOhlL1Kt+po+2xPF5nSZY50nSFd5EaXeSEr9lPbudJ2pnSVI23mR9u50Yes\n+Okkf97yNhc6ps2N7biza5afnNLlOu3DSU7d8vY/m+T5U9dvluTeKcHQRhs+meRPq5+PSfI9\nSe6S5HUtbX/ihCT/M8kZKW/oibbacGJ1+Zwk5yV5f5Kn5PCes6bb8O0pr4VHJ/lQ9fj/KeVv\n0ubfgc11kSld5kiXGdJVbnSZF7JiP7WdK21nShc50nZ+tJ0bXWfFoZSC+snV9V7k03Ftbmyg\njk9y+cyyr1TLm3KzJK9O8t+TvC1lz0ZbbXhISpX/5ZSK/91JTm9x+7+d5MVJ3pnkPlPL2/o7\nXJnkBdX3o5LcNclrUsYLt9GGE5PcPCUovzXJNyb56yQXt7R9mtfW37GrHOkiQ7rKjS7zQlYw\nrY2/eZuZ0maOtJ0fbedG11nx5CSvSPKP1fVe5JMCaXOXJbnhzLIbVcubcJckL0/Zs/AbHbTh\n1UmuW7XjpUlu0OL2vz9lT8dj56xrqw0XJPmxqev/kLJn6aFJXt9CGy5N6Xr/9ZQxyv+YEqLf\nl7LHrs3XIs1o47XcZY60nSFd5kaXeSErmNb0a73tTGkrR7rIj7Zzo8usODbJj6ccQzbR9ufq\nuQyx29z7Uw4SHE0tu3OS9zSwrbsl+cskT8jhAGqrDd+a5F9VP1+T8oZ9aUp4tPUc/OuUMbIf\nTel2/uWUN/D7W2zDzXN4jPfEdZJ8raU2/GPKjo3pscmjJFe1tH2a1/Tfsasc6SpDusyNLvNC\nVjCtyb95m5nSdo50kR9t50aXWXH/lN/rnKll8mlHzR74eFzKFIRPSqmET0uZevIeW97uDVJe\nxA+as66NNtwrpYvzu6rrt0rpbn5GS9uf58wcPliyrTbcK6VL/37V9W9LGRP9yBbb8NqUvXTX\nSXLblNfFY1rcPtvVZqZ0mSN9yZA2c6PrvJAV+6utXGk7U7rOkTbyo4vc6CornppSXE+TTztm\nMk/71SnjQ69IGTOZlMr2TSl/wA8n+dEGtv/wlC7Q2XnjX9JiGx6Z5CNJvpTyZn1OSji2tf1Z\n00HVZhseUz3+pSnPx0+33IYTU/75XZrk/JRzTkz2tHTxd2A9XWRK1znShwxpOze6zAtZsX/a\nzpUuMqXLHGkrP9rOja6y4veS/K85y+UTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwpz6b5GEtbu8RSW5e\n/XzTJOPqss5jklya5GlLPPa9k3wwyaFNGjjl/0/yP7b0WLCP+pwv90zy5iSXJLkwydMPeGz5\nAv3S53z5riTnJPl8ko8n+fkDHlu+QM+0HTAfTHLn6ueDAubZSf4syVk5uEA6PskFSe6zeROv\ndVySd6WEIrC6vubLCUk+l+QnkoySnJzS1h+seVz5Av3T13y5RZIvJ3lodf2UlB0xD655XPkC\nPbQoYO6R5E1JPpzkH5P8u2r51ye5Jsmjk7wyybury+tV6x9V3ecjSX4/ycuSPKW6HCf5WJIf\ny+GAeVSS9yX5THWbG1SPc1p1+cocXCD9fJJXT12/X0o4fCrJ/03ywJm2/9skr0pyfsqe45+s\nrp+b5MlTj/Ow6vc45oDtA0fra77cNMm/mWnPq5L8h5q2yhfon77my62S/NBMe/4m9b1I8gV6\nqC5gDiW5OCVEkuTWST6Z8ka9WUow/GK17tiUN+G/TgmGryX5Z9W6f53kihx+045z9B6Y364e\n44Qkn0jyyJm2LFMgvbfa1qTtX0hyenX9QUm+VD3+pO1nVuvukeTqJE+qrt8lyVeTXLe6flyS\nL6YMxwFWswv5kmqbn04Z5jKPfIH+2YV8OSbJ91RtvUvN7yFfoIfqAuZHUgJl2m8keW4OB8Md\npta9OskvpLzJPzhzv49kccB889RtX1M9zrSDCqQTqse5XXX9ESl7UqbdPCWoJtu8zcx9v6m6\nfr3q+m2n7vvGJD+zYPvAfLuQLzdL8rYk/7nmd5Av0E99z5eHJLkqpeA5o+Z3kC877LiuG0An\nTkxykyTnTS27XspBzRNfnPr56pS9KCeljO2f9okDtvX5qZ+vqh5nFbeoLi+uLm86pw2fnrl+\nWXV5zcz1q6vL6TZcnOSWK7YJqNeXfLlLkpcneU7KB6h55Avslr7ky6tTenPukuSlKcPvnjNz\nf/mywxRI++nClPGt3zJn3aJZ5y7N0bOwfP22GlVjNHP9Uyld5dNOyZFhuarxBvcFjtSHfLlb\nygeYf5fkLxfcTr7Abuk6X741JRNenlLE/ENKgfT9ObpAki87zMFd++mslKCYzMJyvZRZ5R5Y\nd4fK36fMCHW36vrDc7jrOEmuTNmzs02TPS+TvSR/ndL1/MPV9e9KcnYOH4S5qlumhBawHWel\n23y5QcoMmY/N4uIokS+wa85Kt/ly4yQvSsmGpBQ8358y4cIs+bLDFEjD9/KUruHJ94UpBwU+\nOGX2lnOTvD+l2/bvD3isjyX52SSvSDnw8LSUsJrswXhJktfl4HOOJOXgyCtSxvH+p+rnV8y5\n3RdTZpH5jqnrD0o5bumzSX4ryQ+k7B1a1XEpBzge9HsD8/UxXx6UcgzCy3M4Z66o7j9LvkB/\n9TFf3p7SM/2cqi3/N8k7kvzKnNvKF9gjs0X1W1KmxWzSL6RM5rBtD4lpMqFP5AvQFPkCNOL6\nKecDmMwsc7cklye5U8PbPT5lz9E9tviYxyZ5Zw53dQPdki9AU+QL0KgHJflAykGSH0ryoy1t\n9z4pXelft6XH+9WUaUGB/pAvQFPkCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAMDiXJhkn+ZE56y6u1p2xwuNdWN3ne1dsx7r3a8vHU9r3UzPLz6uWXzCz/Ber5e9eYRtD\nfe7Yb5u+d5Z5ff+v6ja/e0Bb+vRekSkAHOiYrhvAVrw+yV8k+VRDj/+NKf+4f7Khx6/z5ury\ntKllN0ty++rn2yS59dS6u83cbxlDfe7Yb5u+d9Z9X/T99S5TADiQAmkYfjzJw5L8Q0OP/8MN\nPe5BJh9K7jG17F7V5VdmrifrfZgZ6nPHftv0vbPu+6Lvr3eZAsCBFEj9d2zKMI/3p/wDPzfJ\n42ZuMzs046Qkf5rkspS9mL+U5Jer2zx3zjaOSfI7KUP/LknytKl170ryX6ufn5Pkqjn3f0v1\n2E+fWf7n1fLfrK5/fZI/SPKJJFck+ViSZyS5zpzHTA5/KLlTkhtVP08+vLx65vqhlD2r0/fb\nhecOmrDpe2f2fXFikj9OeV9cnPI6H89s86DX+6L3yiyZIlMA2DOrHIP07Or6uUn+S5IPzqxP\njv6H/LLq+heS/FGSjyb5x2rZ7825318nOb/axrj6fkh1m59JGZc/TvLGJP9tTpufWK0/e2rZ\n9ZJ8qVp+72rZ26rrf5HkN5K8Y06bpo2SfK66zf2qZX9VXT+9uvzbavkDq+vnT91/F547aMKm\n753Z98VLquufSflg/v4k/5Qjj0Gqe70v816ZJVNkCgB7ZlIgLfo+I8ktUvYQjnN4qMc3Jbkm\n5Z/nxPQ/5JtP3ecHqvWHprb5u3Pu9/dJrpvkuCTnVMv++9TtzsriMe+3qdp0TbX9VG0Zpxz8\nnCQ3rq5fVm0nSY5P8swsnpDi1dX9fjblw80lKUXksdVjfSllj+tTqtu9uLrfrjx30JR13zvJ\nke+Lmyb52tT1pLyfL8nR74uzcvTrfdn3yjSZIlMAOmOIXb+dlvJP+2spe25vkzKM5FNJ7pjy\nD3vWydV9xkleUy27NGUvaZ3nVdu4KuUA4yS51QrtvDBlT+4oyfdVyyZ7PP+kuvxSkotSPsC8\nN8mvJ3lAyl7YFyx47OljBu6YMtTn7UmuTvLOlGEyp+boYwV25bmDpqz73pl1SsqQtWtSei2S\n8n5e9L6YZ5X3ikyRKQCdUSB16/9L+QAw/T0989Gh6vK6KWPsL6i+b1ktn/dP86Tq8ktJrpxa\nfsmCdnxy6ufLqstjD2j7rD+tLk+vLh9cXf7x1G0enuQDKR8anpSyJ/cTKQc015n+MDM5sPod\nM5d3TXLPmdvv0nMHTVj3vTPrptXlZSlFxMSlK7Zn1feKTJEpAJ047uCb0KHJB5CvZP7MRbPn\n7Ji+z41S/r6Tg3hPmnPbidmDrdfxsiTPSvLdSe6e5HYpY+2nZ3J6W8qe2Tsl+edJfjDJ96Qc\n33CzJF+e87hnp+yl/abqPsnhDzFvry6/I8kdUn7391fLdum5gyas+96Z9fnqcvZ9cdP5N6+1\n6ntFpgDQCT1I/XZ2yh7bG6Yc1PualAN4b1Kt/8Kc+3w4ZSjMMUkeVC27ScqHhnVN/mHfaMFt\nJkNiDqUcA5Acuaf3jimzNz2mauNzU8bofzrJDZKcUPO4X0sZhz9K8kM58sDtyYeZR1SXb0n5\n3ZPdeu6gCeu+d2Z9KOW9dEwOD3e7aeaf0HSbr3eZMp9MAWiYAqnfPpVytvokeUPKjEf/J8kf\nJvmJzJ/i9Z+SvLb6+UVJXpryj33RkI6DXFRdPqlqz41rbjcZEvPd1eWfTK37cpKnVvd/fsoH\nnlemHMR8do4cVjJrMsTlJil7kCd7ZS+o7neTmdslu/fcQRPWee/MujiHj595YcrxPW9LKUSS\nUmhMbPv1LlOOJlMAGqZA6r8zUw46vibJY1OGmfxG5k8RPvHYJK9LObD6fil7Vv+mWndl3Z0W\n+LWUvcgnpRwEPaq53WQ62yR5X44csnNxkvun7HF9WMo/97umTBn84Cz2pqmf3zGz7u1TP89+\nyNul5w6asO57Z9ZPpLwvrp/kX6Z8MJ8UL9ebut22X+8y5WgyBQDW8O0pQzhuPrVscn6QMztp\n0e7w3AHbJFMAoAdem/LP9yMpJzZ8fXX94zEc4yCeO2CbZAoA9MAJKf+Iz0+Zrem8lHHyt++w\nTbvCcwdsk0wBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2K5R1w3ogUcneUjXjYAtuybJ05N8qON2\n7Dv5whDJF2DQjuu6AT3wsCTfkuQtXTcEtuiRSV4TH2C6Jl8YIvkCDJoCqfjfSX6660bAFp3e\ndQO4lnxhaOQLMGjHdN0AAACAvlAgAQAAVBRIAAAAFQUSAABARYEEAABQMYsdnXnBN1w6nvx8\nxnmHnJMLYEvGL861+Tp6pHMeAqxCDxKdmC6O5l0HYD3TxdG86wAspkACgIFQDAFsToEEAABQ\nUSABwEA43ghgcwokOjE7KYNJGgC2Y7ZIUjQBrMYsdnRGUQTQDEURwPr0IAEAAFT0ILE1zmsE\nUMzOJqdHB2B36EFiK5zXCKAw1TbAblMgAUDDFE0Au0OBBAANM8QOYHf0AXN5KgAAIABJREFU\n+Rik+yV5VJJTkxyf5LIk70ny/CTndNguYPfJFwBgrr72ID0+ySuSXJnkhUmeleQl1bo3Jnl0\nR+2ihvMasUPkC41yHiIAmnBukjvXrLtPkg9scVsvT/LbW3w86IMLUnpIOJp8gc3IF2DQ+tqD\ndCj1H1LOTnLLFtsCDIt8AQBq9fUYpI8mOTPJs2eWj5I8KeVYAXpk3rTehtnRU/KFRs2bsc4w\nO4Dd0dcC6cwkr0zyc0k+mOTyJDdMckr180O7axqw4+QLAFCrrwXSO5PcIckDkpycw7NMPTPJ\n3yW5urumsawXfMOlY71I9JB8oXXjF2esFwlgN/S1QErKwdIPz9HT8H4xpuHdCYojeky+0CrF\nEcDu6OskDabhBZoiXwCAnWMaXtiMaXjryRfYjHwBBq2vPUim4QWaIl8AgFp9LZAm0/DOMg0v\nsCn5AgDU6uskDabhBZoiXwCAWn0tkLY5De+pSR68YP1d0t/nAdg++QIA1OrrP+4HJPnbJG9I\nmVXqsUm+P8kDk9wqyYtXeKx7J3nEgvW3S3+fB2D75AsAsHOumPr5qUkuTPL0JM9IcnHKNL3b\nclGSd23x8aAPzDJVT77AZuQLQAemP8B8KMm3TV2/S8pxA9viAwxD5ANMPfkCm5EvwKD1dRa7\naTdI8t6p6+9OGQYDsCn5AgAcoa8F0ihl7P4JSd6a5L5T6x6YslcWYB3yBQCo1deDhy9Pcl7K\nB5nJ9TclOS3Jq5M8rptmAQMgXwCAWn0tkA6l9G59XZITk1xZLT8/ZQaqd3TULmD3yRcAoFZf\nh9glyTVJPp/kYykHhCbJp1M+vLyiq0YBgyBfAIC5+lwgLXJ61w0ABku+AMAe6+sQu6cdsP7Y\nVloBDJF8AQBq9bVAenLKuUMurVm/qz1fQPfkCwBQq68F0hOTPCjJI2rWX1GzHOAg8gUAqNXX\nPaUvSPLJlGl3AbbpBZEvAECNvvYgJckTFqy7fmutAIZIvgAAc/W1BwkAAKB1CiQAAICKAgkA\nAKCiQAIAAKgokAAAACoKJAAAgIoCCQAAoKJAAgAAqCiQAAAAKgokAACAigIJAACgokACAACo\nKJAAAAAqCiQAAICKAgkAAKCiQAIAAKgokAAAACoKJAAAgIoCCQAAoKJAAgAAqCiQAAAAKgok\nAACAynFdN4D984JvuHQ8ff2M8w6NumoLQN+NX5zx7LLRIyM3ARqiB4lWzRZHdcsAAKALCiQA\nAICKAgkAAKCiQKJVjjcCAKDPTNJA684479BoctyRgglgscmEDOMXZ2xyBoDmKZDohMIIYDWK\nI4B2GGIHAABQUSABAABUFEgAAAAVBRIAAEBFgQQAAFBRIAEAAFQUSAAAABUFEgAAQEWBBAAA\nUFEgAQAAVBRIAAAAFQUSAABARYEEAABQUSABAABUFEgAAAAVBRIAAEDluK4bAOt6wTdcOq5b\nd8Z5h0ZttgVg28YvzhEZN3pkDsy1de4DwJH0ILGTFhVHy6wH6LPZQqdu2ab3AeBoCiQAAICK\nAgkAAKDS52OQ7pfkUUlOTXJ8ksuSvCfJ85Oc02G76IEzzjs0cgwSG5Av7Jx1jidyDBLA6vra\ng/T4JK9IcmWSF+b/tXfn0ZaV9Z3Gn1tVKAjBWzIIURBY3S1oOQRBRWWUtCBGSASNFkjhkEFL\nAgLatHSLvRzSnZhO6KVJMGpFLBSxaWQILWVWQEHSAgmBAmRQC7BkKqAAkaGA23+8e3t37dr7\nnH3O2fvs6fmsdda9Z3rPe8+t+9b+nvd9fxv+Ajg7um8VcExN/VKDJENQ3vdSBscXNd7MUmaS\n4aZI0BnnOZKk9rgdWJJz3z7ATSW+1lrguhLbk5rgLsIMiTbl+CJNxvFFUqc1dQZplvyDlKuB\nHabYF0nd4vgiSZJyNTUg3QYsz7h9BjiJsFdAksbh+CJJknI1tUjDcuB84GPAzcDjwPOAPaLv\nD6+va5JazvFFkiTlampAuhbYDTgQ2J35KlOfBS4Hnqmva5JazvFFkiTlampAgrBZ+kg2LcP7\nCJbhlTQZxxdJkpSpqXuQLMMrqSqOL5IkKVdTZ5BOBA4AVmfcdxbw5eireip9kljPfaQROL6o\n0+ZWstH46PmQJGk0TZ1BsgyvcqXDkTQixxd1Vjoc5d0mScrX1BmkuAzvGanbLcPbU8NC0Ypd\n1s/1bRYpfk/69nOXwPFFjZAVXMaZ7SkSgOZWMjdK23Gbzj5J6qNhA98CYC/gjcALo8ffA1xJ\n2Mj8bEX9eg2hDO8M+WV4byzptdYC9wOvLqk9lWyUGaO+hIUCSwzvAk4Fvj61To3O8UW9NSjU\njBNkRjGs/QJL9NowvkjS2AbNIB0FfIZw4PIjwoELwJ7Ap6LrnwDOraBfZZbh3RP47QH3bwU8\nOl431TR9mEnKCowt/LkdX6QGylui50ySpD7JC0h/C+wNnAJcDDyd8bzDgE8CBwN/WEHfyirD\n+3LCwVieLYDNx+yjKuZ+o05yfJEqNLOUGfcdSdL48gLSesIBTN4nqU8D3wEuAj5XQb8+TPgU\n+RxCGd7HCZ/ELiGU4T2e4lWmzhry2LWEn1cNtGzN7IwhKejQ++D4Ig1Qxv4fQ5IkjW/Y4HsK\nZA6wc8CDhL0Ct5bdKeB24Aiyy/DuQyjD+7KSXss9Ai2QDAeDQlPLlpkVNiwctXQPkuOLeq1I\ngCkSkpLtpB8/Tslv9yBJ6rthA+W3gbcBdxAGxBcBOwOXAYuB3wI+AKwsuV/rgO3J3qS9CLgP\neEFJr+UBjBpvjEDYhgMYxxcpIS8wNXD/TxvGF0ka27DzIN0HLANeStgLsAdwHOGT1zcA+wKn\nVdCvuAxvmmV41Qsrdlk/F1/q7kuFHF/UG3MrmYsvdfdFkjTYsE+lfkyo8pS2mrBeH2ANsEt5\nXQIsw9tYBcpLa0TjhqAh730bPuF1fFFnjbN8rqzzIk1BG8YXSRrbsBmkhYQ1+UmvIWxohrCO\n/5GyO8V8Gd73ARcCVxE2bR9D+LS5rIMXjSCvvHQdfemKou9fOgx1JJg6vqjXhu31aWg4kqTO\nG3QeJIBPA98nbGp+AJglfOL7UUK4OhM4tqK+bQAujS5p5wG/V9HrSo3UkVCU5PiiTppkGZ2h\nSJLqlxeQZgmlaf+eUPb2AGCb6LYrgJ9Fj9uZes7x8dYaXlNSORxfJElSY+UFpB8SNk//CPgF\ncHbO414FfJXySuLGhm3MXljy66mArPLaHZzVmKq89zRd1jz+viPvv+OLOq3oOYiyZovGKcst\nSSpXXkB6H6EE73XANwmf6t4T3bcD8Cbg9wkbj99ZQb9Ojl477wSLw/ZOqSLJg/eWHpw3Tvo9\nzduXlLcHrIW/B8cXdd6wkFQkHMW3GZIkabryAtI/Eyo6fYRQqWZJ6v7VhHOTvBt4rIJ+nQAc\nBhyVc/8TFbymCmrhAXnjxe9ph0LQII4v6oU42FjaW5LaZVCRhseAP40uWxM+2Z0D7qWaylJJ\nK4A9gb2Bqyt+LUnT5/iiXjAcSVL7DKtiF3uE6g9a0o4fcF8dG7dVkaxZk7ylZh2bSRlJh/eA\nOb6os4ruR8p77KDldXmPbdH5lCSpkVxrLzVIVuBJ3pb3vaRuSAaZUcJR3m2SpNEVnUGSpqrP\nJ6AdFnwMRlK7jDp7U8Vsj8UeJKk4Z5DUSIYASSqP4UiSihsWkI7Luf30kvshqX8cX6QxZQUe\nQ5AkVWt7Qundn0Zfk5f9qab0bl3WEs6JInXJXcDRdXcih+OL1G5NHl8kaWJ5e5D2B/4bsCtw\nQ+q+DeSf+V6ShnF8kSRJjZUXkM6NLt8Gjpxed6RsyaINbd2fFP8Mbe1/iRxf1BtxZbkyl78l\nq9W5rE6Syjesit17CdPoOwELU/d9upIeSSnpinYrdlk/16aQ0fb+V8jxRZ2VLrldVhW5qtqV\nJM0bFpDOJpxx/nrg6eq7I/WjxLchCXB8Uc80JcyMcjJaSeqjYQFpX8I+gWmf5V491YdwpF9z\nfJGmLO8Es4YkSZo3rMz33XSropSk5nB8kSRJjZM3g7Rt9PV/AH8OfBF4KPWYdVV1Sv0zyszR\nsjWzM+nHN3m5Wtv6OwWOL+q8maXMFF3KNsmSt/ixLpuTpPLkBaT7U9dPyHiMg69KMSwcFQkT\nTd/T0+S+1cDxRb1QJKSMuuStaPAZZdmcYUqSNpYXkLabai+kHFnBwn1Kref4IpUoK2TlSc84\nGY4kaVN5ASle3nIKZA68c8CDwJXArRX0Sz0XB6MunP9Im3B8kWpmMJKkfMOq2L0OeBtwB3AX\n8CJgZ+AyYDFh78AHgJXVdVF9lXf+oKw9PWolxxf12igzP4Nk7XeSJI1vWBW7+4BlwEuBg4E9\ngOOA1cAbCGV6T6uwf+qB9MzQoJmiOBiN8hw1luOLlGGc2Z30c5whkqTxDZtBOgj4UOq2bwH/\nFfg4cA2wRQX9Us+ME3AMRa3n+CKVyFAkSeUYNoO0ENgnddtrgK2i74/AkzxqigxFneL4IqUY\nciSpfsNmkD4NfB+4HXgAmAV2Bz5KCFdnAsdW2UFVq8nn50nvNWpS31QKxxc1StY+nioDS3rv\nkOFIkpphWED6e2AVcACwDbAeuAL4WXT/zsATVXVO1coqdNC08wk1qS8qneOLes9QJEnNkxeQ\ntgIeA7YkLHG5IOP+X+LBi6TROb6ocawCJ0mK5QWkR4EdgbsHPNdPvSSNw/FFjWOpbElSLC8g\n7UQowbvTFPuiKcs6n5BL2jQFji+SJKnVDiZslj43un4Q8Jz6ulO6tcB1dXdCKtldwNF1d6IA\nxxepfdoyvkjSWIaV+f4Q8DXCkpg3RbcdAfx5lZ2S1AuOL5IkqXGGVbE7BdgL+AXwjsRtNwLH\nV9gvqZWyKgO6bDGX44s6ZdplwiVJ1Rg2g/Qk4eAlfZsDvqRJOb6o1eZWMhdfBj1mmn2SJE1u\nWEBaByxN3fYOBlefkpSwYpf1c1kzS3J8UXulg49BSJK6Y9gSu5MI5yj5M8KJHG8lnO3+sIr7\npY6LT0gbB4cmLkNLhpom9q8DHF9Uu3SwyVsSN7eSuUmWy43y/LhPLs+TpHrkDb6/DVwOPEU4\nYDkEWEyoyPRPhE3VXbEWuB94dd0d6YNBMylNCiHj7CUaNks05Z/vLuBU4OtTfM2iHF/UCINm\nfeJwkrevaJIZo0EhrOhja9bk8UWSJpY3g3QBsAG4FLgIuJjwn7zUeXlBJ571mnZ/OsjxRbWr\nYklc0eA0ygzRpDNXkqTR5e1BegHwLsKnn6cC9wBXAf8ZeOV0uqauGTbD0pZ9Oul+FtljZLDa\niOOLGm9Y8YW80DKzlJn4UuQ1yuiLJKlceTNIjwOXRBeAXQnLYN4MnBDd/5LKeyc1SHLPVNEw\nZzDK5PiiThhlqZwkqT2GVbGLPRFdnowuz1bWI6lmeaGmLTNcLeT4oqkbd9nasOdVsTepjLYl\nScXlzSBtBryR8KnuIYRPeC8j7Bk4HbhtCn1TxyRnYJouKySN0ndnjgZyfFEjJANJXviocv9P\nVtvDikNU1RdJ0ry8GaQHgG8ATwPLCSV4Dwe+gAcvmsCg4NCVUNGVn6NCji9qnLLCx7C9SWW/\nniSpfHkD9GnAocArgP8HfDe63DClfk2TZXhrlp6ZqStgFDnvUV5fG3g+pyaX4XV8UaMNqhyX\nnNlJP6aKWaiGVrFr8vgiSRMbNujOEs5ZEi+FgfmDmXMq7Nc0eQBTs3HOOdTFPpSsDQcwji9q\nlUHL3nq2JK4N44skjW1YkYb1wLnA+4EXEypM7Ql8s+J+SVPTln1RHeT4otazBLckdU9ekYbY\nYsInvIcSPuGdJWym/lK13ZLUA44vkiSpcfIC0mmEA5bXA/cC/wD8EbAK+NV0uiZNR5uq63WE\n44s6Y9ASO0lSO+UFpLcDFwN/AvwLOPCrOumAUsfen6J96OBepTo4vqhR0uFmUCW6vCINg+6T\nJLVLXkB67VR7od5rQshoQh96wvFFtRs04zOoctyg4GMokqRuGFakQdIQLs+T2sXlcJKkQYYV\naZB6qynnZ5JUn6LL7yRJ3eEMkpQha1bImSKpHwYVXnD2SZK6z4AkSVLEGSJJkgFJmpBL76R2\nGacAgySpPwxIUoaiocdwJHWXgUmS+skiDbIYQY5hJ5D1fZKabVCBhSLnLXK/kST1kzNIPWcx\ngvEYjqT2yQpM8aWuPkmSmscZJFWuazNUbe+/1AdNnP3J6pPhTJKap8kzSPsBZwJXAtcBVwBf\nBPaqs1MajTNUaijHl44rI3hktWGgkaTua+oM0oeBTwHnAF8DHge2ApYAq4DjgbNq613HTWOG\nJBmSmjwjE/dtxS7r55rcT43E8UUM239U5L5xX2+cfkiSpqepAelE4ABgdcZ9ZwFfxgOYzmhD\n+Gh6/zQSx5eeyCvEkA4rcyuZqzqcpPuSZRr9kCQN19QldrPATTn3XQ3sMMW+9E6ZS+CKBguX\n3WmKHF96xEIMkqRRNXUG6TZgOXBG6vYZ4CTg+qn3SGNLhyTDkGrm+KJapENaEwtJSJKaG5CW\nA+cDHwNuJuwReB6wR/T94fV1rfvKWk42yj4jl7BpihxfVAn3E0lSNzR5AN8MOBDYHdgS+CVw\nI3A58EyJr7MWuB94dYltNkLWTE1WEKmiYMKw125LkYYWuws4Ffh63R1pKMeXFiujXHbZYWbc\nPrU0VDm+SOq0ps4gAewDHAm8nPkDmOuBR4BrauxX50wroCSLMdQVitLBrGiIVOc4vrTUKMvS\n8h6btScpfuy0Q0qLQpEk9UZTizR8GDgP2EAow/sXwNnRfauAY2rqV+v1ef9P+mfPey/6/B71\nhONLSw0KR1mV6cZ57NxK5twbJEn91tQZpDLL8L4eOGLA/VsTPj3ujbrKatc5M2PoUYLjSwcl\nZ2LKmGWSJPVXUwNSmWV4XwK8ZsD9mwHPGaE9FZBevuayNTWI44tKl3fOJUlS+zQ1IJVZhvec\n6JJnLfDwSL1ribr32DQpFOW9F+olx5cOGTeIVDFzZCiSpG5o6h6k5cApwM8JewIuAL4XXf8g\nYQ+BCmhSSGmavPfG96zzHF9aKh1A8gLJpEHFoCNJ/dbUGaRrgd3YtAzvZym/DG/necAfeMJa\nRRxfWqxoeMl73KDKdpP0S5LUHU0NSAcC/wRcSviE9w+AtwMHATsCK+vrWrulQ4HhST3k+NJS\n7vGRJE1DUwPSJcDm0fcfAz4C/B1hw/PnCZusv1BP19ora8akrop20+ZskRIcX1ooqzT3sJBU\ndJ+RYUuSlNTUgJR0HHAocEN0/VvAN/EARgWNEo76EBa1EceXFhinoILhSJI0rqYWaUjagvmD\nF4B/IyyDkUplOOolx5cWqCLEzCxlxnAkScrS1BmkGWBnYD1wFbAv8IPovoMIpXNVgjaHgjLP\ns9Tm90Ejc3zpmHH2JrmfSZKUp6kzSI8DawjnD3kX8L7o9r2BC4H/Xk+3uqete3PS/W7rz6Fa\nOL60UF6J76y9SaO2XcU5kSRJ7dXUGaRZQnh7PrAY2BDdfgehAtWPauqXGmDUMJQ+SWzW9TL7\np8ZzfGmpUWZ68gLUzFJmsgJRkaIPkqR+aGpAAngWeCi6xO6LLuqxdMAp+pxB19U7ji89Mel5\nkyRJ/dPUJXaqQFYoMChIkiRJ8wxIPZMMRG0OR84ISYL8vUllP0eS1B9NXmKnilQRJurY0xO/\nzopd1s/Fr29QkvonGXCKVqfLus/KdpIkcAZJJaizopzV7CTFJqloV0Y1PElSNxiQJEmtV0Wg\nMSRJUj8ZkCRJkiQp4h4kSVLrTGO/kPuQJKmfnEHSxOqsKJf1Wu5Dkrota79QVpgZ58Sy4zxX\nktQtziCpFHVVjzMMSYpNGmoMRZIkMCB1Th3ltiWpDJbZliQ1gQGpQ7JKXnc1JE0yc5R+blff\nI6lNii6bG6WNYec6ynuMJKnf3IPUEX1aajbsZx0UePr0PkltMWo57aL7hYqc28hS3pKkNGeQ\n1BnjzgR1eaZN6qp0KDLoSJLK4gxSR4xzgL9il/VzyUsV/ZKkYapc5mZwkiSNyoDUIaOU284K\nRG0OSZPMADl7JNVv0jLbgx4fhyT3G0mSinCJXcdUebDflAp58WvH/RmlL5M8V1K1phFgZpYy\nY2CSJA1iQGqhIjM9kx74D3uNqvbtjFJhzlkjqVvGWQ4Xh5xRnhuHJIOSJCmLS+xapugyuDLL\nYE/LOMv+2rwsUNLkkkEnz7CCDu5TkiQlGZA0tjrDSbKwhEUmpParKqQUnR0yJEmSYgYkdYYh\nSVKSS+ckSeMwIOnX4n05dezPyQs37hWS+qGKMDPqvqSyX1+S1E4GpJbJCwxFSnwnl6ItWzM7\nk3xMsrrbtGdiygpHhimp3aoKSemgNGlJcUlSt1nFroWKhqRYOoAkK9DVHSrGDUfL1szOuKRO\n6p5kGe4qn2sokiTlMSD1VFaZ7qKBo+5QFWtKPyTVw5AjSaqCAanH4pBU50xM3a8vqXmKzgRZ\neU6SVAUDUs+NGk6mNWuT7JczRVI/1F3qW5IkMCD1wjizNNMMJcOW+mUtB5TULWWGIwORJGkS\nVrHribYEDJfbSSrCECRJqooBqUeyQlLR2ySpDHHZ7azy20XMLGUmDkdZIcngJEmalEvseiRr\ndqZpy9cs2iB1V1YgmlvJXBx6BgWmvOBjIJIklc0ZpJ5oU+goctJbSd0zKOxYsU6SNC3OILVM\nHHTaGBpG6Xsbfz5JQRxmxpndmeREsZIklcGA1CLJWaBBYSM9W1R32LAqndQfyXATL59L3540\nSohKtidJUlVcYtcSRZfIjbPPqI7ld21a8iepmLw9RlW/hiRJZTIg9YSBRFKTGXwkSU3hErsO\nMQRJapv0krw6+yJJEjiD1BrDzldUZzhascv6ufiSdb/nWpL6oazzErnPSJJUJ2eQWiQvVJQR\njsYtnFC0AIOBSOqnsgsrGJ4kSVVzBkmSVKlxls6lg1B8MtnyeiVJUjZnkBouOUPThCV1ef2R\n1G9V7B8yEEmS6mBAarC85WtNCEdZ17NuN0RJ3VV2KDIQSZKawCV2LVNWOEoHl0H7mwYVYBjG\nynpSN1lxTpLUVc4g9diw2Z2i4SZuxzAkSZKktnMGqWUmXbK2bM3sTJnL3lxCJ0mSpC4xIDVY\n1jK4SWZpyg4zRZbpGaCk9ptbyVzyUnd/JEmqkkvsGq6MynVlnN+oaFvJEGc4ktovKxAlz21U\nVmCaWcpMsi0LNkiS6mJAaolphqNJGYyk/kgHm3GeD5sGrbJPMCtJUlEGpIZr0pI6SSqTAUiS\n1ETuQWqwKsPRsNLd7ieS+im9zygrxKRvGyfoFHmO+50kSXVwBqmHksFo0H6heD+RwUjqh2Qg\nyQtJZRRqKBqonGGSJNXBGaSGGvUcRMNuG7XdIm1J6o5BoafMCnZ5oaeMWSlJksrgDFKDjFP9\nzRkeSU01asgxFEmSmsCA1ADpWZ1J9h5J0jgmrUaXbquMdiRJqoMBqYPSASs5w5R1sllnoKR+\nSAegsoOMwUiS1AUGpJZLh5us2afkbcvWzM4YiKT+sSKcJEnFWKShoYoEGYOOpEnkVa0bh7NH\nkqSucAZpSsrcVzRJMLKog6SkcYORgUiS1FUGpIqNG4ziIDNqmMnaY5S+f5z+SGqHrPMXGYIk\nSSrOJXYVmmTWaJIgYwiS+ikdhNx3JEnS6JxBKkFWVbi6wlFWGy6rk7qtiiDk7JEkqa8MSAWN\nEnjGCUdVBhjDkdR8eSFnWFAZFo6KhicDkSRJgQEpx6RFFUaZRTLASP0yyozP3ErmqjhfUdZe\nJUmS1OyAtB9wNPByYEvgl8D1wFeAa6p84TIrziVNKwilz3s0jdeUWqa28WWc5XBlhKT086sK\nRQYvSVLbNTUgfRj4FHAO8DXgcWArYAmwCjgeOKu23hVURzhJhzv3H0mb6MT4MoppBZWsIhGG\nJElS2zQ1IJ0IHACszrjvLODLFD+A2Q9464D7twYeG6Vzw9QVSKqa+ZI6ptXjS1rWcrk6ZnGs\nmCdJ6oqmBqRZ4Kac+64GdhihrRcAuw24fwPw4AjtbcTZGal1WjO+FDWt5XOSJPVBUwPSbcBy\n4IzU7TPASYS9AkWdH13y/G/g58kbPNmq1Gm1ji/pGZ4i2hB4xvm5JElqoqYGpOWEg46PATcT\n9gg8D9gj+v7wqjvQxhCUFeza+HNIFat9fGlD4BmH1fEkSV3Q1IB0LWHZyoHA7sxXmfoscDnw\nTH1dazYDkTSU40uFDEWSpLZrakCCsHb/0ugiSWVyfJEkSZkW1N0BSZIkSWoKA5IkSZIkRQxI\nkiRJkhQxIEmSJElSpMlFGqZpCfAHdXciw+HAw7S3qtYMsBNwF7T2/CiLgK2AC+vuyIi2rLsD\n+rWs8eUo4F6q+bt4DrANcHcFbQM8P/r6cEXt7wg8ADxVQdvxmHRnBW0DbAH8BnBfRe1vAzxJ\nqLpYhd8ELgIeG/I4xxdJnWZAgmuADwAfr7sjGXYjhKNn6+7ImGYI/8aepr0BaQGwEHhZ3R0Z\n0f3ArXV3Qpnjy0LgJVT3d7EgujxdQdsQ+g/VfXCziDDmVTHuVT0mVf3eLyL0u6r3fjNCoB8W\nwBxfJEm12QAcXHcnJrAb4T/znevuyAQOIZw8VCrLtoS/iyUVtf8eYG1FbQN8NbpUZS3hZ6jC\nEsJ7v21F7X+UcJ6tqlwCfK7C9p8BDqqwfUlqBfcgSZIkSVLEgCRJkiRJEQOSJEmSJEUMSJIk\nSZIUMSBJkiRJUsSAJEmSJEkRz4PUbN8Abqu7ExO4DzgXWFd3RyZwK/DNujuhTnmE8Hfxi4ra\nXw2cV1HbAJdX2DaEvq+uqO1fEN77Rypq/1pgtqK2AVYBP6mw/bOB2ytsX5IkSZIkSZIkSZIk\nSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZLUDA8DTwJPJC4H\n1tqjYo4F1gOnpW7fE/ghsA64HfjjKfdrFHk/Q1t/J2qevH9jZXj6Au3hAAAJG0lEQVQtcAXw\nIPBz4PSS238zcA3wEPAz4D+V3D7A5sDNwLdLbrfqv+HfAL5GeO/XAf8LWFhCu7/Lxn1+AtgA\nnFtC27H9gH8GfgzcBHy8xLYlSZrYAuBZYOe6OzKiMwj/YV/Gxgd+mwF3AicQfrZXEA4e9p1y\n/4rI+xna+jtR8+T9GyvD1sADwB8CM8DuhL+13yup/RcCjwGHR9f3IISBt5XUfuwvgZ9SbkCa\nxt/wWcA3gC0J79U/EgJl2RYQPnA6fNgDC9qKENjfGl3fjhCujyypfUmSJrYYmCMc7LTJ3tHX\n89n4wO8/Ev6zTfqfwJnT6NSI8n6Gtv5O1Dx5/8bKsC3wvtRtFwCfKKn9HYF3pm77R8qdRToQ\nuAE4iXIDUtV/w7OE2akdK2o/6U+A/1Nie0uAZwihOnY+5c8+SlJrLKi7A9rE4ujrXwNrgBuB\nU9j4P68mujrn9t0Jy2WSbgFeXm13xpL3M7T1d6Lmyfs3VoZ1wFcS17cDXk8IMWW4G/hW9P0C\n4C3Aq4BLSmp/a+BLwDJC2ChT1X/DryS8/8cQlqndAnyS8v+PnSUE3pNLbPMWwnLJo6PrLwH2\nAr5b4mtIUqsYkJpnA7CCMMOyK+E/rROAD9bYp0lsCTyeuu1X0e1t0bXfibpvO+BC4G8Ie0vK\n9DvAU4SwdDLwbyW1+1fASuDaktpLqvpveDGwPSFwvYywXG1Zie3HTgbOA35SYpsbgOMI7/86\nwvLGFcBVJb6GJEmlOx24uO5OFJReOvQR4Hupx3yIsJG8qYosfzqd9vxO1DxVLLGLvYpQDOWk\nitqH8OHabxFmS8oouvJ2QjDaLLq+nPKLNKSdTnl/w/sTQmOyKMMnCb/nsiwE7iHM7pRpV0Iw\n2i+6vh0hVJ9Y8utIUms4g9Q82zO/TyG2GeE/3za6kbCZO7mUZQlwfT3dGUvXfifqrj2BfwCO\nBz5fctsvA94Rff8s8K+EogRvL6Ht9xD279xGWAL3KeBQwvhRhqr/hn8CLGLjPU4zwNMltQ9w\nAKG/15TYJoRwdyfw/ej6/cB3CEsoJUlqhNcRKkXFn+a9grD2f2ltPRpN+pPxRcx/mr2QcJDy\nEOV/Clqm9M/Q9t+JmqeKGaQtCAfqh5Xcbux1hOWxcWW2HQmzPp+p4LXKnkGaxt/wxYQ9TpsB\nOxF+F8eW2P7HCeG3bHsRfq+vjK4/j1Bl8XMVvJYkSWM7lrBxdj1wK6FqUdPF5+d4hrCm/QnC\nWnkIM0Y/IASjW4D31tHBAgb9DG38nah5Bv0bm9SRhEpt6XPmnF1S+xACxa3Ao4SA8deEYFa2\nKpbYVf03vJgQfNcDdxCW8JVZyOULwN+V2F7S+4HVhBm824AvEoKSJEmSJEmSJEmSJEmSJEmS\nJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmS\nJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJKk264AjMm6/Aji5wPNf\nDMwBWw153LbR47bNuf8oYPshbbweuBmYLdCvIv4M+NuS2pKU7WrgE6nb/gvwCLBZ4rYtgMeB\n4xg8plzE/NiUHDeGjTFZHFMkSdImJg1IC4AdgJkhjxt28HIzsGTA87cE7gL2KdCnohYB1xEO\nsiRV45OE8STpSuBu4IDEbYcSQtPmDB5TkgEpOW6MGpAcUyRJhS2ouwNqpL2AHwC3AD8BPhjd\n/puEA50to+tHR4+5Ffgi8G3glEQ7hwCrgfuj+7aIvu4OXED49DjLRwgHHldF1/eLrt8L/Atw\nUHT7i4BngfdH7d0BnA78UXT9duYPrp6O7vsM/ruXqnIRYaZmcXR9FngF8BXCeBA7BLiUEHCS\nY8oxhDHnFuBLhBAC+eNG1hiTxTFFkiRlKjKDNAvcQzhQgflQdBAbL7HbEXgKeEP0uPcAT0Tt\nxJ/u/hWwENgauBNYGj12jsEzSDdE7cX9eRh4a3T9MODRqM3toraWR/ftBTwDnBRdfxXwJPCc\n6PoiwqfWrx3w2pLGNwOsBd4ZXT8KWAW8iRBIYrcAy9h0THkSeGP0mP2BDcyPTclxY9gYk+aY\nIkmSMq0DHiIEoOTlKeYPQn6fEIiSPg+cycYHM+8hLHlJupWNA9K/T9x3EXBq9P2ggLR1dP/O\n0fWjCJ/aJm1P+MQ2fp0Xp57776Lrz42u75R47irgxJzXljS5LwFfjb7/MmFMWEQIJTsCuxJC\nx/ZsPKa8mzCGJP0rgwNS3hiT5JgiSRrJouEPUcecCPzf1G3fSXy/GHgBsCZx23PZdF/BNsAD\nqdvuTF1/KPH904RPeod5YfT1nujrthmvc1/q+i+jr8+mrj8TfU2+7j2EPQ+SqnER8DeE2aS3\nAH9J+Pu/jLAkbnPgR4S/4xcnnrct8GCqrfuHvFaRMcYxRZI0EgNS/6xn/kAhtiHx/c8J6+7/\nQ8Zzkwcz69m0GtSLJu7dppu17yV86py0BxsHuFHNTfBcSYOtIowN7yD8Pd8Q3X4pcDDhA5cL\nM573IOGDl6T03/44HFMkSSNxY6nSLiMc3BweXX8ucAbzm5hjVxI2Te8ZXT+S+SUsw2wgzFJl\nicNb/Ins9wjLXN4VXX8zoZTwcwu+VtoOhAMkSdX4FWEcOQ34buL2SwnFEfYlzDKl/YCw/G7/\n6PpbgJcm7h80bgzimCJJGokBSWmPAm8jVKO7HbiRsJzkytTjfgp8FDiP8Anx3oSDoiKfpJ4N\nXEKoAJX2CKEq1RsT1w8jHGytIyzX+V3CDNaoFhE2U6d/FknlupBQ0CAZkG4jLIN7Arg+4zl3\nAn8MnEWYxX43IUjFM0CDxo1BHFMkSdLUpAP2D8kv3T2KU4HzS2gn7XcIm8D9YEDqF8cUSZJU\nuc0JG6jjsuF7Ao+z8ZKYcW1J2Au1VwltxRYC1zK/rEZSfzimSJKkqTgMuImwHObHwHtLbHsf\nwvK+55fU3p8SSpVL6ifHFEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmS\nJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmS1AL/\nH7Aa2ehRZ14VAAAAAElFTkSuQmCC"
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ],
      "source": [
        "par(mfrow = c(2,3))\n",
        "\n",
        "plot(df$Length1, df$Weight, main = \"Length1 vs Weight\", xlab = \"Length1 (cm)\", ylab = \"Weight (g)\", pch = 16, col = \"red\")\n",
        "\n",
        "plot(df$Length2, df$Weight, main = \"Length2 vs Weight\", xlab = \"Length2 (cm)\", ylab = \"Weight (g)\", pch = 16, col = \"green\")\n",
        "\n",
        "plot(df$Length3, df$Weight, main = \"Length3 vs Weight\", xlab = \"Length3 (cm)\", ylab = \"Weight (g)\", pch = 16, col = \"blue\")\n",
        "\n",
        "plot(df$Height, df$Weight, main = \"Height vs Weight\", xlab = \"Height (cm)\", ylab = \"Weight (g)\", pch = 16, col = \"purple\")\n",
        "\n",
        "plot(df$Width, df$Weight, main = \"Width vs Weight\", xlab = \"Width (cm)\", ylab = \"Weight (g)\", pch = 16, col = \"orange\")\n",
        "\n",
        "par(mfrow = c(1,1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The variables 'Length1'(red), 'Length2'(green) and 'Length3'(blue) shows a strong positive correlation with 'weight'.\n",
        "- The spread has relatively large variance in higer values of lengths.\n",
        "- Linear Trend (lengths) as the length increases, the weight also increases.\n",
        "- Height is not highly correlated with weight (purple)\n",
        "since it is scattered, it has many outliers and there is no linear relationship so height is not reliable for predicting the wight.\n",
        "- Width shows a positive correlation (orange) with weight but it also has some variance in higher widths."
      ],
      "metadata": {
        "id": "Hz6cRJ2wrpRi"
      },
      "id": "Hz6cRJ2wrpRi"
    },
    {
      "cell_type": "markdown",
      "id": "8d5186b4-4945-4a01-9ce0-708d5427e76f",
      "metadata": {
        "id": "8d5186b4-4945-4a01-9ce0-708d5427e76f"
      },
      "source": [
        "**Part C:** Use your favorite method in R to fit simple linear regression models to the data. Fit a separate SLR model for each feature.\n",
        "\n",
        "\n",
        "Once you have fit each model, report the following information about each model:\n",
        "- intercept value\n",
        "- slope value\n",
        "- p-value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494bb7df-285e-4963-aecf-0df33f60a797",
      "metadata": {
        "id": "494bb7df-285e-4963-aecf-0df33f60a797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971273d7-1ee4-4112-b18b-d388f7d40d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Feature Intercept     Slope      p_value\n",
            "1 Length1 -462.3751  32.79216 2.415227e-30\n",
            "2 Length2 -473.6490  30.68637 1.295504e-31\n",
            "3 Length3 -490.4006  28.46017 1.299621e-33\n",
            "4  Height -144.3860  60.49635 1.881076e-03\n",
            "5   Width -433.2589 188.24855 4.163981e-23\n"
          ]
        }
      ],
      "source": [
        "features = c(\"Length1\", \"Length2\", \"Length3\", \"Height\", \"Width\")\n",
        "\n",
        "res_df = data.frame(Feature = character(),\n",
        "                     Intercept = numeric(),\n",
        "                     Slope = numeric(),\n",
        "                     P_Value = numeric(),\n",
        "                     stringsAsFactors = FALSE)\n",
        "\n",
        "for (feature in features) {\n",
        "  model = lm(Weight ~ df[[feature]], data = df)\n",
        "  model_summary = summary(model)\n",
        "  intercept = model_summary$coefficients[1,1]\n",
        "  slope = model_summary$coefficients[2,1]\n",
        "  p_value = model_summary$coefficients[1,4]\n",
        "  res_df = rbind(res_df, data.frame(Feature = feature,\n",
        "                                      Intercept = intercept,\n",
        "                                      Slope = slope,\n",
        "                                      p_value = p_value))\n",
        "}\n",
        "print(res_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f79f83d8-872a-4e7c-a707-9339d0409aea",
      "metadata": {
        "id": "f79f83d8-872a-4e7c-a707-9339d0409aea"
      },
      "source": [
        "**Part D:** Use the SLR model from **Part C** for $\\texttt{Length3}$ versus $\\texttt{Weight}$ to estimate the weight of a fish whose measurement for $\\texttt{Length3}=31$ cm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b786de4-75b2-4bb9-ab91-ce2369833163",
      "metadata": {
        "id": "2b786de4-75b2-4bb9-ab91-ce2369833163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e037d1b-71a7-4893-9a7f-3e03c8ddd58c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "391.864703358166"
            ],
            "text/markdown": "391.864703358166",
            "text/latex": "391.864703358166",
            "text/plain": [
              "[1] 391.8647"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "intercept_length3 = res_df[res_df$Feature == \"Length3\", \"Intercept\"]\n",
        "slope_length3 = res_df[res_df$Feature == \"Length3\", \"Slope\"]\n",
        "y_pred = intercept_length3 + slope_length3 * 31\n",
        "y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b08e1bc-bc85-46e0-93b8-5fb6f2f10f01",
      "metadata": {
        "id": "0b08e1bc-bc85-46e0-93b8-5fb6f2f10f01"
      },
      "source": [
        "**Part E:** Looking at all 5 SLR models from **Part C**, what do you notice about the p-values? What inferences could you make from this information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12d06b9a-7d6e-48b3-9f7e-c02c359304c0",
      "metadata": {
        "id": "12d06b9a-7d6e-48b3-9f7e-c02c359304c0"
      },
      "source": [
        "- The p values are very small ie. less than 0.05 which indicates each feature significantly contributes in predicting the response variable 'weight'\n",
        "- Smallest p value is for 'Length3' so it is the strongest predictor out of all the predictors.\n",
        "- The p values of Length1, Length2 and Length3 are extremely smaller (ie. $\\text{e}^-30$ and smaller) that represents lengths of fish are highly correlated with the response 'weigth' compared to other predictors such as 'height' and 'width'."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13e22585-fb42-4494-a3f9-cf208947e949",
      "metadata": {
        "id": "13e22585-fb42-4494-a3f9-cf208947e949"
      },
      "source": [
        "**Part F:(Optional for 4010 Students)**\n",
        "\n",
        "Now, let's fit a multiiple linear regression model!\n",
        "\n",
        "Explicitly write out the MLR model using the coefficients that you found so that you have an answer of the form:\n",
        "$$ \\hat{y} = \\beta_0+\\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\beta_5 x_5 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080a5fa7-e651-4c31-b6e5-0b3770ba7d0e",
      "metadata": {
        "id": "080a5fa7-e651-4c31-b6e5-0b3770ba7d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "9b622ace-3a28-4525-c1f0-46a83a2dd690"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<strong>(Intercept):</strong> -499.586955356943"
            ],
            "text/markdown": "**(Intercept):** -499.586955356943",
            "text/latex": "\\textbf{(Intercept):} -499.586955356943",
            "text/plain": [
              "(Intercept) \n",
              "   -499.587 "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<strong>Length1:</strong> 62.3552144324637"
            ],
            "text/markdown": "**Length1:** 62.3552144324637",
            "text/latex": "\\textbf{Length1:} 62.3552144324637",
            "text/plain": [
              " Length1 \n",
              "62.35521 "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<strong>Length2:</strong> -6.5267524920434"
            ],
            "text/markdown": "**Length2:** -6.5267524920434",
            "text/latex": "\\textbf{Length2:} -6.5267524920434",
            "text/plain": [
              "  Length2 \n",
              "-6.526752 "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<strong>Length3:</strong> -29.0262186126936"
            ],
            "text/markdown": "**Length3:** -29.0262186126936",
            "text/latex": "\\textbf{Length3:} -29.0262186126936",
            "text/plain": [
              "  Length3 \n",
              "-29.02622 "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<strong>Height:</strong> 28.2973513222766"
            ],
            "text/markdown": "**Height:** 28.2973513222766",
            "text/latex": "\\textbf{Height:} 28.2973513222766",
            "text/plain": [
              "  Height \n",
              "28.29735 "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<strong>Width:</strong> 22.4733066522373"
            ],
            "text/markdown": "**Width:** 22.4733066522373",
            "text/latex": "\\textbf{Width:} 22.4733066522373",
            "text/plain": [
              "   Width \n",
              "22.47331 "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "mlr_model = lm(Weight ~ Length1 + Length2 + Length3 + Height + Width, data = df)\n",
        "coeff_mlr_model = coef(mlr_model)\n",
        "\n",
        "intercept = coeff_mlr_model[1]\n",
        "beta1 = coeff_mlr_model[2]\n",
        "beta2 = coeff_mlr_model[3]\n",
        "beta3 = coeff_mlr_model[4]\n",
        "beta4 = coeff_mlr_model[5]\n",
        "beta5 = coeff_mlr_model[6]\n",
        "\n",
        "intercept\n",
        "beta1\n",
        "beta2\n",
        "beta3\n",
        "beta4\n",
        "beta5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01617191-02da-42b3-9bf4-965c242b885a",
      "metadata": {
        "id": "01617191-02da-42b3-9bf4-965c242b885a"
      },
      "source": [
        "The **Multiple Linear Regression (MLR) equation** using the provided coefficients is:  \n",
        "\n",
        "\n",
        "$$\\hat{y} = -499.5869 + 62.3552 * \\text{Length1} - 6.5268 * \\text{Length2} - 29.0262 * \\text{Length3} + 28.2974 * \\text{Height} + 22.4733 * \\text{Width}$$\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.2.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}