{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9akJWJrfLRYa",
        "outputId": "494457c3-eae1-4d48-a643-ad14a4a934a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (2.32.4)\n",
            "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
            "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langsmith>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.4.3-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain) (2.11.7)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
            "  Downloading greenlet-3.2.3-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
            "Collecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n",
            "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: anyio in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
            "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.0/1.0 MB 24.2 MB/s eta 0:00:00\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl (2.1 MB)\n",
            "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.1/2.1 MB 59.6 MB/s eta 0:00:00\n",
            "Downloading faiss_cpu-1.11.0-cp310-cp310-win_amd64.whl (15.0 MB)\n",
            "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
            "   ------------------- -------------------- 7.3/15.0 MB 41.2 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 11.5/15.0 MB 34.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 15.0/15.0 MB 24.8 MB/s eta 0:00:00\n",
            "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
            "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
            "   -------------------------------- ------- 10.5/12.9 MB 46.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.9/12.9 MB 50.6 MB/s eta 0:00:00\n",
            "Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl (894 kB)\n",
            "   ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
            "   --------------------------------------- 894.0/894.0 kB 42.1 MB/s eta 0:00:00\n",
            "Downloading greenlet-3.2.3-cp310-cp310-win_amd64.whl (296 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading langsmith-0.4.3-py3-none-any.whl (367 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
            "Installing collected packages: zstandard, numpy, jsonpointer, greenlet, async-timeout, tiktoken, SQLAlchemy, requests-toolbelt, jsonpatch, faiss-cpu, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "\n",
            "  Attempting uninstall: numpy\n",
            "\n",
            "    Found existing installation: numpy 1.24.4\n",
            "\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "    Uninstalling numpy-1.24.4:\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -- -------------------------------------  1/14 [numpy]\n",
            "   -------- -------------------------------  3/14 [greenlet]\n",
            "  Attempting uninstall: async-timeout\n",
            "   -------- -------------------------------  3/14 [greenlet]\n",
            "    Found existing installation: async-timeout 5.0.1\n",
            "   -------- -------------------------------  3/14 [greenlet]\n",
            "    Uninstalling async-timeout-5.0.1:\n",
            "   -------- -------------------------------  3/14 [greenlet]\n",
            "      Successfully uninstalled async-timeout-5.0.1\n",
            "   -------- -------------------------------  3/14 [greenlet]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ----------------- ----------------------  6/14 [SQLAlchemy]\n",
            "   ---------------------- -----------------  8/14 [jsonpatch]\n",
            "   ------------------------- --------------  9/14 [faiss-cpu]\n",
            "   ------------------------- --------------  9/14 [faiss-cpu]\n",
            "   ------------------------- --------------  9/14 [faiss-cpu]\n",
            "   ---------------------------- ----------- 10/14 [langsmith]\n",
            "   ---------------------------- ----------- 10/14 [langsmith]\n",
            "   ------------------------------- -------- 11/14 [langchain-core]\n",
            "   ------------------------------- -------- 11/14 [langchain-core]\n",
            "   ------------------------------- -------- 11/14 [langchain-core]\n",
            "   ------------------------------- -------- 11/14 [langchain-core]\n",
            "   ------------------------------- -------- 11/14 [langchain-core]\n",
            "   ---------------------------------- ----- 12/14 [langchain-text-splitters]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ---------------------------------------- 14/14 [langchain]\n",
            "\n",
            "Successfully installed SQLAlchemy-2.0.41 async-timeout-4.0.3 faiss-cpu-1.11.0 greenlet-3.2.3 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.26 langchain-core-0.3.66 langchain-text-splitters-0.3.8 langsmith-0.4.3 numpy-2.2.6 requests-toolbelt-1.0.0 tiktoken-0.9.0 zstandard-0.23.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 6.31.1 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain faiss-cpu tiktoken requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2ZMMCXRALVmr"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain.llms.base import LLM\n",
        "from typing import List, Dict, Any\n",
        "import requests\n",
        "import numpy as np\n",
        "import faiss\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R4UBxN3DPlct"
      },
      "outputs": [],
      "source": [
        "# Using requests library for embeddings\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "def generate_embeddings(text: str):\n",
        "    url = \"https://api.euron.one/api/v1/euri/alpha/embeddings\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjNmQwZDlkMC1mNzgzLTQ3MTItOTBlYy1jYjAwZGUzNjQ5ZWMiLCJlbWFpbCI6ImhhcmlzaG5hbmRoYW4wMkBnbWFpbC5jb20iLCJpYXQiOjE3NDgzODIzNTMsImV4cCI6MTc3OTkxODM1M30.4uOCjjuVYPi_SL7MVnIOSOGKMsc8YhmD-aqohvU2Uwk\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"input\": text,\n",
        "        \"model\": \"text-embedding-3-small\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    data = response.json()\n",
        "\n",
        "    # Convert to numpy array for vector operations\n",
        "    embedding = np.array(data['data'][0]['embedding'])\n",
        "\n",
        "    return embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9GKZXAhQ0dN",
        "outputId": "375fda89-6ffe-495a-bce1-ee4b4d5f91df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting euriai\n",
            "  Downloading euriai-0.3.30-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from euriai) (2.32.4)\n",
            "Requirement already satisfied: langchain-core in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from euriai) (0.3.66)\n",
            "Collecting llama-index>=0.10.0 (from euriai)\n",
            "  Downloading llama_index-0.12.44-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from euriai) (2.2.6)\n",
            "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_agent_openai-0.4.11-py3-none-any.whl.metadata (439 bytes)\n",
            "Collecting llama-index-cli<0.5,>=0.4.2 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_cli-0.4.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.44 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_core-0.12.44-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.6,>=0.5.0 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_program_openai-0.3.2-py3-none-any.whl.metadata (473 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl.metadata (492 bytes)\n",
            "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_readers_file-0.4.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting nltk>3.8.1 (from llama-index>=0.10.0->euriai)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading openai-1.92.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (3.12.13)\n",
            "Collecting aiosqlite (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (2024.6.1)\n",
            "Requirement already satisfied: httpx in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (0.28.1)\n",
            "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_workflows-1.0.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (3.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (6.0.2)\n",
            "Collecting setuptools>=80.9.0 (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (4.14.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (1.20.1)\n",
            "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (3.1.4)\n",
            "Requirement already satisfied: platformdirs in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (4.3.8)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (4.13.4)\n",
            "Collecting pandas<2.3.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
            "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading pypdf-5.6.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (2.7)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl.metadata (252 bytes)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (1.9.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: sniffio in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (0.4.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (0.4.6)\n",
            "Collecting llama-cloud==0.1.26 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_parse-0.6.37-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.37 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_cloud_services-0.6.37-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-cloud-services>=0.6.37->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.10.0->euriai) (8.2.1)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_parse-0.6.36-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.36 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_cloud_services-0.6.36-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_parse-0.6.35-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.35 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_cloud_services-0.6.35-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_parse-0.6.34-py3-none-any.whl.metadata (6.9 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.32 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.10.0->euriai)\n",
            "  Downloading llama_cloud_services-0.6.34-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from llama-cloud-services>=0.6.32->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.10.0->euriai) (1.1.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from nltk>3.8.1->llama-index>=0.10.0->euriai) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from nltk>3.8.1->llama-index>=0.10.0->euriai) (2024.11.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index>=0.10.0->euriai) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from requests->euriai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from requests->euriai) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (3.2.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama-index>=0.10.0->euriai) (3.0.2)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-core->euriai) (0.4.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-core->euriai) (1.33)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->euriai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langsmith>=0.3.45->langchain-core->euriai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langsmith>=0.3.45->langchain-core->euriai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langsmith>=0.3.45->langchain-core->euriai) (0.23.0)\n",
            "Downloading euriai-0.3.30-py3-none-any.whl (9.5 kB)\n",
            "Downloading llama_index-0.12.44-py3-none-any.whl (7.1 kB)\n",
            "Downloading llama_index_agent_openai-0.4.11-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_cli-0.4.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.44-py3-none-any.whl (7.6 MB)\n",
            "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.3/7.6 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 0.8/7.6 MB 1.6 MB/s eta 0:00:05\n",
            "   ------ --------------------------------- 1.3/7.6 MB 1.9 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 1.8/7.6 MB 2.1 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 2.6/7.6 MB 2.3 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 3.1/7.6 MB 2.4 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 3.7/7.6 MB 2.4 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 4.5/7.6 MB 2.6 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 5.0/7.6 MB 2.6 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 5.8/7.6 MB 2.6 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 6.3/7.6 MB 2.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 6.6/7.6 MB 2.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 6.8/7.6 MB 2.5 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 7.1/7.6 MB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 7.3/7.6 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.6/7.6 MB 2.2 MB/s eta 0:00:00\n",
            "Downloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl (25 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl (3.4 kB)\n",
            "Downloading llama_index_program_openai-0.3.2-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl (3.7 kB)\n",
            "Downloading llama_index_readers_file-0.4.9-py3-none-any.whl (40 kB)\n",
            "Downloading llama_index_workflows-1.0.1-py3-none-any.whl (36 kB)\n",
            "Downloading openai-1.92.2-py3-none-any.whl (753 kB)\n",
            "   ---------------------------------------- 0.0/753.3 kB ? eta -:--:--\n",
            "   ------------- -------------------------- 262.1/753.3 kB ? eta -:--:--\n",
            "   --------------------------- ------------ 524.3/753.3 kB 1.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 753.3/753.3 kB 1.9 MB/s eta 0:00:00\n",
            "Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
            "Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
            "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/11.6 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.8/11.6 MB 1.8 MB/s eta 0:00:07\n",
            "   --- ------------------------------------ 1.0/11.6 MB 1.5 MB/s eta 0:00:07\n",
            "   ---- ----------------------------------- 1.3/11.6 MB 1.5 MB/s eta 0:00:07\n",
            "   ----- ---------------------------------- 1.6/11.6 MB 1.5 MB/s eta 0:00:07\n",
            "   ------ --------------------------------- 1.8/11.6 MB 1.6 MB/s eta 0:00:07\n",
            "   -------- ------------------------------- 2.4/11.6 MB 1.6 MB/s eta 0:00:06\n",
            "   --------- ------------------------------ 2.6/11.6 MB 1.6 MB/s eta 0:00:06\n",
            "   --------- ------------------------------ 2.9/11.6 MB 1.6 MB/s eta 0:00:06\n",
            "   ---------- ----------------------------- 3.1/11.6 MB 1.6 MB/s eta 0:00:06\n",
            "   ----------- ---------------------------- 3.4/11.6 MB 1.5 MB/s eta 0:00:06\n",
            "   ------------ --------------------------- 3.7/11.6 MB 1.5 MB/s eta 0:00:06\n",
            "   ------------- -------------------------- 3.9/11.6 MB 1.4 MB/s eta 0:00:06\n",
            "   --------------- ------------------------ 4.5/11.6 MB 1.5 MB/s eta 0:00:05\n",
            "   ---------------- ----------------------- 4.7/11.6 MB 1.5 MB/s eta 0:00:05\n",
            "   ------------------ --------------------- 5.2/11.6 MB 1.5 MB/s eta 0:00:05\n",
            "   -------------------- ------------------- 6.0/11.6 MB 1.6 MB/s eta 0:00:04\n",
            "   ---------------------- ----------------- 6.6/11.6 MB 1.7 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 7.1/11.6 MB 1.7 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 7.6/11.6 MB 1.8 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 8.4/11.6 MB 1.9 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 8.7/11.6 MB 1.9 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 8.9/11.6 MB 1.9 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 9.2/11.6 MB 1.8 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 9.4/11.6 MB 1.8 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 9.7/11.6 MB 1.8 MB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 10.0/11.6 MB 1.8 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.2/11.6 MB 1.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.5/11.6 MB 1.7 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 10.7/11.6 MB 1.7 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 11.3/11.6 MB 1.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.6/11.6 MB 1.7 MB/s eta 0:00:00\n",
            "Downloading pypdf-5.6.1-py3-none-any.whl (304 kB)\n",
            "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl (16 kB)\n",
            "Downloading llama_cloud-0.1.26-py3-none-any.whl (266 kB)\n",
            "Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading llama_parse-0.6.34-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.34-py3-none-any.whl (39 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   ------------- -------------------------- 0.5/1.5 MB 3.4 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 0.8/1.5 MB 2.8 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.0/1.5 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 1.3/1.5 MB 1.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.5/1.5 MB 1.4 MB/s eta 0:00:00\n",
            "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
            "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
            "   ----------------- ---------------------- 0.5/1.2 MB 837.5 kB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 1.0/1.2 MB 1.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.2/1.2 MB 1.1 MB/s eta 0:00:00\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, setuptools, pypdf, mypy-extensions, marshmallow, jiter, griffe, deprecated, aiosqlite, typing-inspect, pandas, nltk, llama-index-instrumentation, dataclasses-json, banks, openai, llama-index-workflows, llama-cloud, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index, euriai\n",
            "\n",
            "  Attempting uninstall: setuptools\n",
            "\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "    Found existing installation: setuptools 78.1.1\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "    Uninstalling setuptools-78.1.1:\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "      Successfully uninstalled setuptools-78.1.1\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   --- ------------------------------------  3/35 [setuptools]\n",
            "   ---- -----------------------------------  4/35 [pypdf]\n",
            "   ---- -----------------------------------  4/35 [pypdf]\n",
            "   -------- -------------------------------  7/35 [jiter]\n",
            "   --------- ------------------------------  8/35 [griffe]\n",
            "   ------------ --------------------------- 11/35 [typing-inspect]\n",
            "  Attempting uninstall: pandas\n",
            "   ------------ --------------------------- 11/35 [typing-inspect]\n",
            "    Found existing installation: pandas 2.3.0\n",
            "   ------------ --------------------------- 11/35 [typing-inspect]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "    Uninstalling pandas-2.3.0:\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "      Successfully uninstalled pandas-2.3.0\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   ------------- -------------------------- 12/35 [pandas]\n",
            "   -------------- ------------------------- 13/35 [nltk]\n",
            "   -------------- ------------------------- 13/35 [nltk]\n",
            "   -------------- ------------------------- 13/35 [nltk]\n",
            "   -------------- ------------------------- 13/35 [nltk]\n",
            "   -------------- ------------------------- 13/35 [nltk]\n",
            "   -------------- ------------------------- 13/35 [nltk]\n",
            "   -------------- ------------------------- 13/35 [nltk]\n",
            "   -------------- ------------------------- 13/35 [nltk]\n",
            "   -------------- ------------------------- 13/35 [nltk]\n",
            "   -------------- ------------------------- 13/35 [nltk]\n",
            "   ----------------- ---------------------- 15/35 [dataclasses-json]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   ------------------- -------------------- 17/35 [openai]\n",
            "   --------------------- ------------------ 19/35 [llama-cloud]\n",
            "   --------------------- ------------------ 19/35 [llama-cloud]\n",
            "   --------------------- ------------------ 19/35 [llama-cloud]\n",
            "   --------------------- ------------------ 19/35 [llama-cloud]\n",
            "   --------------------- ------------------ 19/35 [llama-cloud]\n",
            "   --------------------- ------------------ 19/35 [llama-cloud]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ---------------------- ----------------- 20/35 [llama-index-core]\n",
            "   ------------------------ --------------- 21/35 [llama-index-readers-file]\n",
            "   ------------------ --------- 23/35 [llama-index-indices-managed-llama-cloud]\n",
            "   -------------------------------- ------- 28/35 [llama-index-cli]\n",
            "   ------------------------------------- -- 33/35 [llama-index]\n",
            "   ---------------------------------------- 35/35 [euriai]\n",
            "\n",
            "Successfully installed aiosqlite-0.21.0 banks-2.1.2 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 euriai-0.3.30 filetype-1.2.0 griffe-1.7.3 jiter-0.10.0 llama-cloud-0.1.26 llama-cloud-services-0.6.34 llama-index-0.12.44 llama-index-agent-openai-0.4.11 llama-index-cli-0.4.3 llama-index-core-0.12.44 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.7.7 llama-index-instrumentation-0.2.0 llama-index-llms-openai-0.4.7 llama-index-multi-modal-llms-openai-0.5.1 llama-index-program-openai-0.3.2 llama-index-question-gen-openai-0.3.1 llama-index-readers-file-0.4.9 llama-index-readers-llama-parse-0.4.0 llama-index-workflows-1.0.1 llama-parse-0.6.34 marshmallow-3.26.1 mypy-extensions-1.1.0 nltk-3.9.1 openai-1.92.2 pandas-2.2.3 pypdf-5.6.1 setuptools-80.9.0 striprtf-0.0.26 typing-inspect-0.9.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 6.31.1 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install euriai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "irDz2ZcCRFM7"
      },
      "outputs": [],
      "source": [
        "from euriai import EuriaiClient\n",
        "def generate_response(prompt):\n",
        "  client = EuriaiClient(\n",
        "      api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjNmQwZDlkMC1mNzgzLTQ3MTItOTBlYy1jYjAwZGUzNjQ5ZWMiLCJlbWFpbCI6ImhhcmlzaG5hbmRoYW4wMkBnbWFpbC5jb20iLCJpYXQiOjE3NDgzODIzNTMsImV4cCI6MTc3OTkxODM1M30.4uOCjjuVYPi_SL7MVnIOSOGKMsc8YhmD-aqohvU2Uwk\",\n",
        "      model=\"gpt-4.1-nano\"  # You can also try: \"gemini-2.0-flash-001\", \"llama-4-maverick\", etc.\n",
        "  )\n",
        "\n",
        "  response = client.generate_completion(\n",
        "      prompt= prompt,\n",
        "      temperature=0.7,\n",
        "      max_tokens=300\n",
        "  )\n",
        "\n",
        "  print(response)\n",
        "  return response['choices'][0][\"message\"][\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcnV9unifhJi",
        "outputId": "30e5a161-e472-481a-995a-03409af2c33f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-community) (0.3.66)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-community) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-community) (3.12.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-community) (0.4.3)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-community) (2.2.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yoges\\.conda\\envs\\py310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
            "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
            "   --------------------------------- ------ 2.1/2.5 MB 14.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.5/2.5 MB 18.1 MB/s eta 0:00:00\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "Installing collected packages: httpx-sse, pydantic-settings, langchain-community\n",
            "\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   -------------------------- ------------- 2/3 [langchain-community]\n",
            "   ---------------------------------------- 3/3 [langchain-community]\n",
            "\n",
            "Successfully installed httpx-sse-0.4.1 langchain-community-0.3.26 pydantic-settings-2.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0MuMJ1Yfi6f",
        "outputId": "eefbd3d9-e5fc-4c5e-dccb-08ac1b85eb44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.66)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajJd8wiggqJ8",
        "outputId": "fd75f6b9-ad78-4867-d4bc-99e4a12c03f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'C:\\\\Users\\\\yoges\\\\Data_Science_Preparation\\\\Generative AI Learnings\\\\RAG Langchain\\\\data.txt'}, page_content=\"Helping Millions of Students Succeed\\nSudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\\n\\nIn 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.\\n\\n\\nThe Entrepreneur and Teacher: Sudhanshu's Dual Legacy\\nSudhanshu's journey isn't just one of entrepreneurial success; it's also a story of dedication to teaching. Throughout his career, he has remained a passionate educator, constantly looking for ways to empower others through knowledge. Whether teaching courses in Big Data, Data Science, or programming, Sudhanshu has always sought to make complex subjects accessible to learners at all levels.\\n\\nHis commitment to affordable education has earned him the respect and admiration of countless students. Many credit Sudhanshu with changing their lives, helping them secure jobs, improve their skills, and break free from the limitations of their backgrounds.\\n\\nEarly Life and the Power of Education\\nSudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education. Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship. His surroundings offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.\\n\\nWhile many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge. He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family. Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE).\\n\\n\\nRising Through the Ranks of the Tech World\\nAfter completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young. During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more. He became a well-rounded technologist, well-respected in his field.\\n\\nDespite his growing success, Sudhanshu never forgot his roots. He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education. It was during this time that Sudhanshu realized a harsh truth: quality education was often inaccessible to those who needed it the most. The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills.\\n\\nThe Birth of iNeuron: Democratizing Education\\nFueled by his passion for making education accessible, Sudhanshu decided to take action. In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone. His mission was clear: to provide high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.\\n\\niNeuron was designed to be more than just an online learning platform. It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills. Most importantly, iNeuron was priced to ensure no student would be left behind due to financial constraints.\\n\\nThe company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality. In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher. This allowed iNeuron to expand its offerings and reach a larger audience.\\n\\nThe Foundation of Euron: Expanding the Mission\\nBuilding on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling. Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills. The platform provides a comprehensive bundle of resources, including courses, books, live classes, and projects. Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\\n\\nFor individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist. The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\\n\\nThe Euron Motto: Education for All, Without Limits\\n\\nAt the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits. Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background. This belief is what drives Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world.\")]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "document = TextLoader(r\"C:\\Users\\yoges\\Data_Science_Preparation\\Generative AI Learnings\\RAG Langchain\\data.txt\").load()\n",
        "document\n",
        "\n",
        "\n",
        "# or\n",
        "# with open(\"data.txt\",\"r\") as file:\n",
        "#   text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2n28z_IPfO-m"
      },
      "outputs": [],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
        "# break the data into chunks\n",
        "# if any of the sentence is break into half the overlap will make sure it starts from the base again\n",
        "docs = splitter.split_documents(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCDyttcGgXt9",
        "outputId": "cc54a19b-931a-4d62-f752-42cf93d6c5f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox9mv5HEg129",
        "outputId": "ed9d9c66-ee6b-45e6-aff7-f42667c390f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Helping Millions of Students Succeed',\n",
              " \"Sudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students,\",\n",
              " 'Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.',\n",
              " 'In 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.',\n",
              " \"The Entrepreneur and Teacher: Sudhanshu's Dual Legacy\",\n",
              " \"Sudhanshu's journey isn't just one of entrepreneurial success; it's also a story of dedication to teaching. Throughout his career, he has remained a passionate educator, constantly looking for ways to empower others through knowledge. Whether teaching courses in Big Data, Data Science, or\",\n",
              " 'in Big Data, Data Science, or programming, Sudhanshu has always sought to make complex subjects accessible to learners at all levels.',\n",
              " 'His commitment to affordable education has earned him the respect and admiration of countless students. Many credit Sudhanshu with changing their lives, helping them secure jobs, improve their skills, and break free from the limitations of their backgrounds.',\n",
              " 'Early Life and the Power of Education',\n",
              " \"Sudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education. Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship. His surroundings offered little opportunity,\",\n",
              " 'offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.',\n",
              " 'While many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge. He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family. Despite the numerous',\n",
              " 'family. Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE).',\n",
              " 'Rising Through the Ranks of the Tech World',\n",
              " 'After completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young. During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5',\n",
              " 'SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more. He became a well-rounded technologist, well-respected in his field.',\n",
              " 'Despite his growing success, Sudhanshu never forgot his roots. He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education. It was during this time that Sudhanshu realized a harsh truth: quality',\n",
              " 'a harsh truth: quality education was often inaccessible to those who needed it the most. The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills.',\n",
              " 'The Birth of iNeuron: Democratizing Education',\n",
              " 'Fueled by his passion for making education accessible, Sudhanshu decided to take action. In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone. His mission was clear: to provide high-quality courses at a',\n",
              " 'high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.',\n",
              " 'iNeuron was designed to be more than just an online learning platform. It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills. Most importantly, iNeuron was priced to ensure no',\n",
              " 'was priced to ensure no student would be left behind due to financial constraints.',\n",
              " \"The company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality. In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher. This allowed iNeuron to expand its offerings and reach a larger audience.\",\n",
              " 'The Foundation of Euron: Expanding the Mission',\n",
              " 'Building on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling. Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills. The platform provides a comprehensive bundle of',\n",
              " \"a comprehensive bundle of resources, including courses, books, live classes, and projects. Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\",\n",
              " \"For individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist. The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\",\n",
              " 'The Euron Motto: Education for All, Without Limits',\n",
              " \"At the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits. Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background. This belief is what drives Euron's mission to make tech\",\n",
              " \"Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world.\"]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 2: Convert everything into embeddings and save it into the Vector DB (FAISS)\n",
        "texts = [doc.page_content for doc in docs]\n",
        "texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QqJgbuaAh5m3"
      },
      "outputs": [],
      "source": [
        "embeddings = [generate_embeddings(i).astype('float32') for i in texts]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjkhm1c5iI2V",
        "outputId": "9adf5182-9b13-432c-aa41-7fa23ac2d8d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([ 0.02873218, -0.03871168,  0.05527106, ..., -0.01516116,\n",
              "        -0.03901326,  0.00616522], shape=(1536,), dtype=float32),\n",
              " array([-0.01364236,  0.00639423,  0.05721121, ..., -0.00413274,\n",
              "        -0.00975312, -0.00021493], shape=(1536,), dtype=float32),\n",
              " array([-0.02204193, -0.00722562,  0.00345266, ..., -0.00756314,\n",
              "        -0.02643654, -0.00205438], shape=(1536,), dtype=float32),\n",
              " array([-0.04330518, -0.05195538,  0.02764536, ..., -0.03267549,\n",
              "         0.01820879,  0.03354321], shape=(1536,), dtype=float32),\n",
              " array([ 0.01671011,  0.01011956,  0.04287479, ..., -0.04371754,\n",
              "         0.01135734, -0.00684733], shape=(1536,), dtype=float32),\n",
              " array([-0.00970297, -0.00214104,  0.0598214 , ..., -0.01701215,\n",
              "        -0.01090567,  0.00101315], shape=(1536,), dtype=float32),\n",
              " array([-0.00568317, -0.01421538,  0.03512035, ..., -0.00705393,\n",
              "         0.00747801,  0.00206959], shape=(1536,), dtype=float32),\n",
              " array([ 0.00620001, -0.03134765,  0.04846245, ...,  0.0006798 ,\n",
              "        -0.0170516 ,  0.01701368], shape=(1536,), dtype=float32),\n",
              " array([ 0.05260113, -0.00281351,  0.01458545, ..., -0.01748176,\n",
              "        -0.00835124, -0.01642974], shape=(1536,), dtype=float32),\n",
              " array([-0.00127736, -0.01250005,  0.01973938, ...,  0.00045937,\n",
              "        -0.00792601,  0.00018986], shape=(1536,), dtype=float32),\n",
              " array([-0.01566061, -0.01703123, -0.0013262 , ..., -0.02850383,\n",
              "        -0.02363051, -0.0083189 ], shape=(1536,), dtype=float32),\n",
              " array([-0.00455234, -0.01004747,  0.01445166, ..., -0.01896359,\n",
              "        -0.03189331, -0.0079868 ], shape=(1536,), dtype=float32),\n",
              " array([ 0.01018288, -0.01619557,  0.02019248, ..., -0.0308894 ,\n",
              "         0.0128109 ,  0.01059296], shape=(1536,), dtype=float32),\n",
              " array([ 0.00830214, -0.03766377,  0.00336707, ..., -0.01579856,\n",
              "         0.00382325,  0.00084325], shape=(1536,), dtype=float32),\n",
              " array([-0.05622125, -0.01156551,  0.04697343, ..., -0.00197205,\n",
              "         0.00072715,  0.00687276], shape=(1536,), dtype=float32),\n",
              " array([-0.05323311, -0.0117742 ,  0.03674017, ..., -0.01866784,\n",
              "         0.00754092, -0.00424298], shape=(1536,), dtype=float32),\n",
              " array([-0.01863363, -0.01560451,  0.02871755, ..., -0.01864674,\n",
              "        -0.02286914, -0.024941  ], shape=(1536,), dtype=float32),\n",
              " array([ 0.01140893, -0.01492077,  0.0070722 , ..., -0.01925143,\n",
              "        -0.02319391, -0.0084551 ], shape=(1536,), dtype=float32),\n",
              " array([ 0.01442112, -0.01111941,  0.01553988, ...,  0.00856126,\n",
              "        -0.0335083 , -0.0195647 ], shape=(1536,), dtype=float32),\n",
              " array([-0.03590128, -0.01738218,  0.01270188, ..., -0.00478768,\n",
              "        -0.00250753, -0.01179866], shape=(1536,), dtype=float32),\n",
              " array([-0.02509347, -0.02105911,  0.02858715, ..., -0.02311095,\n",
              "        -0.0164286 , -0.00468943], shape=(1536,), dtype=float32),\n",
              " array([-0.03405431,  0.00919975, -0.00795448, ...,  0.00507638,\n",
              "        -0.02498163, -0.003901  ], shape=(1536,), dtype=float32),\n",
              " array([-0.01449904, -0.01275365,  0.00701777, ..., -0.00890076,\n",
              "        -0.01229014, -0.03053344], shape=(1536,), dtype=float32),\n",
              " array([ 0.00689439, -0.01485711,  0.02219871, ..., -0.00688818,\n",
              "         0.01465835,  0.01464593], shape=(1536,), dtype=float32),\n",
              " array([-9.6296547e-03,  9.1859922e-03,  6.2200002e-02, ...,\n",
              "        -1.1193383e-02,  7.8640966e-05, -1.8299254e-02],\n",
              "       shape=(1536,), dtype=float32),\n",
              " array([-0.03392362, -0.00518741,  0.03510491, ..., -0.00739591,\n",
              "        -0.01656377, -0.01142771], shape=(1536,), dtype=float32),\n",
              " array([-0.02502919,  0.01078778,  0.0622926 , ...,  0.00509441,\n",
              "        -0.01197297,  0.0029343 ], shape=(1536,), dtype=float32),\n",
              " array([-0.04738135, -0.020828  ,  0.0440371 , ...,  0.00399304,\n",
              "         0.00071651,  0.00731053], shape=(1536,), dtype=float32),\n",
              " array([ 0.02577582,  0.00692495,  0.02222492, ...,  0.00642981,\n",
              "        -0.00594174, -0.02066875], shape=(1536,), dtype=float32),\n",
              " array([-0.00095485, -0.01345976,  0.03403033, ..., -0.00268995,\n",
              "        -0.00041477, -0.015184  ], shape=(1536,), dtype=float32),\n",
              " array([-0.02958555, -0.01552563, -0.0035048 , ..., -0.01067387,\n",
              "         0.00217311, -0.02038417], shape=(1536,), dtype=float32)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kCPJqcD-idTj"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.docstore.document import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5bxMNMqaj69F"
      },
      "outputs": [],
      "source": [
        "dimension = embeddings[0].shape[0]\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "faiss_index.add(np.array(embeddings).astype('float32'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdSTTegykAWa",
        "outputId": "71d753a0-1141-402d-a938-88262f6c41b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7a22d60d0660> >"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "faiss_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdhssWy4k7cE",
        "outputId": "03cb4268-45bc-4090-ccdf-63d033d2fad9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([ 0.02873218, -0.03871168,  0.05527106, ..., -0.01516116,\n",
              "        -0.03901326,  0.00616522], dtype=float32),\n",
              " array([-0.01364236,  0.00639423,  0.05721121, ..., -0.00413274,\n",
              "        -0.00975312, -0.00021493], dtype=float32),\n",
              " array([-0.02204193, -0.00722562,  0.00345266, ..., -0.00756314,\n",
              "        -0.02643654, -0.00205438], dtype=float32),\n",
              " array([-0.04330518, -0.05195538,  0.02764536, ..., -0.03267549,\n",
              "         0.01820879,  0.03354321], dtype=float32),\n",
              " array([ 0.01669575,  0.010132  ,  0.04289808, ..., -0.0436881 ,\n",
              "         0.01136312, -0.00684026], dtype=float32),\n",
              " array([-0.00970297, -0.00214104,  0.0598214 , ..., -0.01701215,\n",
              "        -0.01090567,  0.00101315], dtype=float32),\n",
              " array([-0.00568317, -0.01421538,  0.03512035, ..., -0.00705393,\n",
              "         0.00747801,  0.00206959], dtype=float32),\n",
              " array([ 0.00617231, -0.03135141,  0.04851883, ...,  0.00069134,\n",
              "        -0.01702837,  0.0169778 ], dtype=float32),\n",
              " array([ 0.05260113, -0.00281351,  0.01458545, ..., -0.01748176,\n",
              "        -0.00835124, -0.01642974], dtype=float32),\n",
              " array([-0.00127736, -0.01250005,  0.01973938, ...,  0.00045937,\n",
              "        -0.00792601,  0.00018986], dtype=float32),\n",
              " array([-0.01566061, -0.01703123, -0.0013262 , ..., -0.02850383,\n",
              "        -0.02363051, -0.0083189 ], dtype=float32),\n",
              " array([-0.00455234, -0.01004747,  0.01445166, ..., -0.01896359,\n",
              "        -0.03189331, -0.0079868 ], dtype=float32),\n",
              " array([ 0.01018288, -0.01619557,  0.02019248, ..., -0.0308894 ,\n",
              "         0.0128109 ,  0.01059296], dtype=float32),\n",
              " array([ 0.00830214, -0.03766377,  0.00336707, ..., -0.01579856,\n",
              "         0.00382325,  0.00084325], dtype=float32),\n",
              " array([-0.05622125, -0.01156551,  0.04697343, ..., -0.00197205,\n",
              "         0.00072715,  0.00687276], dtype=float32),\n",
              " array([-0.05323311, -0.0117742 ,  0.03674017, ..., -0.01866784,\n",
              "         0.00754092, -0.00424298], dtype=float32),\n",
              " array([-0.01863363, -0.01560451,  0.02871755, ..., -0.01864674,\n",
              "        -0.02286914, -0.024941  ], dtype=float32),\n",
              " array([ 0.01140893, -0.01492077,  0.0070722 , ..., -0.01925143,\n",
              "        -0.02319391, -0.0084551 ], dtype=float32),\n",
              " array([ 0.01442112, -0.01111941,  0.01553988, ...,  0.00856126,\n",
              "        -0.0335083 , -0.0195647 ], dtype=float32),\n",
              " array([-0.03590128, -0.01738218,  0.01270188, ..., -0.00478768,\n",
              "        -0.00250753, -0.01179866], dtype=float32),\n",
              " array([-0.02509295, -0.02104481,  0.02861428, ..., -0.02308274,\n",
              "        -0.01646985, -0.00468933], dtype=float32),\n",
              " array([-0.034051  ,  0.00920521, -0.007941  , ...,  0.00507906,\n",
              "        -0.02499191, -0.00389427], dtype=float32),\n",
              " array([-0.01449904, -0.01275365,  0.00701777, ..., -0.00890076,\n",
              "        -0.01229014, -0.03053344], dtype=float32),\n",
              " array([ 0.00689439, -0.01485711,  0.02219871, ..., -0.00688818,\n",
              "         0.01465835,  0.01464593], dtype=float32),\n",
              " array([-9.6296547e-03,  9.1859922e-03,  6.2200002e-02, ...,\n",
              "        -1.1193383e-02,  7.8640966e-05, -1.8299254e-02], dtype=float32),\n",
              " array([-0.03405544, -0.0053003 ,  0.0351598 , ..., -0.00749297,\n",
              "        -0.01660395, -0.01147381], dtype=float32),\n",
              " array([-0.02502919,  0.01078778,  0.0622926 , ...,  0.00509441,\n",
              "        -0.01197297,  0.0029343 ], dtype=float32),\n",
              " array([-0.04738135, -0.020828  ,  0.0440371 , ...,  0.00399304,\n",
              "         0.00071651,  0.00731053], dtype=float32),\n",
              " array([ 0.02577582,  0.00692495,  0.02222492, ...,  0.00642981,\n",
              "        -0.00594174, -0.02066875], dtype=float32),\n",
              " array([-0.00095485, -0.01345976,  0.03403033, ..., -0.00268995,\n",
              "        -0.00041477, -0.015184  ], dtype=float32),\n",
              " array([-0.02958555, -0.01552563, -0.0035048 , ..., -0.01067387,\n",
              "         0.00217311, -0.02038417], dtype=float32)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IxPttiW5lb4C"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LnsV72W7nD4L"
      },
      "outputs": [],
      "source": [
        "document = [Document(page_content=text) for text in texts[:len(embeddings)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf370sKsnTtR",
        "outputId": "9958cf94-e1b4-4445-974c-217c4b118eb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='Helping Millions of Students Succeed'),\n",
              " Document(metadata={}, page_content=\"Sudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students,\"),\n",
              " Document(metadata={}, page_content='Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.'),\n",
              " Document(metadata={}, page_content='In 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.'),\n",
              " Document(metadata={}, page_content=\"The Entrepreneur and Teacher: Sudhanshu's Dual Legacy\"),\n",
              " Document(metadata={}, page_content=\"Sudhanshu's journey isn't just one of entrepreneurial success; it's also a story of dedication to teaching. Throughout his career, he has remained a passionate educator, constantly looking for ways to empower others through knowledge. Whether teaching courses in Big Data, Data Science, or\"),\n",
              " Document(metadata={}, page_content='in Big Data, Data Science, or programming, Sudhanshu has always sought to make complex subjects accessible to learners at all levels.'),\n",
              " Document(metadata={}, page_content='His commitment to affordable education has earned him the respect and admiration of countless students. Many credit Sudhanshu with changing their lives, helping them secure jobs, improve their skills, and break free from the limitations of their backgrounds.'),\n",
              " Document(metadata={}, page_content='Early Life and the Power of Education'),\n",
              " Document(metadata={}, page_content=\"Sudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education. Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship. His surroundings offered little opportunity,\"),\n",
              " Document(metadata={}, page_content='offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.'),\n",
              " Document(metadata={}, page_content='While many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge. He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family. Despite the numerous'),\n",
              " Document(metadata={}, page_content='family. Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE).'),\n",
              " Document(metadata={}, page_content='Rising Through the Ranks of the Tech World'),\n",
              " Document(metadata={}, page_content='After completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young. During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5'),\n",
              " Document(metadata={}, page_content='SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more. He became a well-rounded technologist, well-respected in his field.'),\n",
              " Document(metadata={}, page_content='Despite his growing success, Sudhanshu never forgot his roots. He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education. It was during this time that Sudhanshu realized a harsh truth: quality'),\n",
              " Document(metadata={}, page_content='a harsh truth: quality education was often inaccessible to those who needed it the most. The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills.'),\n",
              " Document(metadata={}, page_content='The Birth of iNeuron: Democratizing Education'),\n",
              " Document(metadata={}, page_content='Fueled by his passion for making education accessible, Sudhanshu decided to take action. In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone. His mission was clear: to provide high-quality courses at a'),\n",
              " Document(metadata={}, page_content='high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.'),\n",
              " Document(metadata={}, page_content='iNeuron was designed to be more than just an online learning platform. It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills. Most importantly, iNeuron was priced to ensure no'),\n",
              " Document(metadata={}, page_content='was priced to ensure no student would be left behind due to financial constraints.'),\n",
              " Document(metadata={}, page_content=\"The company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality. In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher. This allowed iNeuron to expand its offerings and reach a larger audience.\"),\n",
              " Document(metadata={}, page_content='The Foundation of Euron: Expanding the Mission'),\n",
              " Document(metadata={}, page_content='Building on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling. Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills. The platform provides a comprehensive bundle of'),\n",
              " Document(metadata={}, page_content=\"a comprehensive bundle of resources, including courses, books, live classes, and projects. Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\"),\n",
              " Document(metadata={}, page_content=\"For individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist. The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\"),\n",
              " Document(metadata={}, page_content='The Euron Motto: Education for All, Without Limits'),\n",
              " Document(metadata={}, page_content=\"At the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits. Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background. This belief is what drives Euron's mission to make tech\"),\n",
              " Document(metadata={}, page_content=\"Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world.\")]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqfXWU2YnaXi",
        "outputId": "d9089a71-f6f2-4199-8971-e067dddabe7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['a3af1924-8143-4b7f-aa94-967b3bd322e2',\n",
              " '7110e8a6-78b9-4603-a709-f57aa865f33c',\n",
              " '70d4b2e7-0475-4b79-961b-5fead362d099',\n",
              " 'd676318c-f5fe-4acc-829c-ef30218f8df1',\n",
              " '5e9c7cff-450c-41f7-afb8-90b4915513ac',\n",
              " 'b04100ab-3d7b-4945-a6ca-77616e431da3',\n",
              " 'ad1daf5c-95b3-4955-9218-a045a40648f9',\n",
              " '38f56381-195d-4f70-ae9b-8a483f872b7a',\n",
              " '487cf4e7-1f52-4dd5-a4f2-69c56001bc55',\n",
              " 'dd79735f-6ae1-4bd1-8e58-635a6c4214a5',\n",
              " '6b50ec7f-2aa8-4094-bae7-82aa513b98c3',\n",
              " '56d10808-c040-4865-9efc-f7b5192def70',\n",
              " '78a63101-453f-4ba5-bad5-b29ecfbf322c',\n",
              " '1558f704-db54-4893-bc88-9dd2b667d603',\n",
              " '5128997f-70ec-4ab7-8211-f6b88f415b7b',\n",
              " 'c80c4bfc-210e-434e-b94d-417c14dbe28a',\n",
              " '11792ed0-8ca5-4d27-b08e-3d2ff3a32c82',\n",
              " 'f5381dca-db62-4737-a07a-62191f12eb55',\n",
              " 'ba79a871-88e8-4b99-bf72-2fa61874ebfc',\n",
              " '0721c59a-9081-46b5-828b-936c1f108289',\n",
              " 'b7517de9-547d-4b5d-9dc9-85833ec2209e',\n",
              " 'ea90da8b-33ba-435c-bfcd-e131b2b98e74',\n",
              " '1bae4fdf-d10c-41f4-8f5d-9d6abf2185d2',\n",
              " 'c25fbdfd-d2b1-44bb-8ab7-abd40c03fc5c',\n",
              " '0a0befb5-ef62-43f1-92c4-9619f07922c8',\n",
              " '77d2a9ef-8b28-4779-8dbc-fe8bd4a37f70',\n",
              " 'd14137f0-b2b6-4e78-b000-f994f3c6c0e9',\n",
              " 'fda9fec6-70b0-4e47-ab58-57f44cdf63ed',\n",
              " 'e4ba2d51-4a7c-4a9c-b082-cb1e2c3a5a42',\n",
              " 'dda3959e-863b-45f2-bbc2-d47ebc3ca516',\n",
              " '9f18b5bc-b894-492d-883f-79154161be98']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "vector_store = FAISS(\n",
        "    embedding_function=generate_embeddings,\n",
        "    index=faiss_index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")\n",
        "\n",
        "vector_store.add_documents(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "iPfPwAqgnqd1"
      },
      "outputs": [],
      "source": [
        "vector_store.save_local(\"faiss index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "oNDlfO8Ppe1J"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\":2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-xgSK3XqcWF",
        "outputId": "4980281c-9578-437c-da3d-8c7c5942420e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In whispers woven through the fabric of night,  \n",
            "Time’s silent river flows, both swift and slight,  \n",
            "A voyage spun in threads of yesterday and morrow,  \n",
            "Where hopes and fears collide, dissolve, and borrow.\n",
            "\n",
            "A leap beyond the shadowed veil of now,  \n",
            "To moments lost, to then and future’s vow,  \n",
            "Where history’s secrets softly intertwine,  \n",
            "And every choice becomes a sacred line.\n",
            "\n",
            "Through corridors of what once might have been,  \n",
            "We chase the echoes of a distant kin,  \n",
            "A whisper of seconds, a breath so fleet—  \n",
            "Time’s endless dance, both bitter and sweet.\n",
            "\n",
            "With every tick, a universe rewrites,  \n",
            "A flash of dawn, a fall of night’s delights,  \n",
            "Boundless yet confined within its sway,  \n",
            "Time travels on, never led astray.\n",
            "\n",
            "So dream of moments yet to unfold,  \n",
            "Of stories yet to be told,  \n",
            "For in the voyage through the ages’ seam,  \n",
            "Time’s eternal river flows as a dream.\n"
          ]
        }
      ],
      "source": [
        "from euriai import EuriaiLangChainLLM\n",
        "\n",
        "llm = EuriaiLangChainLLM(\n",
        "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjNmQwZDlkMC1mNzgzLTQ3MTItOTBlYy1jYjAwZGUzNjQ5ZWMiLCJlbWFpbCI6ImhhcmlzaG5hbmRoYW4wMkBnbWFpbC5jb20iLCJpYXQiOjE3NDYzMzUzOTIsImV4cCI6MTc3Nzg3MTM5Mn0.3Q5m_zcpqTcsuwQ3prMjhFuAYa_Fy1BLapaCv93DRQ8\",\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=300\n",
        ")\n",
        "\n",
        "print(llm.invoke(\"Write a poem about time travel.\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "B30N_up4rRKo"
      },
      "outputs": [],
      "source": [
        "rag_chain = RetrievalQA.from_chain_type(llm = llm,retriever = retriever)\n",
        "# retrieval has to be extracted from the vector db - faiss we have stored there\n",
        "# llm - by using an API call / EURI API we can use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-18w3QAMrldK",
        "outputId": "92b59cea-9dc2-4a99-8ef0-603faf4df99d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-42-2566710363.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  rag_chain(\"who is sudhanshu\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'who is sudhanshu',\n",
              " 'result': 'Sudhanshu is a person from Jamshedpur, Jharkhand, India, who overcame financial hardships and challenges to pursue education. His story is one of determination and resilience, driven by the belief in the transformative power of education to improve his life and the lives of his family.'}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain(\"who is sudhanshu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYcfSPkmsJyv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
