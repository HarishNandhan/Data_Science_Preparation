{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original source: https://www.kaggle.com/code/hojjatk/read-mnist-dataset\n",
    "#It has been modified for ease of use w/ pytorch\n",
    "\n",
    "#You do NOT need to modify ANY code in this file!\n",
    "\n",
    "import numpy as np\n",
    "import struct\n",
    "from array import array\n",
    "import torch\n",
    "\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "\n",
    "    def read_images_labels(self, images_filepath, labels_filepath):\n",
    "        n = 60000 if \"train\" in images_filepath else 10000\n",
    "        labels = torch.zeros((n, 10))\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            l = torch.tensor(array(\"B\", file.read())).unsqueeze(-1)\n",
    "            l = torch.concatenate((torch.arange(0, n).unsqueeze(-1), l), dim = 1).type(torch.int32)\n",
    "            labels[l[:,0], l[:,1]] = 1\n",
    "\n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())\n",
    "        images = torch.zeros((n, 28**2))\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            #img = img.reshape(28, 28)\n",
    "            images[i, :] = torch.tensor(img)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ReLU:\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Applies the ReLU activation function.\n",
    "        ReLU(x) = max(0, x)\n",
    "        \"\"\"\n",
    "        return torch.maximum(torch.zeros_like(x), x)\n",
    "\n",
    "    def backward(self, delta: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Computes the gradient of ReLU.\n",
    "        ReLU'(x) = 1 if x > 0 else 0\n",
    "        \"\"\"\n",
    "        return delta * (x > 0).float()\n",
    "\n",
    "\n",
    "class LeakyReLU:\n",
    "    def __init__(self, alpha=0.1):\n",
    "        \"\"\"\n",
    "        Initializes the LeakyReLU activation function with a specified alpha value.\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Applies the Leaky ReLU activation function.\n",
    "        LeakyReLU(x) = x if x > 0 else alpha * x\n",
    "        \"\"\"\n",
    "        return torch.where(x >= 0, x, self.alpha * x)\n",
    "\n",
    "    def backward(self, delta: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Computes the gradient of Leaky ReLU.\n",
    "        LeakyReLU'(x) = 1 if x > 0 else alpha\n",
    "        \"\"\"\n",
    "        return delta * torch.where(x >= 0, torch.ones_like(x), self.alpha * torch.ones_like(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 218.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.3631, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 452.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 27.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 352.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.0340, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 689.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 42.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 402.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.7416, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 591.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 54.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 373.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5009, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 622.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 63.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 375.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.3047, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 778.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 69.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 430.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.1554, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 745.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 73.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 365.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.0425, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 464.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 380.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.9545, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 786.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 77.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 431.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.8842, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 648.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 79.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 360.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.8268, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 734.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 80.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 395.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.7790, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 560.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 81.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 333.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.7387, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 745.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 82.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 407.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.7039, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 723.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 83.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 404.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.6742, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 606.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 84.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 402.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.6481, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 721.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 84.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 378.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.6246, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 723.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 84.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 410.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.6039, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 674.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 85.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 394.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.5856, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 716.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 85.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 343.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.5689, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 711.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5462266802787781, Test Accuracy: 85.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 423.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.5539, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 764.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 86.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 349.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.5397, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 730.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 86.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 378.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.5270, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 728.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 86.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 389.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.5151, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 704.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 87.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 406.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.5044, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 717.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 87.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 338.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(0.4944, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 805.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 87.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class MLP:\n",
    "    '''\n",
    "    Multi-Layer Perceptron (MLP) for MNIST classification.\n",
    "    Implements forward propagation, backpropagation, and training.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, layer_sizes: list[int]):\n",
    "        self.layer_sizes: list[int] = layer_sizes\n",
    "        self.num_layers = len(layer_sizes) - 1\n",
    "        self.weights: list[torch.tensor] = []\n",
    "        self.biases: list[torch.tensor] = []\n",
    "        self.features: list[torch.tensor] = []  \n",
    "\n",
    "        self.learning_rate: float = 1\n",
    "        self.batch_size: int = 1\n",
    "        self.activation_function: callable[[torch.tensor], torch.tensor] = ReLU\n",
    "        self.lambda_l2: float = 0\n",
    "\n",
    "    def set_hp(self, lr: float, bs: int, activation: object, l2:float) -> None:\n",
    "        \"\"\"\n",
    "        Set hyperparameters for training.\n",
    "        \"\"\"\n",
    "        self.learning_rate = lr\n",
    "        self.batch_size = bs\n",
    "        self.activation_function = activation()\n",
    "        self.lambda_l2 = l2\n",
    "\n",
    "    def initialize(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize all biases to zero and weights using Xavier initialization.\n",
    "        \"\"\"\n",
    "        for i in range(self.num_layers):\n",
    "            d_in = self.layer_sizes[i]\n",
    "            d_out = self.layer_sizes[i + 1]\n",
    "            w_range = np.sqrt(6 / (d_in + d_out))\n",
    "            W = torch.empty(d_in, d_out, device=device).uniform_(-w_range, w_range)\n",
    "            self.weights.append(W)\n",
    "            b = torch.zeros(1, d_out, device=device) \n",
    "            self.biases.append(b)\n",
    "            \n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward propagation through all layers.\n",
    "        Applies activation function to all layers except the last one.\n",
    "        \"\"\"\n",
    "        self.features = [x.to(device)]  \n",
    "\n",
    "        for i in range(self.num_layers):  \n",
    "            x = torch.matmul(x, self.weights[i]) + self.biases[i]\n",
    "            x = self.activation_function.forward(x)  \n",
    "            self.features.append(x) \n",
    "        return x\n",
    "    \n",
    "    def backward(self, delta: torch.Tensor) -> None:\n",
    "        '''\n",
    "        This function should backpropagate the provided delta through the entire MLP, and update the weights according to the hyper-parameters\n",
    "        stored in the class variables.\n",
    "        '''\n",
    "        # back propogation starts from the result\n",
    "        for i in reversed(range(self.num_layers)):\n",
    "            x = self.features[i]\n",
    "\n",
    "            delta = self.activation_function.backward(delta,self.features[i+1])\n",
    "            # Computing gradients\n",
    "            dW = torch.matmul(x.T,delta) / self.batch_size + (self.lambda_l2 / self.batch_size) * self.weights[i]\n",
    "            db = torch.sum(delta, dim=0, keepdim=True) / self.batch_size\n",
    "\n",
    "            # Updating weights and biases with learning rate\n",
    "            self.weights[i] -= self.learning_rate * dW\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "            delta = torch.matmul(delta,self.weights[i].T)\n",
    "\n",
    "    # def backward(self, delta: torch.tensor) -> None:\n",
    "    #     \"\"\"\n",
    "    #     Backpropagation through all layers to compute gradients.\n",
    "    #     Updates weights using gradient descent.\n",
    "    #     \"\"\"\n",
    "    #     # grad_weights = [torch.zeros_like(w) for w in self.weights]\n",
    "    #     # grad_biases = [torch.zeros_like(b) for b in self.biases]\n",
    "\n",
    "    #     for i in reversed(range(self.num_layers)):  \n",
    "    #         X = self.features[i]\n",
    "    #         dW = torch.matmul(X.T, delta) / self.batch_size  + (self.lambda_l2 / self.batch_size) * self.weights[i]\n",
    "    #         db = torch.sum(delta,dim=0,keepdim=True) / self.batch_size\n",
    "            \n",
    "    #         self.weights[i] -= self.learning_rate * dW\n",
    "    #         self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    #         # if i > 0:\n",
    "    #         #     delta = (delta @ self.weights[i].T)\n",
    "    #         #     if i > 1:\n",
    "    #         #         delta *= self.activation_function.backward(delta,self.features[i-1])\n",
    "\n",
    "    #         delta = torch.matmul(delta, self.weights[i].T) * self.activation_function.backward(torch.ones_like(X), X)\n",
    "\n",
    "\n",
    "\n",
    "def TrainMLP(model: MLP, x_train: torch.tensor, y_train: torch.tensor) -> MLP:\n",
    "    \"\"\"\n",
    "    Train the MLP for one epoch using mini-batch gradient descent with GPU support.\n",
    "    \"\"\"\n",
    "    bs = model.batch_size\n",
    "    N = x_train.shape[0]\n",
    "    rng = np.random.default_rng()\n",
    "    idx = rng.permutation(N)\n",
    "    lambda_l2 = model.lambda_l2\n",
    "\n",
    "    L = 0  \n",
    "\n",
    "    for i in tqdm.tqdm(range(N // bs)):\n",
    "        x = x_train[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "        y = y_train[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "\n",
    "        \n",
    "        y_hat = model.forward(x)\n",
    "\n",
    "        \n",
    "        p = torch.exp(y_hat)\n",
    "        p /= torch.sum(p, dim=1, keepdim=True)\n",
    "\n",
    "        # l2 regularisation\n",
    "        l = -1 * torch.sum(y * torch.log(p))\n",
    "        l2_penalty = (model.lambda_l2 / 2) * sum(torch.sum(w**2) for w in model.weights)\n",
    "        l += l2_penalty\n",
    "        L += l\n",
    "\n",
    "        delta = p - y\n",
    "        model.backward(delta)\n",
    "\n",
    "    print(\"Train Loss:\", L / ((N // bs) * bs))\n",
    "\n",
    "\n",
    "\n",
    "def TestMLP(model: MLP, x_test: torch.tensor, y_test: torch.tensor) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the MLP on test data using GPU support.\n",
    "    \"\"\"\n",
    "    bs = model.batch_size\n",
    "    N = x_test.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    L = 0\n",
    "    A = 0\n",
    "\n",
    "    for i in tqdm.tqdm(range(N // bs)):\n",
    "        x = x_test[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "        y = y_test[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "\n",
    "        y_hat = model.forward(x)\n",
    "\n",
    "        \n",
    "        p = torch.exp(y_hat)\n",
    "        p /= torch.sum(p, dim=1, keepdim=True)\n",
    "\n",
    "        \n",
    "        l = -1 * torch.sum(y * torch.log(p))\n",
    "        L += l\n",
    "\n",
    "        \n",
    "        A += torch.sum(torch.where(torch.argmax(p, dim = 1) == torch.argmax(y, dim = 1), 1, 0))\n",
    "\n",
    "    test_loss = L / ((N // bs) * bs)\n",
    "    test_accuracy = 100 * A / ((N // bs) * bs)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    return test_loss, test_accuracy  \n",
    "\n",
    "\n",
    "def normalize_mnist() -> tuple[torch.tensor, torch.tensor, torch.tensor, torch.tensor]:\n",
    "    '''\n",
    "    This function loads the MNIST dataset, then normalizes the \"X\" values to have zero mean, unit variance.\n",
    "    '''\n",
    "\n",
    "    #IMPORTANT!!!#\n",
    "    #UPDATE THE PATH BELOW!#\n",
    "    base_path = \"C:\\\\Users\\\\yoges\\\\Data_Science_Preparation\\\\CSCI 5922 Neural Networks and Deep Learning\\\\Lab Assignments\\\\Lab1Code\\\\MNIST\\\\\"\n",
    "    #^^^^^^^^#\n",
    "\n",
    "\n",
    "    mnist = MnistDataloader(base_path + \"train-images.idx3-ubyte\", base_path + \"train-labels.idx1-ubyte\",\n",
    "                            base_path + \"t10k-images.idx3-ubyte\", base_path + \"t10k-labels.idx1-ubyte\")\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_mean = torch.mean(x_train, dim = 0, keepdim = True)\n",
    "    x_std = torch.std(x_train, dim = 0, keepdim = True)\n",
    "\n",
    "    x_train -= x_mean\n",
    "    x_train /= x_std\n",
    "    x_train[x_train != x_train] = 0\n",
    "\n",
    "    x_test -= x_mean\n",
    "    x_test /= x_std\n",
    "    x_test[x_test != x_test] = 0\n",
    "\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to train and evaluate the MLP model on MNIST using GPU.\n",
    "    \"\"\"\n",
    "    x_train, y_train, x_test, y_test = normalize_mnist()\n",
    "\n",
    "   \n",
    "    model = MLP([784, 256, 10])  \n",
    "    model.initialize()\n",
    "    model.set_hp(lr=1e-3, bs=512, activation=ReLU, l2 = 0.001)  \n",
    "    \n",
    "    E = 25\n",
    "    for _ in range(E):\n",
    "        TrainMLP(model, x_train, y_train)\n",
    "        TestMLP(model, x_test, y_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
