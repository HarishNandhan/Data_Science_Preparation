{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg8BSVK4OcFx"
      },
      "source": [
        "# Lab Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pit0BSlkOfcw"
      },
      "source": [
        "Student name: Harish Nandhan Shanmugam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXp58l3vrC1L"
      },
      "source": [
        "## Notebook version\n",
        "\n",
        "This notebook includes all the codes in the codebase of lab assignment 1. Completing and submitting this script is equivalent to submitting the codebase. Please note that your submitted script should include errorless cell outputs that contain necessary information that proves you have successfully run the notebook in your own directory.\n",
        "\n",
        "You can choose to (1) run this notebook locally on your end or (2) run this notebook on colab. For the former, you will need to download the dataset to your device that resembles the instructions for the codebase. For the latter, **you will need to upload the dataset to your Google Drive** account, and connect your colab notebook to your Google Drive. Then, go to \"File->Save a copy in Drive\" to create a copy you can edit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWOk8c6QstJ2"
      },
      "source": [
        "#### Colab (if applicable)\n",
        "\n",
        "If you are running this script on colab, uncomment and run the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OATj2nvHs2O1"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of GPU:  1\n",
            "GPU Name:  NVIDIA GeForce RTX 3060 Laptop GPU\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"Number of GPU: \", torch.cuda.device_count())\n",
        "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHvOW4Qxs30Y"
      },
      "source": [
        "Note that the Google Drive directory has the root `/content/drive/`. For instance, my directory to the dataset is `'/content/drive/My Drive/Courses/CSCI 5922/CSCI 5922 SP25/Demo/MNIST/'`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ufLsFPnq6gu"
      },
      "source": [
        "### mnist.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nqaf3LuXOa1c"
      },
      "outputs": [],
      "source": [
        "#Original source: https://www.kaggle.com/code/hojjatk/read-mnist-dataset\n",
        "#It has been modified for ease of use w/ pytorch\n",
        "\n",
        "#You do NOT need to modify ANY code in this file!\n",
        "\n",
        "import numpy as np\n",
        "import struct\n",
        "from array import array\n",
        "import torch\n",
        "\n",
        "class MnistDataloader(object):\n",
        "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
        "                 test_images_filepath, test_labels_filepath):\n",
        "        self.training_images_filepath = training_images_filepath\n",
        "        self.training_labels_filepath = training_labels_filepath\n",
        "        self.test_images_filepath = test_images_filepath\n",
        "        self.test_labels_filepath = test_labels_filepath\n",
        "\n",
        "    def read_images_labels(self, images_filepath, labels_filepath):\n",
        "        n = 60000 if \"train\" in images_filepath else 10000\n",
        "        labels = torch.zeros((n, 10))\n",
        "        with open(labels_filepath, 'rb') as file:\n",
        "            magic, size = struct.unpack(\">II\", file.read(8))\n",
        "            if magic != 2049:\n",
        "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
        "            l = torch.tensor(array(\"B\", file.read())).unsqueeze(-1)\n",
        "            l = torch.concatenate((torch.arange(0, n).unsqueeze(-1), l), dim = 1).type(torch.int32)\n",
        "            labels[l[:,0], l[:,1]] = 1\n",
        "\n",
        "        with open(images_filepath, 'rb') as file:\n",
        "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
        "            if magic != 2051:\n",
        "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
        "            image_data = array(\"B\", file.read())\n",
        "        images = torch.zeros((n, 28**2))\n",
        "        for i in range(size):\n",
        "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
        "            #img = img.reshape(28, 28)\n",
        "            images[i, :] = torch.tensor(img)\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "    def load_data(self):\n",
        "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
        "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
        "        return (x_train, y_train),(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpKgf2fMquMh"
      },
      "source": [
        "### activations.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WuJUuwXrOoVg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class ReLU:\n",
        "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
        "        \"\"\"\n",
        "        Applies the ReLU activation function.\n",
        "        ReLU(x) = max(0, x)\n",
        "        \"\"\"\n",
        "        return torch.maximum(torch.zeros_like(x), x)\n",
        "\n",
        "    def backward(self, delta: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
        "        \"\"\"\n",
        "        Computes the gradient of ReLU.\n",
        "        ReLU'(x) = 1 if x > 0 else 0\n",
        "        \"\"\"\n",
        "        return delta * (x > 0).float()\n",
        "\n",
        "\n",
        "class LeakyReLU:\n",
        "    def __init__(self, alpha=0.1):\n",
        "        \"\"\"\n",
        "        Initializes the LeakyReLU activation function with a specified alpha value.\n",
        "        \"\"\"\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
        "        \"\"\"\n",
        "        Applies the Leaky ReLU activation function.\n",
        "        LeakyReLU(x) = x if x > 0 else alpha * x\n",
        "        \"\"\"\n",
        "        return torch.where(x >= 0, x, self.alpha * x)\n",
        "\n",
        "    def backward(self, delta: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
        "        \"\"\"\n",
        "        Computes the gradient of Leaky ReLU.\n",
        "        LeakyReLU'(x) = 1 if x > 0 else alpha\n",
        "        \"\"\"\n",
        "        return delta * torch.where(x >= 0, torch.ones_like(x), self.alpha * torch.ones_like(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L2zEHN7qxuh"
      },
      "source": [
        "### framework.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 286.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(2.4927, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 439.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 16.19%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 423.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(2.2616, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 487.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 22.76%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 443.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(2.1270, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 683.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 29.14%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 487.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(2.0020, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 797.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 37.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 457.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(1.8385, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 728.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 49.77%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 490.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(1.6241, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 730.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 60.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 443.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(1.4065, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 622.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 67.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 459.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(1.2290, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 700.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 71.60%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 460.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(1.0949, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 722.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 75.04%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 407.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.9938, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 463.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 77.22%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 399.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.9153, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 789.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 79.29%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 469.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.8529, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 612.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 80.61%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 469.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.8012, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 697.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 81.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 482.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.7583, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 530.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 82.46%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 497.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.7218, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 354.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 83.22%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 412.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.6902, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 524.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 83.61%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 469.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.6626, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 706.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 84.32%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 481.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.6380, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 673.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 84.93%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 492.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.6166, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 746.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 85.30%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 436.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.5971, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 623.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 85.67%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 476.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.5796, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 712.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 86.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 471.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.5640, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 668.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 86.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 478.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.5495, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 571.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 86.74%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 441.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.5364, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 479.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 86.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 117/117 [00:00<00:00, 417.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: tensor(0.5243, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 712.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: nan, Test Accuracy: 87.21%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class MLP:\n",
        "    '''\n",
        "    Multi-Layer Perceptron (MLP) for MNIST classification.\n",
        "    Implements forward propagation, backpropagation, and training.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, layer_sizes: list[int]):\n",
        "        self.layer_sizes: list[int] = layer_sizes\n",
        "        self.num_layers = len(layer_sizes) - 1\n",
        "        self.weights: list[torch.tensor] = []\n",
        "        self.biases: list[torch.tensor] = []\n",
        "        self.features: list[torch.tensor] = []  \n",
        "\n",
        "        self.learning_rate: float = 1\n",
        "        self.batch_size: int = 1\n",
        "        self.activation_function: callable[[torch.tensor], torch.tensor] = ReLU\n",
        "\n",
        "    def set_hp(self, lr: float, bs: int, activation: object) -> None:\n",
        "        \"\"\"\n",
        "        Set hyperparameters for training.\n",
        "        \"\"\"\n",
        "        self.learning_rate = lr\n",
        "        self.batch_size = bs\n",
        "        self.activation_function = activation()\n",
        "\n",
        "    def initialize(self) -> None:\n",
        "        \"\"\"\n",
        "        Initialize all biases to zero and weights using Xavier initialization.\n",
        "        \"\"\"\n",
        "        for i in range(self.num_layers):\n",
        "            d_in = self.layer_sizes[i]\n",
        "            d_out = self.layer_sizes[i + 1]\n",
        "            w_range = np.sqrt(6 / (d_in + d_out))\n",
        "            W = torch.empty(d_in, d_out, device=device).uniform_(-w_range, w_range)\n",
        "            self.weights.append(W)\n",
        "            b = torch.zeros(1, d_out, device=device) \n",
        "            self.biases.append(b)\n",
        "            \n",
        "\n",
        "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
        "        \"\"\"\n",
        "        Forward propagation through all layers.\n",
        "        Applies activation function to all layers except the last one.\n",
        "        \"\"\"\n",
        "        self.features = [x.to(device)]  \n",
        "\n",
        "        for i in range(self.num_layers):  \n",
        "            x = torch.matmul(x, self.weights[i]) + self.biases[i]\n",
        "            x = self.activation_function.forward(x)  \n",
        "            self.features.append(x) \n",
        "        return x\n",
        "    \n",
        "    def backward(self, delta: torch.Tensor) -> None:\n",
        "        '''\n",
        "        This function should backpropagate the provided delta through the entire MLP, and update the weights according to the hyper-parameters\n",
        "        stored in the class variables.\n",
        "        '''\n",
        "        # back propogation starts from the result\n",
        "        for i in reversed(range(self.num_layers)):\n",
        "            x = self.features[i]\n",
        "\n",
        "            delta = self.activation_function.backward(delta,self.features[i+1])\n",
        "            # Computing gradients\n",
        "            dW = torch.matmul(x.T,delta) / self.batch_size\n",
        "            db = torch.sum(delta, dim=0, keepdim=True) / self.batch_size\n",
        "\n",
        "            # Updating weights and biases with learning rate\n",
        "            self.weights[i] -= self.learning_rate * dW\n",
        "            self.biases[i] -= self.learning_rate * db\n",
        "            delta = torch.matmul(delta,self.weights[i].T)\n",
        "\n",
        "    # def backward(self, delta: torch.tensor) -> None:\n",
        "    #     \"\"\"\n",
        "    #     Backpropagation through all layers to compute gradients.\n",
        "    #     Updates weights using gradient descent.\n",
        "    #     \"\"\"\n",
        "    #     # grad_weights = [torch.zeros_like(w) for w in self.weights]\n",
        "    #     # grad_biases = [torch.zeros_like(b) for b in self.biases]\n",
        "\n",
        "    #     for i in reversed(range(self.num_layers)):  \n",
        "    #         X = self.features[i]\n",
        "    #         dW = torch.matmul(X.T, delta) / self.batch_size  \n",
        "    #         db = torch.sum(delta,dim=0,keepdim=True) / self.batch_size\n",
        "            \n",
        "    #         self.weights[i] -= self.learning_rate * dW\n",
        "    #         self.biases[i] -= self.learning_rate * db\n",
        "\n",
        "    #         # if i > 0:\n",
        "    #         #     delta = (delta @ self.weights[i].T)\n",
        "    #         #     if i > 1:\n",
        "    #         #         delta *= self.activation_function.backward(delta,self.features[i-1])\n",
        "\n",
        "    #         delta = torch.matmul(delta, self.weights[i].T) * self.activation_function.backward(torch.ones_like(X), X)\n",
        "\n",
        "    # def backward(self, delta: torch.tensor) -> None:\n",
        "    #     for i in reversed(range(self.num_layers)):  \n",
        "    #         X = self.features[i]\n",
        "    #         dW = torch.matmul(X.T, delta) / self.batch_size  \n",
        "    #         db = torch.sum(delta, dim=0, keepdim=True) / self.batch_size\n",
        "\n",
        "    #         self.weights[i] -= self.learning_rate * dW\n",
        "    #         self.biases[i] -= self.learning_rate * db\n",
        "\n",
        "    #         if i > 0:  # Skip activation function for the input layer\n",
        "    #             delta = torch.matmul(delta, self.weights[i].T)\n",
        "\n",
        "    #         # ✅ Ensure shapes match for element-wise multiplication\n",
        "    #             delta *= self.activation_function.backward(delta, X)  \n",
        "\n",
        "\n",
        "def TrainMLP(model: MLP, x_train: torch.tensor, y_train: torch.tensor) -> MLP:\n",
        "    \"\"\"\n",
        "    Train the MLP for one epoch using mini-batch gradient descent with GPU support.\n",
        "    \"\"\"\n",
        "    bs = model.batch_size\n",
        "    N = x_train.shape[0]\n",
        "    rng = np.random.default_rng()\n",
        "    idx = rng.permutation(N)\n",
        "\n",
        "    L = 0  \n",
        "\n",
        "    for i in tqdm.tqdm(range(N // bs)):\n",
        "        x = x_train[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
        "        y = y_train[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
        "\n",
        "        \n",
        "        y_hat = model.forward(x)\n",
        "\n",
        "        \n",
        "        p = torch.exp(y_hat)\n",
        "        p /= torch.sum(p, dim=1, keepdim=True)\n",
        "\n",
        "        \n",
        "        l = -1 * torch.sum(y * torch.log(p)) ### batch size not required here\n",
        "        L += l\n",
        "\n",
        "       \n",
        "        delta = p - y\n",
        "        model.backward(delta)\n",
        "\n",
        "    print(\"Train Loss:\", L / ((N // bs) * bs))\n",
        "\n",
        "\n",
        "\n",
        "def TestMLP(model: MLP, x_test: torch.tensor, y_test: torch.tensor) -> tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Evaluate the MLP on test data using GPU support.\n",
        "    \"\"\"\n",
        "    bs = model.batch_size\n",
        "    N = x_test.shape[0]\n",
        "\n",
        "    rng = np.random.default_rng()\n",
        "    idx = rng.permutation(N)\n",
        "\n",
        "    L = 0\n",
        "    A = 0\n",
        "\n",
        "    for i in tqdm.tqdm(range(N // bs)):\n",
        "        x = x_test[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
        "        y = y_test[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
        "\n",
        "        y_hat = model.forward(x)\n",
        "\n",
        "        \n",
        "        p = torch.exp(y_hat)\n",
        "        p /= torch.sum(p, dim=1, keepdim=True)\n",
        "\n",
        "        \n",
        "        l = -1 * torch.sum(y * torch.log(p))\n",
        "        L += l.item()\n",
        "\n",
        "        \n",
        "        A += torch.sum(torch.argmax(p, dim=1) == torch.argmax(y, dim=1)).item()\n",
        "\n",
        "    test_loss = L / ((N // bs) * bs)\n",
        "    test_accuracy = 100 * A / ((N // bs) * bs)\n",
        "\n",
        "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    return test_loss, test_accuracy  \n",
        "\n",
        "\n",
        "def normalize_mnist() -> tuple[torch.tensor, torch.tensor, torch.tensor, torch.tensor]:\n",
        "    '''\n",
        "    This function loads the MNIST dataset, then normalizes the \"X\" values to have zero mean, unit variance.\n",
        "    '''\n",
        "\n",
        "    #IMPORTANT!!!#\n",
        "    #UPDATE THE PATH BELOW!#\n",
        "    base_path = \"C:\\\\Users\\\\yoges\\\\Data_Science_Preparation\\\\CSCI 5922 Neural Networks and Deep Learning\\\\Lab Assignments\\\\Lab1Code\\\\MNIST\\\\\"\n",
        "    #^^^^^^^^#\n",
        "\n",
        "\n",
        "    mnist = MnistDataloader(base_path + \"train-images.idx3-ubyte\", base_path + \"train-labels.idx1-ubyte\",\n",
        "                            base_path + \"t10k-images.idx3-ubyte\", base_path + \"t10k-labels.idx1-ubyte\")\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    x_mean = torch.mean(x_train, dim = 0, keepdim = True)\n",
        "    x_std = torch.std(x_train, dim = 0, keepdim = True)\n",
        "\n",
        "    x_train -= x_mean\n",
        "    x_train /= x_std\n",
        "    x_train[x_train != x_train] = 0\n",
        "\n",
        "    x_test -= x_mean\n",
        "    x_test /= x_std\n",
        "    x_test[x_test != x_test] = 0\n",
        "\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to train and evaluate the MLP model on MNIST using GPU.\n",
        "    \"\"\"\n",
        "    x_train, y_train, x_test, y_test = normalize_mnist()\n",
        "\n",
        "   \n",
        "    model = MLP([784, 256, 10])  \n",
        "    model.initialize()\n",
        "    model.set_hp(lr=1e-3, bs=512, activation=ReLU)  \n",
        "    \n",
        "    E = 25\n",
        "    for _ in range(E):\n",
        "        TrainMLP(model, x_train, y_train)\n",
        "        TestMLP(model, x_test, y_test)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
