{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original source: https://www.kaggle.com/code/hojjatk/read-mnist-dataset\n",
    "#It has been modified for ease of use w/ pytorch\n",
    "\n",
    "#You do NOT need to modify ANY code in this file!\n",
    "\n",
    "import numpy as np\n",
    "import struct\n",
    "from array import array\n",
    "import torch\n",
    "\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "\n",
    "    def read_images_labels(self, images_filepath, labels_filepath):\n",
    "        n = 60000 if \"train\" in images_filepath else 10000\n",
    "        labels = torch.zeros((n, 10))\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            l = torch.tensor(array(\"B\", file.read())).unsqueeze(-1)\n",
    "            l = torch.concatenate((torch.arange(0, n).unsqueeze(-1), l), dim = 1).type(torch.int32)\n",
    "            labels[l[:,0], l[:,1]] = 1\n",
    "\n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())\n",
    "        images = torch.zeros((n, 28**2))\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            #img = img.reshape(28, 28)\n",
    "            images[i, :] = torch.tensor(img)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Tanh:\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return  (torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x))\n",
    "    \n",
    "    def backward(self, delta: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
    "        tanh_org = (torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x))\n",
    "        tanh_derivative = 1 - tanh_org * tanh_org\n",
    "        return delta * tanh_derivative\n",
    "\n",
    "class Sigmoid:\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "    \n",
    "    def backward(self, delta: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
    "        sig_x_org = 1 / (1 + torch.exp(-x))\n",
    "        sig_x_derivative = (sig_x_org * (1 - sig_x_org))\n",
    "        return delta * sig_x_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 227.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.1271, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 482.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 37.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 330.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.8806, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 483.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 51.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 367.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.7484, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 595.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 59.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 353.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.6745, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 529.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 64.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 342.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.6295, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 532.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 68.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 331.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5997, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 559.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 71.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 351.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5786, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 543.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 72.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 365.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5628, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 553.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 73.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 357.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5506, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 522.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 74.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 317.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5409, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 602.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 75.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 358.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5332, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 562.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 75.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 371.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5268, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 565.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 75.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 365.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5215, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 557.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 315.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5171, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 579.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 347.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5137, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 574.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 360.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5106, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 501.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 300.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5082, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 617.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 319.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5060, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 445.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 367.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5043, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 591.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 359.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5026, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 503.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 336.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5013, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 582.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 347.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.5003, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 555.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 309.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.4994, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 611.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 76.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 364.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.4986, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 539.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 77.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 338.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(1.4979, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 606.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 77.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class MLP:\n",
    "    '''\n",
    "    Multi-Layer Perceptron (MLP) for MNIST classification.\n",
    "    Implements forward propagation, backpropagation, and training.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, layer_sizes: list[int]):\n",
    "        self.layer_sizes: list[int] = layer_sizes\n",
    "        self.num_layers = len(layer_sizes) - 1\n",
    "        self.weights: list[torch.tensor] = []\n",
    "        self.biases: list[torch.tensor] = []\n",
    "        self.features: list[torch.tensor] = []  \n",
    "\n",
    "        self.learning_rate: float = 1\n",
    "        self.batch_size: int = 1\n",
    "        self.activation_function: callable[[torch.tensor], torch.tensor] = Tanh\n",
    "\n",
    "    def set_hp(self, lr: float, bs: int, activation: object) -> None:\n",
    "        \"\"\"\n",
    "        Set hyperparameters for training.\n",
    "        \"\"\"\n",
    "        self.learning_rate = lr\n",
    "        self.batch_size = bs\n",
    "        self.activation_function = activation()\n",
    "\n",
    "    def initialize(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize all biases to zero and weights using Xavier initialization.\n",
    "        \"\"\"\n",
    "        for i in range(self.num_layers):\n",
    "            d_in = self.layer_sizes[i]\n",
    "            d_out = self.layer_sizes[i + 1]\n",
    "            w_range = np.sqrt(6 / (d_in + d_out))\n",
    "            W = torch.empty(d_in, d_out, device=device).uniform_(-w_range, w_range)\n",
    "            self.weights.append(W)\n",
    "            b = torch.zeros(1, d_out, device=device) \n",
    "            self.biases.append(b)\n",
    "            \n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward propagation through all layers.\n",
    "        Applies activation function to all layers except the last one.\n",
    "        \"\"\"\n",
    "        self.features = [x.to(device)]  \n",
    "\n",
    "        for i in range(self.num_layers):  \n",
    "            x = torch.matmul(x, self.weights[i]) + self.biases[i]\n",
    "            x = self.activation_function.forward(x)  \n",
    "            self.features.append(x) \n",
    "        return x\n",
    "\n",
    "    def backward(self, delta: torch.Tensor) -> None:\n",
    "        '''\n",
    "        This function should backpropagate the provided delta through the entire MLP, and update the weights according to the hyper-parameters\n",
    "        stored in the class variables.\n",
    "        '''\n",
    "        # back propogation starts from the result\n",
    "        for i in reversed(range(self.num_layers)):\n",
    "            x = self.features[i]\n",
    "\n",
    "            delta = self.activation_function.backward(delta,self.features[i+1])\n",
    "            # Computing gradients\n",
    "            dW = torch.matmul(x.T,delta) / self.batch_size\n",
    "            db = torch.sum(delta, dim=0, keepdim=True) / self.batch_size\n",
    "\n",
    "            # Updating weights and biases with learning rate\n",
    "            self.weights[i] -= self.learning_rate * dW\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "            delta = torch.matmul(delta,self.weights[i].T)\n",
    "\n",
    "    # def backward(self, delta: torch.tensor) -> None:\n",
    "    #     \"\"\"\n",
    "    #     Backpropagation through all layers to compute gradients.\n",
    "    #     Updates weights using gradient descent.\n",
    "    #     \"\"\"\n",
    "    #     # grad_weights = [torch.zeros_like(w) for w in self.weights]\n",
    "    #     # grad_biases = [torch.zeros_like(b) for b in self.biases]\n",
    "\n",
    "    #     for i in reversed(range(self.num_layers)):  \n",
    "    #         X = self.features[i]\n",
    "    #         dW = torch.matmul(X.T, delta) / self.batch_size  \n",
    "    #         db = torch.sum(delta,dim=0,keepdim=True) / self.batch_size\n",
    "            \n",
    "    #         self.weights[i] -= self.learning_rate * dW\n",
    "    #         self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    #         # if i > 0:\n",
    "    #         #     delta = (delta @ self.weights[i].T)\n",
    "    #         #     if i > 1:\n",
    "    #         #         delta *= self.activation_function.backward(delta,self.features[i-1])\n",
    "\n",
    "    #         delta = torch.matmul(delta, self.weights[i].T) * self.activation_function.backward(torch.ones_like(X), X)\n",
    "\n",
    "\n",
    "\n",
    "def TrainMLP(model: MLP, x_train: torch.tensor, y_train: torch.tensor) -> MLP:\n",
    "    \"\"\"\n",
    "    Train the MLP for one epoch using mini-batch gradient descent with GPU support.\n",
    "    \"\"\"\n",
    "    bs = model.batch_size\n",
    "    N = x_train.shape[0]\n",
    "    rng = np.random.default_rng()\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    L = 0  \n",
    "\n",
    "    for i in tqdm.tqdm(range(N // bs)):\n",
    "        x = x_train[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "        y = y_train[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "\n",
    "        \n",
    "        y_hat = model.forward(x)\n",
    "\n",
    "        \n",
    "        p = torch.exp(y_hat)\n",
    "        p /= torch.sum(p, dim=1, keepdim=True)\n",
    "\n",
    "        \n",
    "        l = -1 * torch.sum(y * torch.log(p)) ### batch size not required here\n",
    "        L += l\n",
    "\n",
    "       \n",
    "        delta = p - y\n",
    "        model.backward(delta)\n",
    "\n",
    "    print(\"Train Loss:\", L / ((N // bs) * bs))\n",
    "\n",
    "\n",
    "\n",
    "def TestMLP(model: MLP, x_test: torch.tensor, y_test: torch.tensor) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the MLP on test data using GPU support.\n",
    "    \"\"\"\n",
    "    bs = model.batch_size\n",
    "    N = x_test.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    L = 0\n",
    "    A = 0\n",
    "\n",
    "    for i in tqdm.tqdm(range(N // bs)):\n",
    "        x = x_test[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "        y = y_test[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "\n",
    "        y_hat = model.forward(x)\n",
    "\n",
    "        \n",
    "        p = torch.exp(y_hat)\n",
    "        p /= torch.sum(p, dim=1, keepdim=True)\n",
    "\n",
    "        \n",
    "        l = -1 * torch.sum(y * torch.log(p))\n",
    "        L += l.item()\n",
    "\n",
    "        \n",
    "        A += torch.sum(torch.argmax(p, dim=1) == torch.argmax(y, dim=1)).item()\n",
    "\n",
    "    test_loss = L / ((N // bs) * bs)\n",
    "    test_accuracy = 100 * A / ((N // bs) * bs)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    return test_loss, test_accuracy  \n",
    "\n",
    "\n",
    "def normalize_mnist() -> tuple[torch.tensor, torch.tensor, torch.tensor, torch.tensor]:\n",
    "    '''\n",
    "    This function loads the MNIST dataset, then normalizes the \"X\" values to have zero mean, unit variance.\n",
    "    '''\n",
    "\n",
    "    #IMPORTANT!!!#\n",
    "    #UPDATE THE PATH BELOW!#\n",
    "    base_path = \"C:\\\\Users\\\\yoges\\\\Data_Science_Preparation\\\\CSCI 5922 Neural Networks and Deep Learning\\\\Lab Assignments\\\\Lab1Code\\\\MNIST\\\\\"\n",
    "    #^^^^^^^^#\n",
    "\n",
    "\n",
    "    mnist = MnistDataloader(base_path + \"train-images.idx3-ubyte\", base_path + \"train-labels.idx1-ubyte\",\n",
    "                            base_path + \"t10k-images.idx3-ubyte\", base_path + \"t10k-labels.idx1-ubyte\")\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_mean = torch.mean(x_train, dim = 0, keepdim = True)\n",
    "    x_std = torch.std(x_train, dim = 0, keepdim = True)\n",
    "\n",
    "    x_train -= x_mean\n",
    "    x_train /= x_std\n",
    "    x_train[x_train != x_train] = 0\n",
    "\n",
    "    x_test -= x_mean\n",
    "    x_test /= x_std\n",
    "    x_test[x_test != x_test] = 0\n",
    "\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to train and evaluate the MLP model on MNIST using GPU.\n",
    "    \"\"\"\n",
    "    x_train, y_train, x_test, y_test = normalize_mnist()\n",
    "\n",
    "   \n",
    "    model = MLP([784, 256, 10])  \n",
    "    model.initialize()\n",
    "    model.set_hp(lr=1e-3, bs=512, activation=Tanh)  \n",
    "    \n",
    "    E = 25\n",
    "    for _ in range(E):\n",
    "        TrainMLP(model, x_train, y_train)\n",
    "        TestMLP(model, x_test, y_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
