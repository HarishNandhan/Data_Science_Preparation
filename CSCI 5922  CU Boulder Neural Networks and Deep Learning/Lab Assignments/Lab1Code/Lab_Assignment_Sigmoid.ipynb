{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original source: https://www.kaggle.com/code/hojjatk/read-mnist-dataset\n",
    "#It has been modified for ease of use w/ pytorch\n",
    "\n",
    "#You do NOT need to modify ANY code in this file!\n",
    "\n",
    "import numpy as np\n",
    "import struct\n",
    "from array import array\n",
    "import torch\n",
    "\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "\n",
    "    def read_images_labels(self, images_filepath, labels_filepath):\n",
    "        n = 60000 if \"train\" in images_filepath else 10000\n",
    "        labels = torch.zeros((n, 10))\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            l = torch.tensor(array(\"B\", file.read())).unsqueeze(-1)\n",
    "            l = torch.concatenate((torch.arange(0, n).unsqueeze(-1), l), dim = 1).type(torch.int32)\n",
    "            labels[l[:,0], l[:,1]] = 1\n",
    "\n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())\n",
    "        images = torch.zeros((n, 28**2))\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            #img = img.reshape(28, 28)\n",
    "            images[i, :] = torch.tensor(img)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Tanh:\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return  (torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x))\n",
    "    \n",
    "    def backward(self, delta: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
    "        tanh_org = (torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x))\n",
    "        tanh_derivative = 1 - tanh_org * tanh_org\n",
    "        return delta * tanh_derivative\n",
    "\n",
    "class Sigmoid:\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "    \n",
    "    def backward(self, delta: torch.tensor, x: torch.tensor) -> torch.tensor:\n",
    "        sig_x_org = 1 / (1 + torch.exp(-x))\n",
    "        sig_x_derivative = (sig_x_org * (1 - sig_x_org))\n",
    "        return delta * sig_x_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 238.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.3170, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 495.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 13.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 393.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.3106, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 590.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 14.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 408.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.3043, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 557.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 14.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 385.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2979, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 580.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 15.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 343.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2915, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 605.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 17.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 405.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2852, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 482.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 18.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 382.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2789, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 603.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 19.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 393.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2726, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 601.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 20.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 373.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2664, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 602.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 22.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 427.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2602, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 621.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 23.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 388.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2540, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 589.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 24.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 387.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2480, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 547.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 26.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 378.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2419, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 590.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 27.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 398.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2359, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 611.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 29.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 400.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2300, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 563.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 31.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 391.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2240, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 597.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 33.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 372.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2182, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 581.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 35.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 355.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2125, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 517.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 37.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 323.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2067, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 674.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 39.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 378.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.2011, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 658.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 41.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 374.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.1955, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 521.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 42.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 371.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.1900, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 625.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 44.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 385.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.1844, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 394.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 45.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 385.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.1791, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 644.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 46.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 358.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: tensor(2.1737, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 597.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan, Test Accuracy: 47.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class MLP:\n",
    "    '''\n",
    "    Multi-Layer Perceptron (MLP) for MNIST classification.\n",
    "    Implements forward propagation, backpropagation, and training.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, layer_sizes: list[int]):\n",
    "        self.layer_sizes: list[int] = layer_sizes\n",
    "        self.num_layers = len(layer_sizes) - 1\n",
    "        self.weights: list[torch.tensor] = []\n",
    "        self.biases: list[torch.tensor] = []\n",
    "        self.features: list[torch.tensor] = []  \n",
    "\n",
    "        self.learning_rate: float = 1\n",
    "        self.batch_size: int = 1\n",
    "        self.activation_function: callable[[torch.tensor], torch.tensor] = Sigmoid\n",
    "\n",
    "    def set_hp(self, lr: float, bs: int, activation: object) -> None:\n",
    "        \"\"\"\n",
    "        Set hyperparameters for training.\n",
    "        \"\"\"\n",
    "        self.learning_rate = lr\n",
    "        self.batch_size = bs\n",
    "        self.activation_function = activation()\n",
    "\n",
    "    def initialize(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize all biases to zero and weights using Xavier initialization.\n",
    "        \"\"\"\n",
    "        for i in range(self.num_layers):\n",
    "            d_in = self.layer_sizes[i]\n",
    "            d_out = self.layer_sizes[i + 1]\n",
    "            w_range = np.sqrt(6 / (d_in + d_out))\n",
    "            W = torch.empty(d_in, d_out, device=device).uniform_(-w_range, w_range)\n",
    "            self.weights.append(W)\n",
    "            b = torch.zeros(1, d_out, device=device) \n",
    "            self.biases.append(b)\n",
    "            \n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward propagation through all layers.\n",
    "        Applies activation function to all layers except the last one.\n",
    "        \"\"\"\n",
    "        self.features = [x.to(device)]  \n",
    "\n",
    "        for i in range(self.num_layers):  \n",
    "            x = torch.matmul(x, self.weights[i]) + self.biases[i]\n",
    "            x = self.activation_function.forward(x)  \n",
    "            self.features.append(x) \n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "    def backward(self, delta: torch.Tensor) -> None:\n",
    "        '''\n",
    "        This function should backpropagate the provided delta through the entire MLP, and update the weights according to the hyper-parameters\n",
    "        stored in the class variables.\n",
    "        '''\n",
    "        # back propogation starts from the result\n",
    "        for i in reversed(range(self.num_layers)):\n",
    "            x = self.features[i]\n",
    "\n",
    "            delta = self.activation_function.backward(delta,self.features[i+1])\n",
    "            # Computing gradients\n",
    "            dW = torch.matmul(x.T,delta) / self.batch_size\n",
    "            db = torch.sum(delta, dim=0, keepdim=True) / self.batch_size\n",
    "\n",
    "            # Updating weights and biases with learning rate\n",
    "            self.weights[i] -= self.learning_rate * dW\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "            delta = torch.matmul(delta,self.weights[i].T)\n",
    "\n",
    "    # def backward(self, delta: torch.tensor) -> None:\n",
    "    #     \"\"\"\n",
    "    #     Backpropagation through all layers to compute gradients.\n",
    "    #     Updates weights using gradient descent.\n",
    "    #     \"\"\"\n",
    "    #     # grad_weights = [torch.zeros_like(w) for w in self.weights]\n",
    "    #     # grad_biases = [torch.zeros_like(b) for b in self.biases]\n",
    "\n",
    "    #     for i in reversed(range(self.num_layers)):  \n",
    "    #         X = self.features[i]\n",
    "    #         dW = torch.matmul(X.T, delta) / self.batch_size  \n",
    "    #         db = torch.sum(delta,dim=0,keepdim=True) / self.batch_size\n",
    "            \n",
    "    #         self.weights[i] -= self.learning_rate * dW\n",
    "    #         self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    #         # if i > 0:\n",
    "    #         #     delta = (delta @ self.weights[i].T)\n",
    "    #         #     if i > 1:\n",
    "    #         #         delta *= self.activation_function.backward(delta,self.features[i-1])\n",
    "\n",
    "    #         delta = torch.matmul(delta, self.weights[i].T) * self.activation_function.backward(torch.ones_like(X), X)\n",
    "\n",
    "\n",
    "\n",
    "def TrainMLP(model: MLP, x_train: torch.tensor, y_train: torch.tensor) -> MLP:\n",
    "    \"\"\"\n",
    "    Train the MLP for one epoch using mini-batch gradient descent with GPU support.\n",
    "    \"\"\"\n",
    "    bs = model.batch_size\n",
    "    N = x_train.shape[0]\n",
    "    rng = np.random.default_rng()\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    L = 0  \n",
    "\n",
    "    for i in tqdm.tqdm(range(N // bs)):\n",
    "        x = x_train[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "        y = y_train[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "\n",
    "        \n",
    "        y_hat = model.forward(x)\n",
    "\n",
    "        \n",
    "        p = torch.exp(y_hat)\n",
    "        p /= torch.sum(p, dim=1, keepdim=True)\n",
    "\n",
    "        \n",
    "        l = -1 * torch.sum(y * torch.log(p)) ### batch size not required here\n",
    "        L += l\n",
    "\n",
    "       \n",
    "        delta = p - y\n",
    "        model.backward(delta)\n",
    "\n",
    "    print(\"Train Loss:\", L / ((N // bs) * bs))\n",
    "\n",
    "\n",
    "\n",
    "def TestMLP(model: MLP, x_test: torch.tensor, y_test: torch.tensor) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the MLP on test data using GPU support.\n",
    "    \"\"\"\n",
    "    bs = model.batch_size\n",
    "    N = x_test.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    idx = rng.permutation(N)\n",
    "\n",
    "    L = 0\n",
    "    A = 0\n",
    "\n",
    "    for i in tqdm.tqdm(range(N // bs)):\n",
    "        x = x_test[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "        y = y_test[idx[i * bs:(i + 1) * bs], ...].to(device)\n",
    "\n",
    "        y_hat = model.forward(x)\n",
    "\n",
    "        \n",
    "        p = torch.exp(y_hat)\n",
    "        p /= torch.sum(p, dim=1, keepdim=True)\n",
    "\n",
    "        \n",
    "        l = -1 * torch.sum(y * torch.log(p))\n",
    "        L += l.item()\n",
    "\n",
    "        \n",
    "        A += torch.sum(torch.argmax(p, dim=1) == torch.argmax(y, dim=1)).item()\n",
    "\n",
    "    test_loss = L / ((N // bs) * bs)\n",
    "    test_accuracy = 100 * A / ((N // bs) * bs)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    return test_loss, test_accuracy  \n",
    "\n",
    "\n",
    "def normalize_mnist() -> tuple[torch.tensor, torch.tensor, torch.tensor, torch.tensor]:\n",
    "    '''\n",
    "    This function loads the MNIST dataset, then normalizes the \"X\" values to have zero mean, unit variance.\n",
    "    '''\n",
    "\n",
    "    #IMPORTANT!!!#\n",
    "    #UPDATE THE PATH BELOW!#\n",
    "    base_path = \"C:\\\\Users\\\\yoges\\\\Data_Science_Preparation\\\\CSCI 5922 Neural Networks and Deep Learning\\\\Lab Assignments\\\\Lab1Code\\\\MNIST\\\\\"\n",
    "    #^^^^^^^^#\n",
    "\n",
    "\n",
    "    mnist = MnistDataloader(base_path + \"train-images.idx3-ubyte\", base_path + \"train-labels.idx1-ubyte\",\n",
    "                            base_path + \"t10k-images.idx3-ubyte\", base_path + \"t10k-labels.idx1-ubyte\")\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_mean = torch.mean(x_train, dim = 0, keepdim = True)\n",
    "    x_std = torch.std(x_train, dim = 0, keepdim = True)\n",
    "\n",
    "    x_train -= x_mean\n",
    "    x_train /= x_std\n",
    "    x_train[x_train != x_train] = 0\n",
    "\n",
    "    x_test -= x_mean\n",
    "    x_test /= x_std\n",
    "    x_test[x_test != x_test] = 0\n",
    "\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to train and evaluate the MLP model on MNIST using GPU.\n",
    "    \"\"\"\n",
    "    x_train, y_train, x_test, y_test = normalize_mnist()\n",
    "\n",
    "   \n",
    "    model = MLP([784, 256, 10])  \n",
    "    model.initialize()\n",
    "    model.set_hp(lr=1e-3, bs=512, activation=Sigmoid)  \n",
    "    \n",
    "    E = 25\n",
    "    for _ in range(E):\n",
    "        TrainMLP(model, x_train, y_train)\n",
    "        TestMLP(model, x_test, y_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
